2
Warning, this script only works for 1000 lines now
500
500
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:25:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:25:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:26:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:26:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:26:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:26:58 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:26:58 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:26:59 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 23:26:59 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 23:26:59 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 23:26:59 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 23:26:59 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 23:26:59 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 23:26:59 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 23:26:59 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 23:26:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0001
14/06/10 23:27:00 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0001 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:27:00 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0001/
14/06/10 23:27:00 INFO mapreduce.Job: Running job: job_1402467816780_0001
14/06/10 23:27:09 INFO mapreduce.Job: Job job_1402467816780_0001 running in uber mode : false
14/06/10 23:27:09 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:27:21 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 23:27:26 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:27:36 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 23:32:03 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 23:32:04 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 23:32:04 INFO mapreduce.Job: Job job_1402467816780_0001 completed successfully
14/06/10 23:32:04 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33202
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=300536
		Total time spent by all reduces in occupied slots (ms)=280712
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=202
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6199
		CPU time spent (ms)=277650
		Physical memory (bytes) snapshot=586686464
		Virtual memory (bytes) snapshot=2510508032
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 23:32:04 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:32:04 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:32:04 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 23:32:04 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 23:32:04 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 23:32:04 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 23:32:04 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 23:32:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0002
14/06/10 23:32:05 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0002 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:32:05 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0002/
14/06/10 23:32:05 INFO mapreduce.Job: Running job: job_1402467816780_0002
14/06/10 23:32:13 INFO mapreduce.Job: Job job_1402467816780_0002 running in uber mode : false
14/06/10 23:32:13 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:32:30 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 23:33:39 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:33:42 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 23:33:47 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 23:33:49 INFO mapreduce.Job: Job job_1402467816780_0002 completed successfully
14/06/10 23:33:49 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33202
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=171960
		Total time spent by all reduces in occupied slots (ms)=5547
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=202
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2590
		CPU time spent (ms)=78180
		Physical memory (bytes) snapshot=551616512
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 412435
[MR2PhaseApriori] Phase 1 execution time: 307881
[MR2PhaseApriori] Phase 2 execution time: 104554
splits=2
columns=16
Tue, Jun 10, 2014 11:33:50 PM
Warning, this script only works for 1000 lines now
500
500
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:34:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:34:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 23:34:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:34:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:34:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:34:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:35:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:35:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:35:46 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:35:46 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:35:47 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 23:35:47 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 23:35:47 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 23:35:47 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 23:35:47 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 23:35:47 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 23:35:47 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 23:35:47 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 23:35:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0003
14/06/10 23:35:47 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0003 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:35:47 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0003/
14/06/10 23:35:47 INFO mapreduce.Job: Running job: job_1402467816780_0003
14/06/10 23:35:55 INFO mapreduce.Job: Job job_1402467816780_0003 running in uber mode : false
14/06/10 23:35:55 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:36:07 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 23:36:11 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:36:20 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 23:40:48 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 23:40:51 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 23:40:51 INFO mapreduce.Job: Job job_1402467816780_0003 completed successfully
14/06/10 23:40:52 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33202
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=300772
		Total time spent by all reduces in occupied slots (ms)=281860
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=202
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6216
		CPU time spent (ms)=272820
		Physical memory (bytes) snapshot=593711104
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 23:40:52 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:40:52 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:40:52 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 23:40:52 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 23:40:52 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 23:40:52 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 23:40:52 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 23:40:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0004
14/06/10 23:40:52 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0004 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:40:52 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0004/
14/06/10 23:40:52 INFO mapreduce.Job: Running job: job_1402467816780_0004
14/06/10 23:41:01 INFO mapreduce.Job: Job job_1402467816780_0004 running in uber mode : false
14/06/10 23:41:01 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:41:18 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 23:42:29 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:42:31 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 23:42:37 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 23:42:38 INFO mapreduce.Job: Job job_1402467816780_0004 completed successfully
14/06/10 23:42:38 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33202
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=175643
		Total time spent by all reduces in occupied slots (ms)=5729
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=202
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2552
		CPU time spent (ms)=78640
		Physical memory (bytes) snapshot=543236096
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 414172
[MR2PhaseApriori] Phase 1 execution time: 307507
[MR2PhaseApriori] Phase 2 execution time: 106665
splits=2
columns=16
Tue, Jun 10, 2014 11:42:40 PM
Warning, this script only works for 1000 lines now
500
500
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:43:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:43:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 23:43:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:43:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:43:37 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:43:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:44:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:44:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:44:36 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:44:36 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:44:37 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 23:44:37 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 23:44:37 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 23:44:37 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 23:44:37 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 23:44:37 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 23:44:37 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 23:44:37 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 23:44:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0005
14/06/10 23:44:37 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0005 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:44:38 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0005/
14/06/10 23:44:38 INFO mapreduce.Job: Running job: job_1402467816780_0005
14/06/10 23:44:46 INFO mapreduce.Job: Job job_1402467816780_0005 running in uber mode : false
14/06/10 23:44:46 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:44:57 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 23:45:02 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:45:10 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 23:49:39 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 23:49:41 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 23:49:42 INFO mapreduce.Job: Job job_1402467816780_0005 completed successfully
14/06/10 23:49:42 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33202
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=299962
		Total time spent by all reduces in occupied slots (ms)=280887
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=202
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6148
		CPU time spent (ms)=272540
		Physical memory (bytes) snapshot=583995392
		Virtual memory (bytes) snapshot=2510548992
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 23:49:42 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:49:42 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:49:42 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 23:49:42 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 23:49:42 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 23:49:42 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 23:49:42 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 23:49:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0006
14/06/10 23:49:42 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0006 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:49:42 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0006/
14/06/10 23:49:42 INFO mapreduce.Job: Running job: job_1402467816780_0006
14/06/10 23:49:51 INFO mapreduce.Job: Job job_1402467816780_0006 running in uber mode : false
14/06/10 23:49:51 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:50:07 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 23:51:19 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:51:21 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 23:51:27 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 23:51:27 INFO mapreduce.Job: Job job_1402467816780_0006 completed successfully
14/06/10 23:51:27 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33202
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=175064
		Total time spent by all reduces in occupied slots (ms)=5618
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=202
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2534
		CPU time spent (ms)=77830
		Physical memory (bytes) snapshot=549871616
		Virtual memory (bytes) snapshot=2528866304
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 413533
[MR2PhaseApriori] Phase 1 execution time: 308006
[MR2PhaseApriori] Phase 2 execution time: 105527
splits=2
columns=16
Tue, Jun 10, 2014 11:51:29 PM
4
Warning, this script only works for 1000 lines now
250
250
250
250
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:51:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:51:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 23:51:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:52:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:52:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:52:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:52:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 23:53:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 23:53:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:53:26 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 23:53:26 INFO input.FileInputFormat: Total input paths to process : 4
14/06/10 23:53:26 INFO mapreduce.JobSubmitter: number of splits:4
14/06/10 23:53:26 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 23:53:26 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 23:53:26 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 23:53:26 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 23:53:26 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 23:53:26 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 23:53:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0007
14/06/10 23:53:27 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0007 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 23:53:27 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0007/
14/06/10 23:53:27 INFO mapreduce.Job: Running job: job_1402467816780_0007
14/06/10 23:53:35 INFO mapreduce.Job: Job job_1402467816780_0007 running in uber mode : false
14/06/10 23:53:35 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 23:53:56 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 23:54:00 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 23:54:14 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 00:02:57 INFO mapreduce.Job:  map 92% reduce 17%
14/06/11 00:02:59 INFO mapreduce.Job:  map 92% reduce 25%
14/06/11 00:03:16 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 00:03:17 INFO mapreduce.Job:  map 100% reduce 35%
14/06/11 00:03:18 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:03:19 INFO mapreduce.Job: Job job_1402467816780_0007 completed successfully
14/06/11 00:03:20 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=3342446
		FILE: Number of bytes written=7082895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33404
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=4
		Launched reduce tasks=1
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=1178402
		Total time spent by all reduces in occupied slots (ms)=559650
	Map-Reduce Framework
		Map input records=4
		Map output records=131076
		Map output bytes=3080288
		Map output materialized bytes=3342464
		Input split bytes=404
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=3342464
		Reduce input records=131076
		Reduce output records=65535
		Spilled Records=262152
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=12959
		CPU time spent (ms)=541970
		Physical memory (bytes) snapshot=1063329792
		Virtual memory (bytes) snapshot=4179726336
		Total committed heap usage (bytes)=809828352
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 00:03:20 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:03:20 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:03:20 INFO input.FileInputFormat: Total input paths to process : 4
14/06/11 00:03:20 INFO mapreduce.JobSubmitter: number of splits:4
14/06/11 00:03:20 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 00:03:20 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 00:03:20 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 00:03:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0008
14/06/11 00:03:20 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0008 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:03:20 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0008/
14/06/11 00:03:20 INFO mapreduce.Job: Running job: job_1402467816780_0008
14/06/11 00:03:27 INFO mapreduce.Job: Job job_1402467816780_0008 running in uber mode : false
14/06/11 00:03:27 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:03:54 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 00:05:01 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 00:05:05 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 00:05:11 INFO mapreduce.Job:  map 92% reduce 0%
14/06/11 00:05:13 INFO mapreduce.Job:  map 100% reduce 0%
14/06/11 00:05:15 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:05:16 INFO mapreduce.Job: Job job_1402467816780_0008 completed successfully
14/06/11 00:05:16 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=6684654
		FILE: Number of bytes written=13774081
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33404
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=4
		Launched reduce tasks=1
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=390575
		Total time spent by all reduces in occupied slots (ms)=10963
	Map-Reduce Framework
		Map input records=4
		Map output records=262140
		Map output bytes=6160368
		Map output materialized bytes=6684672
		Input split bytes=404
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=6684672
		Reduce input records=262140
		Reduce output records=1
		Spilled Records=524280
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=3694
		CPU time spent (ms)=83840
		Physical memory (bytes) snapshot=972230656
		Virtual memory (bytes) snapshot=4179230720
		Total committed heap usage (bytes)=731840512
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 712978
[MR2PhaseApriori] Phase 1 execution time: 596426
[MR2PhaseApriori] Phase 2 execution time: 116552
splits=4
columns=16
Wed, Jun 11, 2014 12:05:17 AM
Warning, this script only works for 1000 lines now
250
250
250
250
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:05:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:05:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 00:05:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:06:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:06:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:06:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:06:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:07:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:07:14 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:07:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:07:14 INFO input.FileInputFormat: Total input paths to process : 4
14/06/11 00:07:14 INFO mapreduce.JobSubmitter: number of splits:4
14/06/11 00:07:14 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 00:07:14 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 00:07:14 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 00:07:14 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 00:07:14 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 00:07:14 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 00:07:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0009
14/06/11 00:07:15 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0009 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:07:15 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0009/
14/06/11 00:07:15 INFO mapreduce.Job: Running job: job_1402467816780_0009
14/06/11 00:07:23 INFO mapreduce.Job: Job job_1402467816780_0009 running in uber mode : false
14/06/11 00:07:23 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:07:45 INFO mapreduce.Job:  map 50% reduce 0%
14/06/11 00:07:49 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 00:07:58 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 00:17:09 INFO mapreduce.Job:  map 92% reduce 17%
14/06/11 00:17:10 INFO mapreduce.Job:  map 92% reduce 25%
14/06/11 00:17:12 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 00:17:13 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:17:14 INFO mapreduce.Job: Job job_1402467816780_0009 completed successfully
14/06/11 00:17:14 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=3342446
		FILE: Number of bytes written=7082895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33404
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=4
		Launched reduce tasks=1
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=1208600
		Total time spent by all reduces in occupied slots (ms)=565851
	Map-Reduce Framework
		Map input records=4
		Map output records=131076
		Map output bytes=3080288
		Map output materialized bytes=3342464
		Input split bytes=404
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=3342464
		Reduce input records=131076
		Reduce output records=65535
		Spilled Records=262152
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=12982
		CPU time spent (ms)=557200
		Physical memory (bytes) snapshot=1056567296
		Virtual memory (bytes) snapshot=4179791872
		Total committed heap usage (bytes)=809828352
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 00:17:14 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:17:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:17:14 INFO input.FileInputFormat: Total input paths to process : 4
14/06/11 00:17:14 INFO mapreduce.JobSubmitter: number of splits:4
14/06/11 00:17:14 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 00:17:14 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 00:17:14 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 00:17:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0010
14/06/11 00:17:14 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0010 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:17:14 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0010/
14/06/11 00:17:14 INFO mapreduce.Job: Running job: job_1402467816780_0010
14/06/11 00:17:23 INFO mapreduce.Job: Job job_1402467816780_0010 running in uber mode : false
14/06/11 00:17:23 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:17:48 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 00:18:56 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 00:19:00 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 00:19:06 INFO mapreduce.Job:  map 92% reduce 0%
14/06/11 00:19:07 INFO mapreduce.Job:  map 100% reduce 0%
14/06/11 00:19:09 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:19:10 INFO mapreduce.Job: Job job_1402467816780_0010 completed successfully
14/06/11 00:19:10 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=6684654
		FILE: Number of bytes written=13774081
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33404
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=4
		Launched reduce tasks=1
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=392921
		Total time spent by all reduces in occupied slots (ms)=10953
	Map-Reduce Framework
		Map input records=4
		Map output records=262140
		Map output bytes=6160368
		Map output materialized bytes=6684672
		Input split bytes=404
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=6684672
		Reduce input records=262140
		Reduce output records=1
		Spilled Records=524280
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=3162
		CPU time spent (ms)=83120
		Physical memory (bytes) snapshot=1004806144
		Virtual memory (bytes) snapshot=4179173376
		Total committed heap usage (bytes)=770834432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 718730
[MR2PhaseApriori] Phase 1 execution time: 602178
[MR2PhaseApriori] Phase 2 execution time: 116552
splits=4
columns=16
Wed, Jun 11, 2014 12:19:12 AM
Warning, this script only works for 1000 lines now
250
250
250
250
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:19:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:19:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 00:19:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:20:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:20:09 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:20:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:20:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:21:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:21:08 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:21:08 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:21:09 INFO input.FileInputFormat: Total input paths to process : 4
14/06/11 00:21:09 INFO mapreduce.JobSubmitter: number of splits:4
14/06/11 00:21:09 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 00:21:09 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 00:21:09 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 00:21:09 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 00:21:09 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 00:21:09 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 00:21:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0011
14/06/11 00:21:10 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0011 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:21:10 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0011/
14/06/11 00:21:10 INFO mapreduce.Job: Running job: job_1402467816780_0011
14/06/11 00:21:17 INFO mapreduce.Job: Job job_1402467816780_0011 running in uber mode : false
14/06/11 00:21:17 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:21:38 INFO mapreduce.Job:  map 25% reduce 0%
14/06/11 00:21:39 INFO mapreduce.Job:  map 50% reduce 0%
14/06/11 00:21:42 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 00:21:56 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 00:30:33 INFO mapreduce.Job:  map 92% reduce 17%
14/06/11 00:30:35 INFO mapreduce.Job:  map 92% reduce 25%
14/06/11 00:30:41 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 00:30:44 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:30:44 INFO mapreduce.Job: Job job_1402467816780_0011 completed successfully
14/06/11 00:30:44 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=3342446
		FILE: Number of bytes written=7082895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33404
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=4
		Launched reduce tasks=1
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=1153466
		Total time spent by all reduces in occupied slots (ms)=541996
	Map-Reduce Framework
		Map input records=4
		Map output records=131076
		Map output bytes=3080288
		Map output materialized bytes=3342464
		Input split bytes=404
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=3342464
		Reduce input records=131076
		Reduce output records=65535
		Spilled Records=262152
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=13568
		CPU time spent (ms)=514410
		Physical memory (bytes) snapshot=1058963456
		Virtual memory (bytes) snapshot=4179763200
		Total committed heap usage (bytes)=809828352
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 00:30:44 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:30:44 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:30:44 INFO input.FileInputFormat: Total input paths to process : 4
14/06/11 00:30:44 INFO mapreduce.JobSubmitter: number of splits:4
14/06/11 00:30:44 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 00:30:44 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 00:30:44 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 00:30:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0012
14/06/11 00:30:44 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0012 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:30:44 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0012/
14/06/11 00:30:44 INFO mapreduce.Job: Running job: job_1402467816780_0012
14/06/11 00:30:53 INFO mapreduce.Job: Job job_1402467816780_0012 running in uber mode : false
14/06/11 00:30:53 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:31:18 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 00:32:25 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 00:32:29 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 00:32:36 INFO mapreduce.Job:  map 92% reduce 0%
14/06/11 00:32:37 INFO mapreduce.Job:  map 100% reduce 0%
14/06/11 00:32:38 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 00:32:39 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:32:40 INFO mapreduce.Job: Job job_1402467816780_0012 completed successfully
14/06/11 00:32:41 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=6684654
		FILE: Number of bytes written=13774081
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33404
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=4
		Launched reduce tasks=1
		Data-local map tasks=4
		Total time spent by all maps in occupied slots (ms)=390356
		Total time spent by all reduces in occupied slots (ms)=11945
	Map-Reduce Framework
		Map input records=4
		Map output records=262140
		Map output bytes=6160368
		Map output materialized bytes=6684672
		Input split bytes=404
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=6684672
		Reduce input records=262140
		Reduce output records=1
		Spilled Records=524280
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=3497
		CPU time spent (ms)=82960
		Physical memory (bytes) snapshot=981123072
		Virtual memory (bytes) snapshot=4179873792
		Total committed heap usage (bytes)=731840512
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 694381
[MR2PhaseApriori] Phase 1 execution time: 577628
[MR2PhaseApriori] Phase 2 execution time: 116753
splits=4
columns=16
Wed, Jun 11, 2014 12:32:42 AM
6
Warning, this script only works for 1000 lines now
166
166
166
166
166
166
4
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:33:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:33:07 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 00:33:07 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:33:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:33:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:33:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:34:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:34:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:34:39 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:34:40 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:34:40 INFO input.FileInputFormat: Total input paths to process : 7
14/06/11 00:34:40 INFO mapreduce.JobSubmitter: number of splits:7
14/06/11 00:34:40 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 00:34:40 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 00:34:40 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 00:34:40 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 00:34:40 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 00:34:40 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 00:34:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0013
14/06/11 00:34:41 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0013 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:34:41 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0013/
14/06/11 00:34:41 INFO mapreduce.Job: Running job: job_1402467816780_0013
14/06/11 00:34:48 INFO mapreduce.Job: Job job_1402467816780_0013 running in uber mode : false
14/06/11 00:34:48 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:35:01 INFO mapreduce.Job:  map 10% reduce 0%
14/06/11 00:35:21 INFO mapreduce.Job:  map 24% reduce 0%
14/06/11 00:35:22 INFO mapreduce.Job:  map 52% reduce 0%
14/06/11 00:35:24 INFO mapreduce.Job:  map 71% reduce 0%
14/06/11 00:35:25 INFO mapreduce.Job:  map 81% reduce 0%
14/06/11 00:35:37 INFO mapreduce.Job:  map 81% reduce 14%
14/06/11 00:39:46 INFO mapreduce.Job:  map 86% reduce 19%
14/06/11 00:49:31 INFO mapreduce.Job:  map 90% reduce 19%
14/06/11 00:49:33 INFO mapreduce.Job:  map 90% reduce 24%
14/06/11 00:49:44 INFO mapreduce.Job:  map 95% reduce 24%
14/06/11 00:49:45 INFO mapreduce.Job:  map 95% reduce 29%
14/06/11 00:49:47 INFO mapreduce.Job:  map 100% reduce 29%
14/06/11 00:49:48 INFO mapreduce.Job:  map 100% reduce 68%
14/06/11 00:49:49 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:49:49 INFO mapreduce.Job: Job job_1402467816780_0013 completed successfully
14/06/11 00:49:49 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=6684853
		FILE: Number of bytes written=14006491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33707
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=7
		Launched reduce tasks=1
		Data-local map tasks=7
		Total time spent by all maps in occupied slots (ms)=3062297
		Total time spent by all reduces in occupied slots (ms)=864768
	Map-Reduce Framework
		Map input records=7
		Map output records=262150
		Map output bytes=6160547
		Map output materialized bytes=6684889
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=6684889
		Reduce input records=262150
		Reduce output records=65535
		Spilled Records=524300
		Shuffled Maps =7
		Failed Shuffles=0
		Merged Map outputs=7
		GC time elapsed (ms)=43601
		CPU time spent (ms)=1121510
		Physical memory (bytes) snapshot=1774809088
		Virtual memory (bytes) snapshot=6683406336
		Total committed heap usage (bytes)=1340145664
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 00:49:49 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:49:49 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:49:49 INFO input.FileInputFormat: Total input paths to process : 7
14/06/11 00:49:49 INFO mapreduce.JobSubmitter: number of splits:7
14/06/11 00:49:49 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 00:49:49 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 00:49:49 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 00:49:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0014
14/06/11 00:49:50 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0014 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:49:50 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0014/
14/06/11 00:49:50 INFO mapreduce.Job: Running job: job_1402467816780_0014
14/06/11 00:49:57 INFO mapreduce.Job: Job job_1402467816780_0014 running in uber mode : false
14/06/11 00:49:57 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:50:37 INFO mapreduce.Job:  map 38% reduce 0%
14/06/11 00:50:40 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 00:50:43 INFO mapreduce.Job:  map 71% reduce 0%
14/06/11 00:51:14 INFO mapreduce.Job:  map 71% reduce 5%
14/06/11 00:51:59 INFO mapreduce.Job:  map 76% reduce 5%
14/06/11 00:52:00 INFO mapreduce.Job:  map 81% reduce 5%
14/06/11 00:52:01 INFO mapreduce.Job:  map 81% reduce 14%
14/06/11 00:52:02 INFO mapreduce.Job:  map 86% reduce 14%
14/06/11 00:52:04 INFO mapreduce.Job:  map 86% reduce 19%
14/06/11 00:52:08 INFO mapreduce.Job:  map 90% reduce 19%
14/06/11 00:52:10 INFO mapreduce.Job:  map 95% reduce 24%
14/06/11 00:52:11 INFO mapreduce.Job:  map 100% reduce 24%
14/06/11 00:52:13 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 00:52:14 INFO mapreduce.Job: Job job_1402467816780_0014 completed successfully
14/06/11 00:52:14 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=11698140
		FILE: Number of bytes written=24043897
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33707
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=7
		Launched reduce tasks=1
		Data-local map tasks=7
		Total time spent by all maps in occupied slots (ms)=795133
		Total time spent by all reduces in occupied slots (ms)=86521
	Map-Reduce Framework
		Map input records=7
		Map output records=458745
		Map output bytes=10780644
		Map output materialized bytes=11698176
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=11698176
		Reduce input records=458745
		Reduce output records=1
		Spilled Records=917490
		Shuffled Maps =7
		Failed Shuffles=0
		Merged Map outputs=7
		GC time elapsed (ms)=6032
		CPU time spent (ms)=91600
		Physical memory (bytes) snapshot=1649401856
		Virtual memory (bytes) snapshot=6683021312
		Total committed heap usage (bytes)=1223163904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1056953
[MR2PhaseApriori] Phase 1 execution time: 912249
[MR2PhaseApriori] Phase 2 execution time: 144704
splits=6
columns=16
Wed, Jun 11, 2014 12:52:15 AM
Warning, this script only works for 1000 lines now
166
166
166
166
166
166
4
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:52:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:52:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 00:52:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:53:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:53:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:53:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:53:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 00:54:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 00:54:12 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:54:12 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 00:54:13 INFO input.FileInputFormat: Total input paths to process : 7
14/06/11 00:54:13 INFO mapreduce.JobSubmitter: number of splits:7
14/06/11 00:54:13 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 00:54:13 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 00:54:13 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 00:54:13 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 00:54:13 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 00:54:13 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 00:54:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0015
14/06/11 00:54:13 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0015 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 00:54:14 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0015/
14/06/11 00:54:14 INFO mapreduce.Job: Running job: job_1402467816780_0015
14/06/11 00:54:22 INFO mapreduce.Job: Job job_1402467816780_0015 running in uber mode : false
14/06/11 00:54:22 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 00:54:34 INFO mapreduce.Job:  map 10% reduce 0%
14/06/11 00:54:55 INFO mapreduce.Job:  map 38% reduce 0%
14/06/11 00:54:56 INFO mapreduce.Job:  map 52% reduce 0%
14/06/11 00:54:57 INFO mapreduce.Job:  map 71% reduce 0%
14/06/11 00:54:58 INFO mapreduce.Job:  map 81% reduce 0%
14/06/11 00:55:11 INFO mapreduce.Job:  map 81% reduce 14%
14/06/11 00:59:22 INFO mapreduce.Job:  map 86% reduce 14%
14/06/11 00:59:23 INFO mapreduce.Job:  map 86% reduce 19%
14/06/11 01:08:55 INFO mapreduce.Job:  map 90% reduce 19%
14/06/11 01:08:58 INFO mapreduce.Job:  map 90% reduce 24%
14/06/11 01:09:11 INFO mapreduce.Job:  map 95% reduce 24%
14/06/11 01:09:13 INFO mapreduce.Job:  map 95% reduce 29%
14/06/11 01:09:18 INFO mapreduce.Job:  map 100% reduce 29%
14/06/11 01:09:19 INFO mapreduce.Job:  map 100% reduce 67%
14/06/11 01:09:20 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:09:21 INFO mapreduce.Job: Job job_1402467816780_0015 completed successfully
14/06/11 01:09:21 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=6684853
		FILE: Number of bytes written=14006491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33707
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=7
		Launched reduce tasks=1
		Data-local map tasks=7
		Total time spent by all maps in occupied slots (ms)=3049152
		Total time spent by all reduces in occupied slots (ms)=861889
	Map-Reduce Framework
		Map input records=7
		Map output records=262150
		Map output bytes=6160547
		Map output materialized bytes=6684889
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=6684889
		Reduce input records=262150
		Reduce output records=65535
		Spilled Records=524300
		Shuffled Maps =7
		Failed Shuffles=0
		Merged Map outputs=7
		GC time elapsed (ms)=37353
		CPU time spent (ms)=1111070
		Physical memory (bytes) snapshot=1772634112
		Virtual memory (bytes) snapshot=6683578368
		Total committed heap usage (bytes)=1340145664
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 01:09:21 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:09:21 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:09:21 INFO input.FileInputFormat: Total input paths to process : 7
14/06/11 01:09:22 INFO mapreduce.JobSubmitter: number of splits:7
14/06/11 01:09:22 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 01:09:22 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 01:09:22 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 01:09:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0016
14/06/11 01:09:22 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0016 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:09:22 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0016/
14/06/11 01:09:22 INFO mapreduce.Job: Running job: job_1402467816780_0016
14/06/11 01:09:29 INFO mapreduce.Job: Job job_1402467816780_0016 running in uber mode : false
14/06/11 01:09:29 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:09:38 INFO mapreduce.Job:  map 14% reduce 0%
14/06/11 01:09:51 INFO mapreduce.Job:  map 14% reduce 5%
14/06/11 01:10:05 INFO mapreduce.Job:  map 71% reduce 5%
14/06/11 01:11:19 INFO mapreduce.Job:  map 81% reduce 5%
14/06/11 01:11:22 INFO mapreduce.Job:  map 86% reduce 14%
14/06/11 01:11:25 INFO mapreduce.Job:  map 86% reduce 19%
14/06/11 01:11:29 INFO mapreduce.Job:  map 90% reduce 19%
14/06/11 01:11:31 INFO mapreduce.Job:  map 100% reduce 24%
14/06/11 01:11:33 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:11:33 INFO mapreduce.Job: Job job_1402467816780_0016 completed successfully
14/06/11 01:11:33 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=11698140
		FILE: Number of bytes written=24043897
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33707
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=7
		Launched reduce tasks=1
		Data-local map tasks=7
		Total time spent by all maps in occupied slots (ms)=686347
		Total time spent by all reduces in occupied slots (ms)=112017
	Map-Reduce Framework
		Map input records=7
		Map output records=458745
		Map output bytes=10780644
		Map output materialized bytes=11698176
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=11698176
		Reduce input records=458745
		Reduce output records=1
		Spilled Records=917490
		Shuffled Maps =7
		Failed Shuffles=0
		Merged Map outputs=7
		GC time elapsed (ms)=5551
		CPU time spent (ms)=92250
		Physical memory (bytes) snapshot=1631789056
		Virtual memory (bytes) snapshot=6683324416
		Total committed heap usage (bytes)=1223163904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1042623
[MR2PhaseApriori] Phase 1 execution time: 911074
[MR2PhaseApriori] Phase 2 execution time: 131549
splits=6
columns=16
Wed, Jun 11, 2014  1:11:34 AM
Warning, this script only works for 1000 lines now
166
166
166
166
166
166
4
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:11:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:11:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 01:11:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:12:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:12:32 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:12:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:12:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:13:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:13:31 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:13:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:13:32 INFO input.FileInputFormat: Total input paths to process : 7
14/06/11 01:13:32 INFO mapreduce.JobSubmitter: number of splits:7
14/06/11 01:13:32 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 01:13:32 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 01:13:32 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 01:13:32 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 01:13:32 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 01:13:32 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 01:13:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0017
14/06/11 01:13:33 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0017 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:13:33 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0017/
14/06/11 01:13:33 INFO mapreduce.Job: Running job: job_1402467816780_0017
14/06/11 01:13:41 INFO mapreduce.Job: Job job_1402467816780_0017 running in uber mode : false
14/06/11 01:13:41 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:13:53 INFO mapreduce.Job:  map 10% reduce 0%
14/06/11 01:14:14 INFO mapreduce.Job:  map 24% reduce 0%
14/06/11 01:14:15 INFO mapreduce.Job:  map 52% reduce 0%
14/06/11 01:14:17 INFO mapreduce.Job:  map 71% reduce 0%
14/06/11 01:14:18 INFO mapreduce.Job:  map 81% reduce 0%
14/06/11 01:14:29 INFO mapreduce.Job:  map 81% reduce 14%
14/06/11 01:18:44 INFO mapreduce.Job:  map 86% reduce 14%
14/06/11 01:18:47 INFO mapreduce.Job:  map 86% reduce 19%
14/06/11 01:28:16 INFO mapreduce.Job:  map 90% reduce 19%
14/06/11 01:28:19 INFO mapreduce.Job:  map 90% reduce 24%
14/06/11 01:28:28 INFO mapreduce.Job:  map 95% reduce 24%
14/06/11 01:28:31 INFO mapreduce.Job:  map 95% reduce 29%
14/06/11 01:28:35 INFO mapreduce.Job:  map 100% reduce 29%
14/06/11 01:28:37 INFO mapreduce.Job:  map 100% reduce 67%
14/06/11 01:28:38 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:28:38 INFO mapreduce.Job: Job job_1402467816780_0017 completed successfully
14/06/11 01:28:38 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=6684853
		FILE: Number of bytes written=14006491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33707
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=7
		Launched reduce tasks=1
		Data-local map tasks=7
		Total time spent by all maps in occupied slots (ms)=3044635
		Total time spent by all reduces in occupied slots (ms)=862016
	Map-Reduce Framework
		Map input records=7
		Map output records=262150
		Map output bytes=6160547
		Map output materialized bytes=6684889
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=6684889
		Reduce input records=262150
		Reduce output records=65535
		Spilled Records=524300
		Shuffled Maps =7
		Failed Shuffles=0
		Merged Map outputs=7
		GC time elapsed (ms)=36895
		CPU time spent (ms)=1113820
		Physical memory (bytes) snapshot=1758228480
		Virtual memory (bytes) snapshot=6683054080
		Total committed heap usage (bytes)=1340145664
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 01:28:38 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:28:38 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:28:39 INFO input.FileInputFormat: Total input paths to process : 7
14/06/11 01:28:39 INFO mapreduce.JobSubmitter: number of splits:7
14/06/11 01:28:39 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 01:28:39 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 01:28:39 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 01:28:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0018
14/06/11 01:28:39 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0018 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:28:39 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0018/
14/06/11 01:28:39 INFO mapreduce.Job: Running job: job_1402467816780_0018
14/06/11 01:28:46 INFO mapreduce.Job: Job job_1402467816780_0018 running in uber mode : false
14/06/11 01:28:46 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:28:55 INFO mapreduce.Job:  map 14% reduce 0%
14/06/11 01:29:08 INFO mapreduce.Job:  map 14% reduce 5%
14/06/11 01:29:21 INFO mapreduce.Job:  map 43% reduce 5%
14/06/11 01:29:22 INFO mapreduce.Job:  map 71% reduce 5%
14/06/11 01:30:37 INFO mapreduce.Job:  map 81% reduce 5%
14/06/11 01:30:39 INFO mapreduce.Job:  map 81% reduce 14%
14/06/11 01:30:40 INFO mapreduce.Job:  map 86% reduce 14%
14/06/11 01:30:42 INFO mapreduce.Job:  map 86% reduce 19%
14/06/11 01:30:46 INFO mapreduce.Job:  map 90% reduce 19%
14/06/11 01:30:48 INFO mapreduce.Job:  map 100% reduce 24%
14/06/11 01:30:50 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:30:50 INFO mapreduce.Job: Job job_1402467816780_0018 completed successfully
14/06/11 01:30:50 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=11698140
		FILE: Number of bytes written=24043897
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33707
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=7
		Launched reduce tasks=1
		Data-local map tasks=7
		Total time spent by all maps in occupied slots (ms)=688151
		Total time spent by all reduces in occupied slots (ms)=112041
	Map-Reduce Framework
		Map input records=7
		Map output records=458745
		Map output bytes=10780644
		Map output materialized bytes=11698176
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=11698176
		Reduce input records=458745
		Reduce output records=1
		Spilled Records=917490
		Shuffled Maps =7
		Failed Shuffles=0
		Merged Map outputs=7
		GC time elapsed (ms)=5320
		CPU time spent (ms)=91430
		Physical memory (bytes) snapshot=1634938880
		Virtual memory (bytes) snapshot=6692118528
		Total committed heap usage (bytes)=1223163904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1040821
[MR2PhaseApriori] Phase 1 execution time: 909340
[MR2PhaseApriori] Phase 2 execution time: 131481
splits=6
columns=16
Wed, Jun 11, 2014  1:30:51 AM
8
Warning, this script only works for 1000 lines now
125
125
125
125
125
125
125
125
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:31:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:31:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 01:31:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:31:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:31:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:32:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:32:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:32:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:32:48 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:32:49 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:32:49 INFO input.FileInputFormat: Total input paths to process : 8
14/06/11 01:32:49 INFO mapreduce.JobSubmitter: number of splits:8
14/06/11 01:32:49 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 01:32:49 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 01:32:49 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 01:32:49 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 01:32:49 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 01:32:49 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 01:32:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0019
14/06/11 01:32:50 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0019 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:32:50 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0019/
14/06/11 01:32:50 INFO mapreduce.Job: Running job: job_1402467816780_0019
14/06/11 01:32:57 INFO mapreduce.Job: Job job_1402467816780_0019 running in uber mode : false
14/06/11 01:32:57 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:33:14 INFO mapreduce.Job:  map 17% reduce 0%
14/06/11 01:33:30 INFO mapreduce.Job:  map 29% reduce 0%
14/06/11 01:33:31 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 01:33:34 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 01:33:49 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 01:42:44 INFO mapreduce.Job:  map 88% reduce 17%
14/06/11 01:42:45 INFO mapreduce.Job:  map 88% reduce 21%
14/06/11 01:42:47 INFO mapreduce.Job:  map 92% reduce 21%
14/06/11 01:42:51 INFO mapreduce.Job:  map 92% reduce 25%
14/06/11 01:43:18 INFO mapreduce.Job:  map 96% reduce 29%
14/06/11 01:43:25 INFO mapreduce.Job:  map 100% reduce 29%
14/06/11 01:43:27 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:43:27 INFO mapreduce.Job: Job job_1402467816780_0019 completed successfully
14/06/11 01:43:28 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=6684886
		FILE: Number of bytes written=14086151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33808
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=1
		Data-local map tasks=8
		Total time spent by all maps in occupied slots (ms)=2538012
		Total time spent by all reduces in occupied slots (ms)=594360
	Map-Reduce Framework
		Map input records=8
		Map output records=262152
		Map output bytes=6160576
		Map output materialized bytes=6684928
		Input split bytes=808
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=6684928
		Reduce input records=262152
		Reduce output records=65535
		Spilled Records=524304
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=33478
		CPU time spent (ms)=1133870
		Physical memory (bytes) snapshot=2027089920
		Virtual memory (bytes) snapshot=7517630464
		Total committed heap usage (bytes)=1542914048
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 01:43:28 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:43:28 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:43:28 INFO input.FileInputFormat: Total input paths to process : 8
14/06/11 01:43:28 INFO mapreduce.JobSubmitter: number of splits:8
14/06/11 01:43:28 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 01:43:28 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 01:43:28 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 01:43:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0020
14/06/11 01:43:28 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0020 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:43:28 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0020/
14/06/11 01:43:28 INFO mapreduce.Job: Running job: job_1402467816780_0020
14/06/11 01:43:35 INFO mapreduce.Job: Job job_1402467816780_0020 running in uber mode : false
14/06/11 01:43:35 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:43:52 INFO mapreduce.Job:  map 17% reduce 0%
14/06/11 01:44:12 INFO mapreduce.Job:  map 25% reduce 0%
14/06/11 01:44:13 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 01:44:14 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 01:44:26 INFO mapreduce.Job:  map 75% reduce 8%
14/06/11 01:45:09 INFO mapreduce.Job:  map 79% reduce 8%
14/06/11 01:45:10 INFO mapreduce.Job:  map 88% reduce 8%
14/06/11 01:45:12 INFO mapreduce.Job:  map 88% reduce 21%
14/06/11 01:45:13 INFO mapreduce.Job:  map 92% reduce 21%
14/06/11 01:45:15 INFO mapreduce.Job:  map 96% reduce 25%
14/06/11 01:45:16 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 01:45:18 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:45:19 INFO mapreduce.Job: Job job_1402467816780_0020 completed successfully
14/06/11 01:45:19 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=13369302
		FILE: Number of bytes written=27467169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33808
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=1
		Data-local map tasks=8
		Total time spent by all maps in occupied slots (ms)=637955
		Total time spent by all reduces in occupied slots (ms)=62514
	Map-Reduce Framework
		Map input records=8
		Map output records=524280
		Map output bytes=12320736
		Map output materialized bytes=13369344
		Input split bytes=808
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=13369344
		Reduce input records=524280
		Reduce output records=1
		Spilled Records=1048560
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=5853
		CPU time spent (ms)=94760
		Physical memory (bytes) snapshot=1868697600
		Virtual memory (bytes) snapshot=7517560832
		Total committed heap usage (bytes)=1386938368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 752868
[MR2PhaseApriori] Phase 1 execution time: 641348
[MR2PhaseApriori] Phase 2 execution time: 111520
splits=8
columns=16
Wed, Jun 11, 2014  1:45:20 AM
Warning, this script only works for 1000 lines now
125
125
125
125
125
125
125
125
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:45:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:45:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 01:45:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:46:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:46:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:46:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:46:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 01:47:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 01:47:17 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:47:18 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:47:18 INFO input.FileInputFormat: Total input paths to process : 8
14/06/11 01:47:18 INFO mapreduce.JobSubmitter: number of splits:8
14/06/11 01:47:18 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 01:47:18 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 01:47:18 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 01:47:18 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 01:47:18 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 01:47:18 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 01:47:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0021
14/06/11 01:47:19 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0021 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:47:19 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0021/
14/06/11 01:47:19 INFO mapreduce.Job: Running job: job_1402467816780_0021
14/06/11 01:47:27 INFO mapreduce.Job: Job job_1402467816780_0021 running in uber mode : false
14/06/11 01:47:27 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:47:44 INFO mapreduce.Job:  map 17% reduce 0%
14/06/11 01:48:00 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 01:48:03 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 01:48:04 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 01:48:19 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 01:57:13 INFO mapreduce.Job:  map 88% reduce 17%
14/06/11 01:57:15 INFO mapreduce.Job:  map 88% reduce 21%
14/06/11 01:57:18 INFO mapreduce.Job:  map 92% reduce 21%
14/06/11 01:57:21 INFO mapreduce.Job:  map 92% reduce 25%
14/06/11 01:57:41 INFO mapreduce.Job:  map 96% reduce 25%
14/06/11 01:57:43 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 01:57:44 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:57:45 INFO mapreduce.Job: Job job_1402467816780_0021 completed successfully
14/06/11 01:57:45 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=6684886
		FILE: Number of bytes written=14086151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33808
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=1
		Data-local map tasks=8
		Total time spent by all maps in occupied slots (ms)=2526405
		Total time spent by all reduces in occupied slots (ms)=581816
	Map-Reduce Framework
		Map input records=8
		Map output records=262152
		Map output bytes=6160576
		Map output materialized bytes=6684928
		Input split bytes=808
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=6684928
		Reduce input records=262152
		Reduce output records=65535
		Spilled Records=524304
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=35464
		CPU time spent (ms)=1124070
		Physical memory (bytes) snapshot=2028392448
		Virtual memory (bytes) snapshot=7518175232
		Total committed heap usage (bytes)=1542914048
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 01:57:45 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:57:45 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 01:57:46 INFO input.FileInputFormat: Total input paths to process : 8
14/06/11 01:57:46 INFO mapreduce.JobSubmitter: number of splits:8
14/06/11 01:57:46 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 01:57:46 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 01:57:46 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 01:57:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0022
14/06/11 01:57:46 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0022 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 01:57:46 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0022/
14/06/11 01:57:46 INFO mapreduce.Job: Running job: job_1402467816780_0022
14/06/11 01:57:54 INFO mapreduce.Job: Job job_1402467816780_0022 running in uber mode : false
14/06/11 01:57:54 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 01:58:11 INFO mapreduce.Job:  map 17% reduce 0%
14/06/11 01:58:30 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 01:58:32 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 01:58:45 INFO mapreduce.Job:  map 75% reduce 8%
14/06/11 01:59:27 INFO mapreduce.Job:  map 79% reduce 8%
14/06/11 01:59:28 INFO mapreduce.Job:  map 83% reduce 8%
14/06/11 01:59:29 INFO mapreduce.Job:  map 88% reduce 8%
14/06/11 01:59:30 INFO mapreduce.Job:  map 88% reduce 21%
14/06/11 01:59:31 INFO mapreduce.Job:  map 92% reduce 21%
14/06/11 01:59:33 INFO mapreduce.Job:  map 96% reduce 25%
14/06/11 01:59:34 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 01:59:36 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 01:59:37 INFO mapreduce.Job: Job job_1402467816780_0022 completed successfully
14/06/11 01:59:37 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=13369302
		FILE: Number of bytes written=27467169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33808
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=1
		Data-local map tasks=8
		Total time spent by all maps in occupied slots (ms)=637810
		Total time spent by all reduces in occupied slots (ms)=62172
	Map-Reduce Framework
		Map input records=8
		Map output records=524280
		Map output bytes=12320736
		Map output materialized bytes=13369344
		Input split bytes=808
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=13369344
		Reduce input records=524280
		Reduce output records=1
		Spilled Records=1048560
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=5603
		CPU time spent (ms)=94380
		Physical memory (bytes) snapshot=1892855808
		Virtual memory (bytes) snapshot=7518466048
		Total committed heap usage (bytes)=1425932288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 741630
[MR2PhaseApriori] Phase 1 execution time: 629909
[MR2PhaseApriori] Phase 2 execution time: 111721
splits=8
columns=16
Wed, Jun 11, 2014  1:59:38 AM
Warning, this script only works for 1000 lines now
125
125
125
125
125
125
125
125
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:00:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:00:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 02:00:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:00:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:00:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:00:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:01:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:01:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:01:36 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:01:36 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:01:36 INFO input.FileInputFormat: Total input paths to process : 8
14/06/11 02:01:37 INFO mapreduce.JobSubmitter: number of splits:8
14/06/11 02:01:37 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 02:01:37 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 02:01:37 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 02:01:37 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 02:01:37 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 02:01:37 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 02:01:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0023
14/06/11 02:01:37 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0023 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:01:37 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0023/
14/06/11 02:01:37 INFO mapreduce.Job: Running job: job_1402467816780_0023
14/06/11 02:01:46 INFO mapreduce.Job: Job job_1402467816780_0023 running in uber mode : false
14/06/11 02:01:46 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:02:03 INFO mapreduce.Job:  map 17% reduce 0%
14/06/11 02:02:18 INFO mapreduce.Job:  map 42% reduce 0%
14/06/11 02:02:19 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 02:02:21 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 02:02:22 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 02:02:36 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 02:11:37 INFO mapreduce.Job:  map 92% reduce 17%
14/06/11 02:11:39 INFO mapreduce.Job:  map 92% reduce 25%
14/06/11 02:11:53 INFO mapreduce.Job:  map 96% reduce 25%
14/06/11 02:11:54 INFO mapreduce.Job:  map 96% reduce 29%
14/06/11 02:12:01 INFO mapreduce.Job:  map 100% reduce 29%
14/06/11 02:12:03 INFO mapreduce.Job:  map 100% reduce 77%
14/06/11 02:12:04 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 02:12:04 INFO mapreduce.Job: Job job_1402467816780_0023 completed successfully
14/06/11 02:12:04 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=6684886
		FILE: Number of bytes written=14086151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33808
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=1
		Data-local map tasks=8
		Total time spent by all maps in occupied slots (ms)=2520628
		Total time spent by all reduces in occupied slots (ms)=582905
	Map-Reduce Framework
		Map input records=8
		Map output records=262152
		Map output bytes=6160576
		Map output materialized bytes=6684928
		Input split bytes=808
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=6684928
		Reduce input records=262152
		Reduce output records=65535
		Spilled Records=524304
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=28934
		CPU time spent (ms)=1123380
		Physical memory (bytes) snapshot=2012340224
		Virtual memory (bytes) snapshot=7517757440
		Total committed heap usage (bytes)=1542914048
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 02:12:04 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:12:04 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:12:04 INFO input.FileInputFormat: Total input paths to process : 8
14/06/11 02:12:04 INFO mapreduce.JobSubmitter: number of splits:8
14/06/11 02:12:04 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 02:12:04 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 02:12:04 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 02:12:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0024
14/06/11 02:12:05 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0024 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:12:05 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0024/
14/06/11 02:12:05 INFO mapreduce.Job: Running job: job_1402467816780_0024
14/06/11 02:12:13 INFO mapreduce.Job: Job job_1402467816780_0024 running in uber mode : false
14/06/11 02:12:13 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:12:30 INFO mapreduce.Job:  map 17% reduce 0%
14/06/11 02:12:49 INFO mapreduce.Job:  map 71% reduce 0%
14/06/11 02:12:50 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 02:13:02 INFO mapreduce.Job:  map 75% reduce 8%
14/06/11 02:13:46 INFO mapreduce.Job:  map 79% reduce 8%
14/06/11 02:13:47 INFO mapreduce.Job:  map 88% reduce 8%
14/06/11 02:13:49 INFO mapreduce.Job:  map 88% reduce 21%
14/06/11 02:13:51 INFO mapreduce.Job:  map 92% reduce 21%
14/06/11 02:13:52 INFO mapreduce.Job:  map 96% reduce 25%
14/06/11 02:13:53 INFO mapreduce.Job:  map 100% reduce 25%
14/06/11 02:13:55 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 02:13:55 INFO mapreduce.Job: Job job_1402467816780_0024 completed successfully
14/06/11 02:13:55 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=13369302
		FILE: Number of bytes written=27467169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33808
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=1
		Data-local map tasks=8
		Total time spent by all maps in occupied slots (ms)=637051
		Total time spent by all reduces in occupied slots (ms)=61967
	Map-Reduce Framework
		Map input records=8
		Map output records=524280
		Map output bytes=12320736
		Map output materialized bytes=13369344
		Input split bytes=808
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=13369344
		Reduce input records=524280
		Reduce output records=1
		Spilled Records=1048560
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=5669
		CPU time spent (ms)=94360
		Physical memory (bytes) snapshot=1859219456
		Virtual memory (bytes) snapshot=7517986816
		Total committed heap usage (bytes)=1386938368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 741231
[MR2PhaseApriori] Phase 1 execution time: 630464
[MR2PhaseApriori] Phase 2 execution time: 110767
splits=8
columns=16
Wed, Jun 11, 2014  2:13:56 AM
10
Warning, this script only works for 1000 lines now
100
100
100
100
100
100
100
100
100
100
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:14:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:14:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 02:14:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:14:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:14:54 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:15:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:15:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:15:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:15:53 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:15:54 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:15:54 INFO input.FileInputFormat: Total input paths to process : 10
14/06/11 02:15:54 INFO mapreduce.JobSubmitter: number of splits:10
14/06/11 02:15:54 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 02:15:54 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 02:15:54 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 02:15:54 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 02:15:54 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 02:15:54 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 02:15:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0025
14/06/11 02:15:55 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0025 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:15:55 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0025/
14/06/11 02:15:55 INFO mapreduce.Job: Running job: job_1402467816780_0025
14/06/11 02:16:03 INFO mapreduce.Job: Job job_1402467816780_0025 running in uber mode : false
14/06/11 02:16:03 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:16:24 INFO mapreduce.Job:  map 10% reduce 0%
14/06/11 02:16:25 INFO mapreduce.Job:  map 20% reduce 0%
14/06/11 02:16:28 INFO mapreduce.Job:  map 33% reduce 0%
14/06/11 02:16:36 INFO mapreduce.Job:  map 43% reduce 0%
14/06/11 02:16:37 INFO mapreduce.Job:  map 63% reduce 0%
14/06/11 02:16:39 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 02:16:40 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 02:16:44 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 02:26:24 INFO mapreduce.Job:  map 87% reduce 17%
14/06/11 02:26:26 INFO mapreduce.Job:  map 87% reduce 20%
14/06/11 02:26:31 INFO mapreduce.Job:  map 90% reduce 20%
14/06/11 02:26:32 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 02:31:09 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 02:31:17 INFO mapreduce.Job:  map 97% reduce 27%
14/06/11 02:31:18 INFO mapreduce.Job:  map 97% reduce 30%
14/06/11 02:31:20 INFO mapreduce.Job:  map 100% reduce 30%
14/06/11 02:31:21 INFO mapreduce.Job:  map 100% reduce 34%
14/06/11 02:31:22 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 02:31:23 INFO mapreduce.Job: Job job_1402467816780_0025 completed successfully
14/06/11 02:31:23 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=8356106
		FILE: Number of bytes written=17587802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34011
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=10
		Total time spent by all maps in occupied slots (ms)=4112584
		Total time spent by all reduces in occupied slots (ms)=895034
	Map-Reduce Framework
		Map input records=10
		Map output records=327690
		Map output bytes=7700720
		Map output materialized bytes=8356160
		Input split bytes=1011
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=8356160
		Reduce input records=327690
		Reduce output records=65535
		Spilled Records=655380
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=61818
		CPU time spent (ms)=1442160
		Physical memory (bytes) snapshot=2404052992
		Virtual memory (bytes) snapshot=9187581952
		Total committed heap usage (bytes)=1792475136
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 02:31:24 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:31:24 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:31:24 INFO input.FileInputFormat: Total input paths to process : 10
14/06/11 02:31:24 INFO mapreduce.JobSubmitter: number of splits:10
14/06/11 02:31:24 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 02:31:24 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 02:31:24 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 02:31:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0026
14/06/11 02:31:24 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0026 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:31:24 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0026/
14/06/11 02:31:24 INFO mapreduce.Job: Running job: job_1402467816780_0026
14/06/11 02:31:32 INFO mapreduce.Job: Job job_1402467816780_0026 running in uber mode : false
14/06/11 02:31:32 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:31:58 INFO mapreduce.Job:  map 20% reduce 0%
14/06/11 02:31:59 INFO mapreduce.Job:  map 27% reduce 0%
14/06/11 02:32:08 INFO mapreduce.Job:  map 33% reduce 0%
14/06/11 02:32:09 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 02:32:27 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 02:32:35 INFO mapreduce.Job:  map 80% reduce 0%
14/06/11 02:32:43 INFO mapreduce.Job:  map 80% reduce 13%
14/06/11 02:32:55 INFO mapreduce.Job:  map 83% reduce 13%
14/06/11 02:32:56 INFO mapreduce.Job:  map 90% reduce 13%
14/06/11 02:32:58 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 02:33:03 INFO mapreduce.Job:  map 93% reduce 23%
14/06/11 02:33:04 INFO mapreduce.Job:  map 100% reduce 27%
14/06/11 02:33:06 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 02:33:06 INFO mapreduce.Job: Job job_1402467816780_0026 completed successfully
14/06/11 02:33:06 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=16711626
		FILE: Number of bytes written=34313736
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34011
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=10
		Total time spent by all maps in occupied slots (ms)=741588
		Total time spent by all reduces in occupied slots (ms)=36879
	Map-Reduce Framework
		Map input records=10
		Map output records=655350
		Map output bytes=15400920
		Map output materialized bytes=16711680
		Input split bytes=1011
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=16711680
		Reduce input records=655350
		Reduce output records=1
		Spilled Records=1310700
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=6731
		CPU time spent (ms)=99450
		Physical memory (bytes) snapshot=2326896640
		Virtual memory (bytes) snapshot=9187160064
		Total committed heap usage (bytes)=1753481216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1034710
[MR2PhaseApriori] Phase 1 execution time: 932123
[MR2PhaseApriori] Phase 2 execution time: 102587
splits=10
columns=16
Wed, Jun 11, 2014  2:33:07 AM
Warning, this script only works for 1000 lines now
100
100
100
100
100
100
100
100
100
100
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:33:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:33:32 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 02:33:32 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:34:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:34:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:34:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:34:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:35:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:35:04 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:35:05 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:35:05 INFO input.FileInputFormat: Total input paths to process : 10
14/06/11 02:35:05 INFO mapreduce.JobSubmitter: number of splits:10
14/06/11 02:35:05 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 02:35:05 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 02:35:05 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 02:35:05 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 02:35:05 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 02:35:05 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 02:35:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0027
14/06/11 02:35:06 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0027 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:35:06 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0027/
14/06/11 02:35:06 INFO mapreduce.Job: Running job: job_1402467816780_0027
14/06/11 02:35:14 INFO mapreduce.Job: Job job_1402467816780_0027 running in uber mode : false
14/06/11 02:35:14 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:35:37 INFO mapreduce.Job:  map 20% reduce 0%
14/06/11 02:35:41 INFO mapreduce.Job:  map 33% reduce 0%
14/06/11 02:35:48 INFO mapreduce.Job:  map 43% reduce 0%
14/06/11 02:35:49 INFO mapreduce.Job:  map 63% reduce 0%
14/06/11 02:35:51 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 02:35:56 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 02:45:19 INFO mapreduce.Job:  map 87% reduce 17%
14/06/11 02:45:21 INFO mapreduce.Job:  map 90% reduce 17%
14/06/11 02:45:23 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 02:50:25 INFO mapreduce.Job:  map 93% reduce 23%
14/06/11 02:50:29 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 02:50:30 INFO mapreduce.Job:  map 97% reduce 27%
14/06/11 02:50:32 INFO mapreduce.Job:  map 97% reduce 30%
14/06/11 02:50:38 INFO mapreduce.Job:  map 100% reduce 30%
14/06/11 02:50:40 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 02:50:41 INFO mapreduce.Job: Job job_1402467816780_0027 completed successfully
14/06/11 02:50:42 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=8356106
		FILE: Number of bytes written=17587802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34011
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=10
		Total time spent by all maps in occupied slots (ms)=4089689
		Total time spent by all reduces in occupied slots (ms)=901103
	Map-Reduce Framework
		Map input records=10
		Map output records=327690
		Map output bytes=7700720
		Map output materialized bytes=8356160
		Input split bytes=1011
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=8356160
		Reduce input records=327690
		Reduce output records=65535
		Spilled Records=655380
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=55457
		CPU time spent (ms)=1427930
		Physical memory (bytes) snapshot=2443636736
		Virtual memory (bytes) snapshot=9187319808
		Total committed heap usage (bytes)=1831469056
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 02:50:42 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:50:42 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:50:42 INFO input.FileInputFormat: Total input paths to process : 10
14/06/11 02:50:42 INFO mapreduce.JobSubmitter: number of splits:10
14/06/11 02:50:42 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 02:50:42 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 02:50:42 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 02:50:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0028
14/06/11 02:50:42 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0028 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:50:42 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0028/
14/06/11 02:50:42 INFO mapreduce.Job: Running job: job_1402467816780_0028
14/06/11 02:50:50 INFO mapreduce.Job: Job job_1402467816780_0028 running in uber mode : false
14/06/11 02:50:50 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:51:17 INFO mapreduce.Job:  map 27% reduce 0%
14/06/11 02:51:27 INFO mapreduce.Job:  map 40% reduce 0%
14/06/11 02:51:28 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 02:51:47 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 02:51:53 INFO mapreduce.Job:  map 80% reduce 0%
14/06/11 02:52:02 INFO mapreduce.Job:  map 80% reduce 13%
14/06/11 02:52:15 INFO mapreduce.Job:  map 87% reduce 13%
14/06/11 02:52:16 INFO mapreduce.Job:  map 90% reduce 13%
14/06/11 02:52:17 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 02:52:22 INFO mapreduce.Job:  map 93% reduce 23%
14/06/11 02:52:23 INFO mapreduce.Job:  map 100% reduce 30%
14/06/11 02:52:25 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 02:52:25 INFO mapreduce.Job: Job job_1402467816780_0028 completed successfully
14/06/11 02:52:25 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=16711626
		FILE: Number of bytes written=34313736
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34011
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=10
		Total time spent by all maps in occupied slots (ms)=746598
		Total time spent by all reduces in occupied slots (ms)=35267
	Map-Reduce Framework
		Map input records=10
		Map output records=655350
		Map output bytes=15400920
		Map output materialized bytes=16711680
		Input split bytes=1011
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=16711680
		Reduce input records=655350
		Reduce output records=1
		Spilled Records=1310700
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=6781
		CPU time spent (ms)=100130
		Physical memory (bytes) snapshot=2296758272
		Virtual memory (bytes) snapshot=9187590144
		Total committed heap usage (bytes)=1714487296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1042653
[MR2PhaseApriori] Phase 1 execution time: 939132
[MR2PhaseApriori] Phase 2 execution time: 103521
splits=10
columns=16
Wed, Jun 11, 2014  2:52:26 AM
Warning, this script only works for 1000 lines now
100
100
100
100
100
100
100
100
100
100
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:52:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:52:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 02:52:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:53:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:53:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:53:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:53:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 02:54:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 02:54:23 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:54:24 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 02:54:24 INFO input.FileInputFormat: Total input paths to process : 10
14/06/11 02:54:24 INFO mapreduce.JobSubmitter: number of splits:10
14/06/11 02:54:24 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 02:54:24 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 02:54:24 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 02:54:24 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 02:54:24 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 02:54:24 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 02:54:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0029
14/06/11 02:54:25 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0029 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 02:54:25 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0029/
14/06/11 02:54:25 INFO mapreduce.Job: Running job: job_1402467816780_0029
14/06/11 02:54:33 INFO mapreduce.Job: Job job_1402467816780_0029 running in uber mode : false
14/06/11 02:54:33 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 02:54:56 INFO mapreduce.Job:  map 20% reduce 0%
14/06/11 02:55:00 INFO mapreduce.Job:  map 33% reduce 0%
14/06/11 02:55:06 INFO mapreduce.Job:  map 53% reduce 0%
14/06/11 02:55:07 INFO mapreduce.Job:  map 63% reduce 0%
14/06/11 02:55:10 INFO mapreduce.Job:  map 83% reduce 0%
14/06/11 02:55:14 INFO mapreduce.Job:  map 83% reduce 17%
14/06/11 03:04:55 INFO mapreduce.Job:  map 87% reduce 17%
14/06/11 03:04:56 INFO mapreduce.Job:  map 90% reduce 17%
14/06/11 03:04:57 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 03:09:44 INFO mapreduce.Job:  map 93% reduce 23%
14/06/11 03:09:45 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 03:09:51 INFO mapreduce.Job:  map 97% reduce 27%
14/06/11 03:09:54 INFO mapreduce.Job:  map 100% reduce 30%
14/06/11 03:09:57 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 03:09:58 INFO mapreduce.Job: Job job_1402467816780_0029 completed successfully
14/06/11 03:09:58 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=8356106
		FILE: Number of bytes written=17587802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34011
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=10
		Total time spent by all maps in occupied slots (ms)=4113947
		Total time spent by all reduces in occupied slots (ms)=899069
	Map-Reduce Framework
		Map input records=10
		Map output records=327690
		Map output bytes=7700720
		Map output materialized bytes=8356160
		Input split bytes=1011
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=8356160
		Reduce input records=327690
		Reduce output records=65535
		Spilled Records=655380
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=58860
		CPU time spent (ms)=1434840
		Physical memory (bytes) snapshot=2483261440
		Virtual memory (bytes) snapshot=9187295232
		Total committed heap usage (bytes)=1870462976
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 03:09:58 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:09:58 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 03:09:58 INFO input.FileInputFormat: Total input paths to process : 10
14/06/11 03:09:58 INFO mapreduce.JobSubmitter: number of splits:10
14/06/11 03:09:58 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 03:09:58 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 03:09:58 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 03:09:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0030
14/06/11 03:09:58 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0030 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:09:58 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0030/
14/06/11 03:09:58 INFO mapreduce.Job: Running job: job_1402467816780_0030
14/06/11 03:10:07 INFO mapreduce.Job: Job job_1402467816780_0030 running in uber mode : false
14/06/11 03:10:07 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 03:10:33 INFO mapreduce.Job:  map 27% reduce 0%
14/06/11 03:10:43 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 03:11:02 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 03:11:10 INFO mapreduce.Job:  map 80% reduce 0%
14/06/11 03:11:18 INFO mapreduce.Job:  map 80% reduce 13%
14/06/11 03:11:31 INFO mapreduce.Job:  map 90% reduce 13%
14/06/11 03:11:33 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 03:11:38 INFO mapreduce.Job:  map 93% reduce 23%
14/06/11 03:11:39 INFO mapreduce.Job:  map 100% reduce 33%
14/06/11 03:11:41 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 03:11:41 INFO mapreduce.Job: Job job_1402467816780_0030 completed successfully
14/06/11 03:11:41 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=16711626
		FILE: Number of bytes written=34313736
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34011
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=10
		Total time spent by all maps in occupied slots (ms)=748551
		Total time spent by all reduces in occupied slots (ms)=36375
	Map-Reduce Framework
		Map input records=10
		Map output records=655350
		Map output bytes=15400920
		Map output materialized bytes=16711680
		Input split bytes=1011
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=16711680
		Reduce input records=655350
		Reduce output records=1
		Spilled Records=1310700
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=7011
		CPU time spent (ms)=100230
		Physical memory (bytes) snapshot=2298040320
		Virtual memory (bytes) snapshot=9186783232
		Total committed heap usage (bytes)=1714487296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1039847
[MR2PhaseApriori] Phase 1 execution time: 936346
[MR2PhaseApriori] Phase 2 execution time: 103501
splits=10
columns=16
Wed, Jun 11, 2014  3:11:43 AM
12
Warning, this script only works for 1000 lines now
83
83
83
83
83
83
83
83
83
83
83
83
4
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:12:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 03:12:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 03:12:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:12:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 03:12:41 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:12:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:13:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:13:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 03:13:40 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:13:41 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 03:13:41 INFO input.FileInputFormat: Total input paths to process : 13
14/06/11 03:13:41 INFO mapreduce.JobSubmitter: number of splits:13
14/06/11 03:13:41 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 03:13:41 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 03:13:41 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 03:13:41 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 03:13:41 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 03:13:41 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 03:13:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0031
14/06/11 03:13:42 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0031 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:13:42 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0031/
14/06/11 03:13:42 INFO mapreduce.Job: Running job: job_1402467816780_0031
14/06/11 03:13:49 INFO mapreduce.Job: Job job_1402467816780_0031 running in uber mode : false
14/06/11 03:13:49 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 03:14:18 INFO mapreduce.Job:  map 15% reduce 0%
14/06/11 03:14:21 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 03:14:33 INFO mapreduce.Job:  map 46% reduce 0%
14/06/11 03:14:34 INFO mapreduce.Job:  map 54% reduce 0%
14/06/11 03:14:35 INFO mapreduce.Job:  map 72% reduce 0%
14/06/11 03:14:38 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 03:14:39 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 03:14:40 INFO mapreduce.Job:  map 82% reduce 15%
14/06/11 03:28:57 INFO mapreduce.Job:  map 85% reduce 15%
14/06/11 03:28:59 INFO mapreduce.Job:  map 85% reduce 18%
14/06/11 03:29:17 INFO mapreduce.Job:  map 87% reduce 18%
14/06/11 03:29:19 INFO mapreduce.Job:  map 90% reduce 18%
14/06/11 03:29:20 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 03:34:11 INFO mapreduce.Job:  map 92% reduce 23%
14/06/11 03:34:13 INFO mapreduce.Job:  map 92% reduce 26%
14/06/11 03:34:17 INFO mapreduce.Job:  map 95% reduce 26%
14/06/11 03:34:19 INFO mapreduce.Job:  map 95% reduce 28%
14/06/11 03:34:25 INFO mapreduce.Job:  map 97% reduce 28%
14/06/11 03:34:26 INFO mapreduce.Job:  map 100% reduce 28%
14/06/11 03:34:28 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 03:34:29 INFO mapreduce.Job: Job job_1402467816780_0031 completed successfully
14/06/11 03:34:29 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=11698513
		FILE: Number of bytes written=24511410
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34317
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=13
		Launched reduce tasks=1
		Data-local map tasks=13
		Total time spent by all maps in occupied slots (ms)=7891368
		Total time spent by all reduces in occupied slots (ms)=1207527
	Map-Reduce Framework
		Map input records=13
		Map output records=458764
		Map output bytes=10780979
		Map output materialized bytes=11698585
		Input split bytes=1317
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=11698585
		Reduce input records=458764
		Reduce output records=65535
		Spilled Records=917528
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=105189
		CPU time spent (ms)=2025130
		Physical memory (bytes) snapshot=3071467520
		Virtual memory (bytes) snapshot=11691085824
		Total committed heap usage (bytes)=2283798528
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 03:34:29 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:34:29 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 03:34:29 INFO input.FileInputFormat: Total input paths to process : 13
14/06/11 03:34:29 INFO mapreduce.JobSubmitter: number of splits:13
14/06/11 03:34:29 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 03:34:29 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 03:34:29 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 03:34:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0032
14/06/11 03:34:29 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0032 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:34:29 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0032/
14/06/11 03:34:29 INFO mapreduce.Job: Running job: job_1402467816780_0032
14/06/11 03:34:38 INFO mapreduce.Job: Job job_1402467816780_0032 running in uber mode : false
14/06/11 03:34:38 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 03:35:13 INFO mapreduce.Job:  map 26% reduce 0%
14/06/11 03:35:14 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 03:35:18 INFO mapreduce.Job:  map 46% reduce 0%
14/06/11 03:35:19 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 03:35:26 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 03:35:54 INFO mapreduce.Job:  map 72% reduce 0%
14/06/11 03:35:55 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 03:35:58 INFO mapreduce.Job:  map 77% reduce 10%
14/06/11 03:36:01 INFO mapreduce.Job:  map 82% reduce 10%
14/06/11 03:36:02 INFO mapreduce.Job:  map 85% reduce 10%
14/06/11 03:36:04 INFO mapreduce.Job:  map 85% reduce 18%
14/06/11 03:36:05 INFO mapreduce.Job:  map 87% reduce 18%
14/06/11 03:36:07 INFO mapreduce.Job:  map 90% reduce 21%
14/06/11 03:36:10 INFO mapreduce.Job:  map 92% reduce 26%
14/06/11 03:36:11 INFO mapreduce.Job:  map 95% reduce 26%
14/06/11 03:36:13 INFO mapreduce.Job:  map 97% reduce 28%
14/06/11 03:36:14 INFO mapreduce.Job:  map 100% reduce 28%
14/06/11 03:36:16 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 03:36:16 INFO mapreduce.Job: Job job_1402467816780_0032 completed successfully
14/06/11 03:36:16 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=21725112
		FILE: Number of bytes written=44583564
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34317
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=13
		Launched reduce tasks=1
		Data-local map tasks=13
		Total time spent by all maps in occupied slots (ms)=1066211
		Total time spent by all reduces in occupied slots (ms)=46931
	Map-Reduce Framework
		Map input records=13
		Map output records=851955
		Map output bytes=20021196
		Map output materialized bytes=21725184
		Input split bytes=1317
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=21725184
		Reduce input records=851955
		Reduce output records=1
		Spilled Records=1703910
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=9667
		CPU time spent (ms)=107380
		Physical memory (bytes) snapshot=2938109952
		Virtual memory (bytes) snapshot=11690721280
		Total committed heap usage (bytes)=2205810688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1357952
[MR2PhaseApriori] Phase 1 execution time: 1250333
[MR2PhaseApriori] Phase 2 execution time: 107619
splits=12
columns=16
Wed, Jun 11, 2014  3:36:18 AM
Warning, this script only works for 1000 lines now
83
83
83
83
83
83
83
83
83
83
83
83
4
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:36:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 03:36:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 03:36:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:37:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 03:37:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:37:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:37:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 03:38:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 03:38:16 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:38:17 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 03:38:17 INFO input.FileInputFormat: Total input paths to process : 13
14/06/11 03:38:17 INFO mapreduce.JobSubmitter: number of splits:13
14/06/11 03:38:17 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 03:38:17 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 03:38:17 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 03:38:17 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 03:38:17 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 03:38:17 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 03:38:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0033
14/06/11 03:38:18 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0033 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:38:18 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0033/
14/06/11 03:38:18 INFO mapreduce.Job: Running job: job_1402467816780_0033
14/06/11 03:38:25 INFO mapreduce.Job: Job job_1402467816780_0033 running in uber mode : false
14/06/11 03:38:25 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 03:39:00 INFO mapreduce.Job:  map 23% reduce 0%
14/06/11 03:39:03 INFO mapreduce.Job:  map 38% reduce 0%
14/06/11 03:39:05 INFO mapreduce.Job:  map 54% reduce 0%
14/06/11 03:39:06 INFO mapreduce.Job:  map 62% reduce 0%
14/06/11 03:39:07 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 03:39:10 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 03:39:27 INFO mapreduce.Job:  map 82% reduce 15%
14/06/11 03:53:50 INFO mapreduce.Job:  map 85% reduce 15%
14/06/11 03:53:52 INFO mapreduce.Job:  map 87% reduce 15%
14/06/11 03:53:53 INFO mapreduce.Job:  map 87% reduce 21%
14/06/11 03:53:55 INFO mapreduce.Job:  map 90% reduce 21%
14/06/11 03:53:56 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 03:58:22 INFO mapreduce.Job:  map 92% reduce 23%
14/06/11 03:58:23 INFO mapreduce.Job:  map 92% reduce 26%
14/06/11 03:59:05 INFO mapreduce.Job:  map 95% reduce 26%
14/06/11 03:59:09 INFO mapreduce.Job:  map 95% reduce 28%
14/06/11 03:59:13 INFO mapreduce.Job:  map 97% reduce 28%
14/06/11 03:59:15 INFO mapreduce.Job:  map 97% reduce 31%
14/06/11 03:59:17 INFO mapreduce.Job:  map 100% reduce 31%
14/06/11 03:59:19 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 03:59:20 INFO mapreduce.Job: Job job_1402467816780_0033 completed successfully
14/06/11 03:59:20 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=11698513
		FILE: Number of bytes written=24511410
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34317
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=13
		Launched reduce tasks=1
		Data-local map tasks=13
		Total time spent by all maps in occupied slots (ms)=7904650
		Total time spent by all reduces in occupied slots (ms)=1217883
	Map-Reduce Framework
		Map input records=13
		Map output records=458764
		Map output bytes=10780979
		Map output materialized bytes=11698585
		Input split bytes=1317
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=11698585
		Reduce input records=458764
		Reduce output records=65535
		Spilled Records=917528
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=102236
		CPU time spent (ms)=2027640
		Physical memory (bytes) snapshot=3085848576
		Virtual memory (bytes) snapshot=11691208704
		Total committed heap usage (bytes)=2283798528
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 03:59:21 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:59:21 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 03:59:21 INFO input.FileInputFormat: Total input paths to process : 13
14/06/11 03:59:21 INFO mapreduce.JobSubmitter: number of splits:13
14/06/11 03:59:21 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 03:59:21 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 03:59:21 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 03:59:21 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0034
14/06/11 03:59:21 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0034 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 03:59:21 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0034/
14/06/11 03:59:21 INFO mapreduce.Job: Running job: job_1402467816780_0034
14/06/11 03:59:28 INFO mapreduce.Job: Job job_1402467816780_0034 running in uber mode : false
14/06/11 03:59:28 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 04:00:06 INFO mapreduce.Job:  map 26% reduce 0%
14/06/11 04:00:09 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 04:00:10 INFO mapreduce.Job:  map 36% reduce 0%
14/06/11 04:00:11 INFO mapreduce.Job:  map 56% reduce 0%
14/06/11 04:00:14 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 04:00:18 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 04:00:48 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 04:00:49 INFO mapreduce.Job:  map 77% reduce 5%
14/06/11 04:00:52 INFO mapreduce.Job:  map 77% reduce 10%
14/06/11 04:00:54 INFO mapreduce.Job:  map 80% reduce 10%
14/06/11 04:00:55 INFO mapreduce.Job:  map 85% reduce 10%
14/06/11 04:00:57 INFO mapreduce.Job:  map 87% reduce 10%
14/06/11 04:00:58 INFO mapreduce.Job:  map 90% reduce 18%
14/06/11 04:01:01 INFO mapreduce.Job:  map 92% reduce 26%
14/06/11 04:01:02 INFO mapreduce.Job:  map 95% reduce 26%
14/06/11 04:01:04 INFO mapreduce.Job:  map 95% reduce 28%
14/06/11 04:01:05 INFO mapreduce.Job:  map 100% reduce 28%
14/06/11 04:01:07 INFO mapreduce.Job:  map 100% reduce 68%
14/06/11 04:01:10 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 04:01:10 INFO mapreduce.Job: Job job_1402467816780_0034 completed successfully
14/06/11 04:01:10 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=21725112
		FILE: Number of bytes written=44583564
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34317
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=13
		Launched reduce tasks=1
		Data-local map tasks=13
		Total time spent by all maps in occupied slots (ms)=1072779
		Total time spent by all reduces in occupied slots (ms)=49242
	Map-Reduce Framework
		Map input records=13
		Map output records=851955
		Map output bytes=20021196
		Map output materialized bytes=21725184
		Input split bytes=1317
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=21725184
		Reduce input records=851955
		Reduce output records=1
		Spilled Records=1703910
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=9494
		CPU time spent (ms)=107630
		Physical memory (bytes) snapshot=2957029376
		Virtual memory (bytes) snapshot=11691327488
		Total committed heap usage (bytes)=2205810688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1375720
[MR2PhaseApriori] Phase 1 execution time: 1266044
[MR2PhaseApriori] Phase 2 execution time: 109676
splits=12
columns=16
Wed, Jun 11, 2014  4:01:11 AM
Warning, this script only works for 1000 lines now
83
83
83
83
83
83
83
83
83
83
83
83
4
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:01:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 04:01:37 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 04:01:37 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:02:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 04:02:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:02:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:02:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:03:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 04:03:09 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 04:03:09 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 04:03:10 INFO input.FileInputFormat: Total input paths to process : 13
14/06/11 04:03:10 INFO mapreduce.JobSubmitter: number of splits:13
14/06/11 04:03:10 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 04:03:10 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 04:03:10 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 04:03:10 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 04:03:10 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 04:03:10 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 04:03:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0035
14/06/11 04:03:10 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0035 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 04:03:10 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0035/
14/06/11 04:03:10 INFO mapreduce.Job: Running job: job_1402467816780_0035
14/06/11 04:03:18 INFO mapreduce.Job: Job job_1402467816780_0035 running in uber mode : false
14/06/11 04:03:18 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 04:03:51 INFO mapreduce.Job:  map 8% reduce 0%
14/06/11 04:03:52 INFO mapreduce.Job:  map 23% reduce 0%
14/06/11 04:03:54 INFO mapreduce.Job:  map 28% reduce 0%
14/06/11 04:03:55 INFO mapreduce.Job:  map 38% reduce 0%
14/06/11 04:03:57 INFO mapreduce.Job:  map 54% reduce 0%
14/06/11 04:03:59 INFO mapreduce.Job:  map 72% reduce 0%
14/06/11 04:04:02 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 04:04:03 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 04:04:18 INFO mapreduce.Job:  map 82% reduce 15%
14/06/11 04:18:26 INFO mapreduce.Job:  map 85% reduce 15%
14/06/11 04:18:29 INFO mapreduce.Job:  map 85% reduce 18%
14/06/11 04:18:34 INFO mapreduce.Job:  map 87% reduce 18%
14/06/11 04:18:35 INFO mapreduce.Job:  map 90% reduce 18%
14/06/11 04:18:38 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 04:23:00 INFO mapreduce.Job:  map 92% reduce 23%
14/06/11 04:23:01 INFO mapreduce.Job:  map 92% reduce 26%
14/06/11 04:23:41 INFO mapreduce.Job:  map 95% reduce 26%
14/06/11 04:23:43 INFO mapreduce.Job:  map 95% reduce 28%
14/06/11 04:23:59 INFO mapreduce.Job:  map 97% reduce 28%
14/06/11 04:24:01 INFO mapreduce.Job:  map 100% reduce 28%
14/06/11 04:24:02 INFO mapreduce.Job:  map 100% reduce 67%
14/06/11 04:24:03 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 04:24:03 INFO mapreduce.Job: Job job_1402467816780_0035 completed successfully
14/06/11 04:24:04 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=11698513
		FILE: Number of bytes written=24511410
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34317
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=13
		Launched reduce tasks=1
		Data-local map tasks=13
		Total time spent by all maps in occupied slots (ms)=7823535
		Total time spent by all reduces in occupied slots (ms)=1210190
	Map-Reduce Framework
		Map input records=13
		Map output records=458764
		Map output bytes=10780979
		Map output materialized bytes=11698585
		Input split bytes=1317
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=11698585
		Reduce input records=458764
		Reduce output records=65535
		Spilled Records=917528
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=92849
		CPU time spent (ms)=2012280
		Physical memory (bytes) snapshot=3147862016
		Virtual memory (bytes) snapshot=11690926080
		Total committed heap usage (bytes)=2361786368
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 04:24:04 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 04:24:04 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 04:24:04 INFO input.FileInputFormat: Total input paths to process : 13
14/06/11 04:24:04 INFO mapreduce.JobSubmitter: number of splits:13
14/06/11 04:24:04 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 04:24:04 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 04:24:04 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 04:24:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0036
14/06/11 04:24:04 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0036 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 04:24:04 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0036/
14/06/11 04:24:04 INFO mapreduce.Job: Running job: job_1402467816780_0036
14/06/11 04:24:12 INFO mapreduce.Job: Job job_1402467816780_0036 running in uber mode : false
14/06/11 04:24:12 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 04:24:49 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 04:24:54 INFO mapreduce.Job:  map 62% reduce 0%
14/06/11 04:24:57 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 04:25:02 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 04:25:29 INFO mapreduce.Job:  map 74% reduce 0%
14/06/11 04:25:30 INFO mapreduce.Job:  map 77% reduce 0%
14/06/11 04:25:32 INFO mapreduce.Job:  map 77% reduce 10%
14/06/11 04:25:37 INFO mapreduce.Job:  map 85% reduce 10%
14/06/11 04:25:38 INFO mapreduce.Job:  map 85% reduce 18%
14/06/11 04:25:41 INFO mapreduce.Job:  map 87% reduce 18%
14/06/11 04:25:42 INFO mapreduce.Job:  map 90% reduce 18%
14/06/11 04:25:44 INFO mapreduce.Job:  map 90% reduce 23%
14/06/11 04:25:45 INFO mapreduce.Job:  map 92% reduce 23%
14/06/11 04:25:46 INFO mapreduce.Job:  map 95% reduce 23%
14/06/11 04:25:47 INFO mapreduce.Job:  map 95% reduce 28%
14/06/11 04:25:48 INFO mapreduce.Job:  map 97% reduce 28%
14/06/11 04:25:49 INFO mapreduce.Job:  map 100% reduce 28%
14/06/11 04:25:50 INFO mapreduce.Job:  map 100% reduce 68%
14/06/11 04:25:51 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 04:25:51 INFO mapreduce.Job: Job job_1402467816780_0036 completed successfully
14/06/11 04:25:51 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=21725112
		FILE: Number of bytes written=44583564
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34317
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=42
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=13
		Launched reduce tasks=1
		Data-local map tasks=13
		Total time spent by all maps in occupied slots (ms)=1066326
		Total time spent by all reduces in occupied slots (ms)=46971
	Map-Reduce Framework
		Map input records=13
		Map output records=851955
		Map output bytes=20021196
		Map output materialized bytes=21725184
		Input split bytes=1317
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=21725184
		Reduce input records=851955
		Reduce output records=1
		Spilled Records=1703910
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=9732
		CPU time spent (ms)=106740
		Physical memory (bytes) snapshot=2958311424
		Virtual memory (bytes) snapshot=11691765760
		Total committed heap usage (bytes)=2205810688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 1364109
[MR2PhaseApriori] Phase 1 execution time: 1256611
[MR2PhaseApriori] Phase 2 execution time: 107497
splits=12
columns=16
Wed, Jun 11, 2014  4:25:52 AM
14
Warning, this script only works for 1000 lines now
71
71
71
71
71
71
71
71
71
71
71
71
71
71
6
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:26:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 04:26:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 04:26:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:26:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 04:26:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:27:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:27:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 04:27:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 04:27:50 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 04:27:50 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 04:27:51 INFO input.FileInputFormat: Total input paths to process : 15
14/06/11 04:27:51 INFO mapreduce.JobSubmitter: number of splits:15
14/06/11 04:27:51 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 04:27:51 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 04:27:51 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 04:27:51 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 04:27:51 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 04:27:51 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 04:27:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0037
14/06/11 04:27:52 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0037 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 04:27:52 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0037/
14/06/11 04:27:52 INFO mapreduce.Job: Running job: job_1402467816780_0037
14/06/11 04:28:00 INFO mapreduce.Job: Job job_1402467816780_0037 running in uber mode : false
14/06/11 04:28:00 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 04:28:34 INFO mapreduce.Job:  map 13% reduce 0%
14/06/11 04:28:37 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 04:28:44 INFO mapreduce.Job:  map 51% reduce 0%
14/06/11 04:28:45 INFO mapreduce.Job:  map 64% reduce 0%
14/06/11 04:28:46 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 04:28:49 INFO mapreduce.Job:  map 78% reduce 0%
14/06/11 04:29:02 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 04:29:04 INFO mapreduce.Job:  map 82% reduce 16%
14/06/11 04:43:24 INFO mapreduce.Job:  map 84% reduce 16%
14/06/11 04:43:27 INFO mapreduce.Job:  map 84% reduce 18%
14/06/11 04:43:32 INFO mapreduce.Job:  map 87% reduce 18%
14/06/11 04:43:34 INFO mapreduce.Job:  map 87% reduce 20%
14/06/11 04:43:38 INFO mapreduce.Job:  map 89% reduce 20%
14/06/11 04:43:41 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 04:48:58 INFO mapreduce.Job: Task Id : attempt_1402467816780_0037_m_000002_0, Status : FAILED
AttemptID:attempt_1402467816780_0037_m_000002_0 Timed out after 1200 secs
14/06/11 04:48:58 INFO mapreduce.Job: Task Id : attempt_1402467816780_0037_m_000003_0, Status : FAILED
AttemptID:attempt_1402467816780_0037_m_000003_0 Timed out after 1200 secs
14/06/11 04:48:58 INFO mapreduce.Job: Task Id : attempt_1402467816780_0037_m_000004_0, Status : FAILED
AttemptID:attempt_1402467816780_0037_m_000004_0 Timed out after 1200 secs
14/06/11 04:48:58 INFO mapreduce.Job: Task Id : attempt_1402467816780_0037_m_000005_0, Status : FAILED
AttemptID:attempt_1402467816780_0037_m_000005_0 Timed out after 1200 secs
14/06/11 04:48:59 INFO mapreduce.Job:  map 71% reduce 22%
14/06/11 04:49:15 INFO mapreduce.Job:  map 76% reduce 22%
14/06/11 04:49:17 INFO mapreduce.Job:  map 80% reduce 22%
14/06/11 04:49:22 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 04:49:28 INFO mapreduce.Job: Task Id : attempt_1402467816780_0037_m_000014_0, Status : FAILED
AttemptID:attempt_1402467816780_0037_m_000014_0 Timed out after 1200 secs
14/06/11 04:49:29 INFO mapreduce.Job:  map 84% reduce 22%
14/06/11 04:49:49 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 04:54:11 INFO mapreduce.Job:  map 91% reduce 22%
14/06/11 04:54:13 INFO mapreduce.Job:  map 91% reduce 24%
14/06/11 05:08:12 INFO mapreduce.Job:  map 93% reduce 24%
14/06/11 05:08:15 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 05:08:34 INFO mapreduce.Job:  map 96% reduce 27%
14/06/11 05:08:36 INFO mapreduce.Job:  map 96% reduce 29%
14/06/11 05:08:43 INFO mapreduce.Job:  map 98% reduce 29%
14/06/11 05:08:45 INFO mapreduce.Job:  map 98% reduce 31%
14/06/11 05:08:48 INFO mapreduce.Job:  map 100% reduce 31%
14/06/11 05:08:52 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 05:08:52 INFO mapreduce.Job: Job job_1402467816780_0037 completed successfully
14/06/11 05:08:52 INFO mapreduce.Job: Counters: 46
	File System Counters
		FILE: Number of bytes read=13369733
		FILE: Number of bytes written=28013046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34521
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=5
		Launched map tasks=20
		Launched reduce tasks=1
		Other local map tasks=5
		Data-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=14315949
		Total time spent by all reduces in occupied slots (ms)=2414504
	Map-Reduce Framework
		Map input records=15
		Map output records=524302
		Map output bytes=12321123
		Map output materialized bytes=13369817
		Input split bytes=1521
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=13369817
		Reduce input records=524302
		Reduce output records=65535
		Spilled Records=1048604
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=112834
		CPU time spent (ms)=2287100
		Physical memory (bytes) snapshot=3556478976
		Virtual memory (bytes) snapshot=13359951872
		Total committed heap usage (bytes)=2650341376
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 05:08:52 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:08:52 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 05:08:52 INFO input.FileInputFormat: Total input paths to process : 15
14/06/11 05:08:52 INFO mapreduce.JobSubmitter: number of splits:15
14/06/11 05:08:52 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 05:08:52 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 05:08:52 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 05:08:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0038
14/06/11 05:08:52 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0038 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:08:52 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0038/
14/06/11 05:08:52 INFO mapreduce.Job: Running job: job_1402467816780_0038
14/06/11 05:09:00 INFO mapreduce.Job: Job job_1402467816780_0038 running in uber mode : false
14/06/11 05:09:00 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 05:09:38 INFO mapreduce.Job:  map 27% reduce 0%
14/06/11 05:09:47 INFO mapreduce.Job:  map 49% reduce 0%
14/06/11 05:09:51 INFO mapreduce.Job:  map 62% reduce 0%
14/06/11 05:10:12 INFO mapreduce.Job:  map 64% reduce 0%
14/06/11 05:10:15 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 05:10:24 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 05:10:25 INFO mapreduce.Job:  map 76% reduce 0%
14/06/11 05:10:33 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 05:10:35 INFO mapreduce.Job:  map 84% reduce 0%
14/06/11 05:10:36 INFO mapreduce.Job:  map 87% reduce 0%
14/06/11 05:10:37 INFO mapreduce.Job:  map 89% reduce 0%
14/06/11 05:10:38 INFO mapreduce.Job:  map 93% reduce 20%
14/06/11 05:10:41 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 05:10:42 INFO mapreduce.Job:  map 96% reduce 27%
14/06/11 05:10:43 INFO mapreduce.Job:  map 100% reduce 27%
14/06/11 05:10:44 INFO mapreduce.Job:  map 100% reduce 31%
14/06/11 05:10:46 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 05:10:46 INFO mapreduce.Job: Job job_1402467816780_0038 completed successfully
14/06/11 05:10:46 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=25067436
		FILE: Number of bytes written=51430116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34521
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=15
		Launched reduce tasks=1
		Data-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=1259148
		Total time spent by all reduces in occupied slots (ms)=29084
	Map-Reduce Framework
		Map input records=15
		Map output records=983025
		Map output bytes=23101380
		Map output materialized bytes=25067520
		Input split bytes=1521
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=25067520
		Reduce input records=983025
		Reduce output records=1
		Spilled Records=1966050
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=11132
		CPU time spent (ms)=111000
		Physical memory (bytes) snapshot=3382165504
		Virtual memory (bytes) snapshot=13359960064
		Total committed heap usage (bytes)=2533359616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 2578100
[MR2PhaseApriori] Phase 1 execution time: 2463538
[MR2PhaseApriori] Phase 2 execution time: 114562
splits=14
columns=16
Wed, Jun 11, 2014  5:10:47 AM
Warning, this script only works for 1000 lines now
71
71
71
71
71
71
71
71
71
71
71
71
71
71
6
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:11:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 05:11:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 05:11:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:11:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 05:11:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:11:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:12:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:12:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 05:12:45 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:12:45 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 05:12:46 INFO input.FileInputFormat: Total input paths to process : 15
14/06/11 05:12:46 INFO mapreduce.JobSubmitter: number of splits:15
14/06/11 05:12:46 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 05:12:46 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 05:12:46 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 05:12:46 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 05:12:46 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 05:12:46 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 05:12:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0039
14/06/11 05:12:47 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0039 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:12:47 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0039/
14/06/11 05:12:47 INFO mapreduce.Job: Running job: job_1402467816780_0039
14/06/11 05:12:54 INFO mapreduce.Job: Job job_1402467816780_0039 running in uber mode : false
14/06/11 05:12:54 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 05:13:28 INFO mapreduce.Job:  map 13% reduce 0%
14/06/11 05:13:31 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 05:13:38 INFO mapreduce.Job:  map 58% reduce 0%
14/06/11 05:13:39 INFO mapreduce.Job:  map 64% reduce 0%
14/06/11 05:13:40 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 05:13:43 INFO mapreduce.Job:  map 78% reduce 0%
14/06/11 05:13:58 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 05:13:59 INFO mapreduce.Job:  map 82% reduce 16%
14/06/11 05:28:19 INFO mapreduce.Job:  map 84% reduce 16%
14/06/11 05:28:21 INFO mapreduce.Job:  map 84% reduce 18%
14/06/11 05:28:23 INFO mapreduce.Job:  map 89% reduce 18%
14/06/11 05:28:24 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 05:33:53 INFO mapreduce.Job: Task Id : attempt_1402467816780_0039_m_000005_0, Status : FAILED
AttemptID:attempt_1402467816780_0039_m_000005_0 Timed out after 1200 secs
14/06/11 05:33:54 INFO mapreduce.Job: Task Id : attempt_1402467816780_0039_m_000003_0, Status : FAILED
AttemptID:attempt_1402467816780_0039_m_000003_0 Timed out after 1200 secs
14/06/11 05:33:54 INFO mapreduce.Job: Task Id : attempt_1402467816780_0039_m_000004_0, Status : FAILED
AttemptID:attempt_1402467816780_0039_m_000004_0 Timed out after 1200 secs
14/06/11 05:33:54 INFO mapreduce.Job: Task Id : attempt_1402467816780_0039_m_000002_0, Status : FAILED
AttemptID:attempt_1402467816780_0039_m_000002_0 Timed out after 1200 secs
14/06/11 05:33:55 INFO mapreduce.Job:  map 71% reduce 22%
14/06/11 05:34:10 INFO mapreduce.Job:  map 76% reduce 22%
14/06/11 05:34:13 INFO mapreduce.Job:  map 80% reduce 22%
14/06/11 05:34:17 INFO mapreduce.Job:  map 84% reduce 22%
14/06/11 05:34:18 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 05:34:24 INFO mapreduce.Job:  map 91% reduce 22%
14/06/11 05:34:24 INFO mapreduce.Job: Task Id : attempt_1402467816780_0039_m_000014_0, Status : FAILED
AttemptID:attempt_1402467816780_0039_m_000014_0 Timed out after 1200 secs
14/06/11 05:34:25 INFO mapreduce.Job:  map 84% reduce 22%
14/06/11 05:34:45 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 05:39:04 INFO mapreduce.Job:  map 91% reduce 22%
14/06/11 05:39:07 INFO mapreduce.Job:  map 91% reduce 24%
14/06/11 05:53:10 INFO mapreduce.Job:  map 93% reduce 24%
14/06/11 05:53:13 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 05:53:24 INFO mapreduce.Job:  map 96% reduce 27%
14/06/11 05:53:25 INFO mapreduce.Job:  map 96% reduce 29%
14/06/11 05:53:28 INFO mapreduce.Job:  map 98% reduce 29%
14/06/11 05:53:29 INFO mapreduce.Job:  map 100% reduce 29%
14/06/11 05:53:31 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 05:53:32 INFO mapreduce.Job: Job job_1402467816780_0039 completed successfully
14/06/11 05:53:32 INFO mapreduce.Job: Counters: 46
	File System Counters
		FILE: Number of bytes read=13369733
		FILE: Number of bytes written=28013046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34521
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=5
		Launched map tasks=20
		Launched reduce tasks=1
		Other local map tasks=5
		Data-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=14274710
		Total time spent by all reduces in occupied slots (ms)=2399586
	Map-Reduce Framework
		Map input records=15
		Map output records=524302
		Map output bytes=12321123
		Map output materialized bytes=13369817
		Input split bytes=1521
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=13369817
		Reduce input records=524302
		Reduce output records=65535
		Spilled Records=1048604
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=116064
		CPU time spent (ms)=2298540
		Physical memory (bytes) snapshot=3533344768
		Virtual memory (bytes) snapshot=13360209920
		Total committed heap usage (bytes)=2611347456
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 05:53:32 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:53:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 05:53:32 INFO input.FileInputFormat: Total input paths to process : 15
14/06/11 05:53:32 INFO mapreduce.JobSubmitter: number of splits:15
14/06/11 05:53:32 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 05:53:32 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 05:53:32 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 05:53:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0040
14/06/11 05:53:32 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0040 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:53:32 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0040/
14/06/11 05:53:32 INFO mapreduce.Job: Running job: job_1402467816780_0040
14/06/11 05:53:40 INFO mapreduce.Job: Job job_1402467816780_0040 running in uber mode : false
14/06/11 05:53:40 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 05:54:17 INFO mapreduce.Job:  map 27% reduce 0%
14/06/11 05:54:26 INFO mapreduce.Job:  map 40% reduce 0%
14/06/11 05:54:30 INFO mapreduce.Job:  map 62% reduce 0%
14/06/11 05:54:52 INFO mapreduce.Job:  map 64% reduce 0%
14/06/11 05:54:54 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 05:55:03 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 05:55:05 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 05:55:06 INFO mapreduce.Job:  map 76% reduce 0%
14/06/11 05:55:13 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 05:55:15 INFO mapreduce.Job:  map 84% reduce 0%
14/06/11 05:55:17 INFO mapreduce.Job:  map 89% reduce 18%
14/06/11 05:55:18 INFO mapreduce.Job:  map 93% reduce 18%
14/06/11 05:55:20 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 05:55:21 INFO mapreduce.Job:  map 96% reduce 27%
14/06/11 05:55:22 INFO mapreduce.Job:  map 100% reduce 27%
14/06/11 05:55:23 INFO mapreduce.Job:  map 100% reduce 31%
14/06/11 05:55:25 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 05:55:26 INFO mapreduce.Job: Job job_1402467816780_0040 completed successfully
14/06/11 05:55:26 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=25067436
		FILE: Number of bytes written=51430116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34521
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=15
		Launched reduce tasks=1
		Data-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=1265605
		Total time spent by all reduces in occupied slots (ms)=30200
	Map-Reduce Framework
		Map input records=15
		Map output records=983025
		Map output bytes=23101380
		Map output materialized bytes=25067520
		Input split bytes=1521
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=25067520
		Reduce input records=983025
		Reduce output records=1
		Spilled Records=1966050
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=11216
		CPU time spent (ms)=111040
		Physical memory (bytes) snapshot=3385593856
		Virtual memory (bytes) snapshot=13359890432
		Total committed heap usage (bytes)=2533359616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 2563149
[MR2PhaseApriori] Phase 1 execution time: 2448570
[MR2PhaseApriori] Phase 2 execution time: 114579
splits=14
columns=16
Wed, Jun 11, 2014  5:55:28 AM
Warning, this script only works for 1000 lines now
71
71
71
71
71
71
71
71
71
71
71
71
71
71
6
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:55:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 05:55:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 05:55:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:56:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 05:56:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:56:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:56:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 05:57:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 05:57:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:57:26 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 05:57:26 INFO input.FileInputFormat: Total input paths to process : 15
14/06/11 05:57:26 INFO mapreduce.JobSubmitter: number of splits:15
14/06/11 05:57:26 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 05:57:26 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 05:57:26 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 05:57:26 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 05:57:26 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 05:57:26 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 05:57:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0041
14/06/11 05:57:27 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0041 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 05:57:27 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0041/
14/06/11 05:57:27 INFO mapreduce.Job: Running job: job_1402467816780_0041
14/06/11 05:57:35 INFO mapreduce.Job: Job job_1402467816780_0041 running in uber mode : false
14/06/11 05:57:35 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 05:58:07 INFO mapreduce.Job:  map 7% reduce 0%
14/06/11 05:58:09 INFO mapreduce.Job:  map 13% reduce 0%
14/06/11 05:58:12 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 05:58:18 INFO mapreduce.Job:  map 38% reduce 0%
14/06/11 05:58:20 INFO mapreduce.Job:  map 64% reduce 0%
14/06/11 05:58:21 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 05:58:24 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 05:58:25 INFO mapreduce.Job:  map 78% reduce 0%
14/06/11 05:58:36 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 05:58:38 INFO mapreduce.Job:  map 82% reduce 16%
14/06/11 06:13:17 INFO mapreduce.Job:  map 84% reduce 16%
14/06/11 06:13:21 INFO mapreduce.Job:  map 84% reduce 18%
14/06/11 06:13:25 INFO mapreduce.Job:  map 87% reduce 18%
14/06/11 06:13:26 INFO mapreduce.Job:  map 89% reduce 18%
14/06/11 06:13:27 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 06:18:34 INFO mapreduce.Job: Task Id : attempt_1402467816780_0041_m_000005_0, Status : FAILED
AttemptID:attempt_1402467816780_0041_m_000005_0 Timed out after 1200 secs
14/06/11 06:18:34 INFO mapreduce.Job: Task Id : attempt_1402467816780_0041_m_000004_0, Status : FAILED
AttemptID:attempt_1402467816780_0041_m_000004_0 Timed out after 1200 secs
14/06/11 06:18:34 INFO mapreduce.Job: Task Id : attempt_1402467816780_0041_m_000002_0, Status : FAILED
AttemptID:attempt_1402467816780_0041_m_000002_0 Timed out after 1200 secs
14/06/11 06:18:34 INFO mapreduce.Job: Task Id : attempt_1402467816780_0041_m_000003_0, Status : FAILED
AttemptID:attempt_1402467816780_0041_m_000003_0 Timed out after 1200 secs
14/06/11 06:18:35 INFO mapreduce.Job:  map 71% reduce 22%
14/06/11 06:18:50 INFO mapreduce.Job:  map 76% reduce 22%
14/06/11 06:18:52 INFO mapreduce.Job:  map 80% reduce 22%
14/06/11 06:18:55 INFO mapreduce.Job:  map 84% reduce 22%
14/06/11 06:18:57 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 06:19:03 INFO mapreduce.Job: Task Id : attempt_1402467816780_0041_m_000014_0, Status : FAILED
AttemptID:attempt_1402467816780_0041_m_000014_0 Timed out after 1200 secs
14/06/11 06:19:04 INFO mapreduce.Job:  map 84% reduce 22%
14/06/11 06:19:22 INFO mapreduce.Job:  map 89% reduce 22%
14/06/11 06:28:28 INFO mapreduce.Job:  map 91% reduce 22%
14/06/11 06:28:29 INFO mapreduce.Job:  map 91% reduce 24%
14/06/11 06:28:32 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 06:33:40 INFO mapreduce.Job:  map 96% reduce 27%
14/06/11 06:33:43 INFO mapreduce.Job:  map 96% reduce 29%
14/06/11 06:33:53 INFO mapreduce.Job:  map 98% reduce 29%
14/06/11 06:33:55 INFO mapreduce.Job:  map 98% reduce 31%
14/06/11 06:34:03 INFO mapreduce.Job:  map 100% reduce 31%
14/06/11 06:34:04 INFO mapreduce.Job:  map 100% reduce 68%
14/06/11 06:34:05 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 06:34:06 INFO mapreduce.Job: Job job_1402467816780_0041 completed successfully
14/06/11 06:34:07 INFO mapreduce.Job: Counters: 46
	File System Counters
		FILE: Number of bytes read=13369733
		FILE: Number of bytes written=28013046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34521
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=5
		Launched map tasks=20
		Launched reduce tasks=1
		Other local map tasks=5
		Data-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=13296733
		Total time spent by all reduces in occupied slots (ms)=2154651
	Map-Reduce Framework
		Map input records=15
		Map output records=524302
		Map output bytes=12321123
		Map output materialized bytes=13369817
		Input split bytes=1521
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=13369817
		Reduce input records=524302
		Reduce output records=65535
		Spilled Records=1048604
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=113348
		CPU time spent (ms)=2330470
		Physical memory (bytes) snapshot=3551883264
		Virtual memory (bytes) snapshot=13359857664
		Total committed heap usage (bytes)=2650341376
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/11 06:34:07 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 06:34:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 06:34:07 INFO input.FileInputFormat: Total input paths to process : 15
14/06/11 06:34:07 INFO mapreduce.JobSubmitter: number of splits:15
14/06/11 06:34:07 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/11 06:34:07 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/11 06:34:07 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/11 06:34:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0042
14/06/11 06:34:07 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0042 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 06:34:07 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0042/
14/06/11 06:34:07 INFO mapreduce.Job: Running job: job_1402467816780_0042
14/06/11 06:34:14 INFO mapreduce.Job: Job job_1402467816780_0042 running in uber mode : false
14/06/11 06:34:14 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 06:34:52 INFO mapreduce.Job:  map 27% reduce 0%
14/06/11 06:35:01 INFO mapreduce.Job:  map 31% reduce 0%
14/06/11 06:35:02 INFO mapreduce.Job:  map 44% reduce 0%
14/06/11 06:35:05 INFO mapreduce.Job:  map 62% reduce 0%
14/06/11 06:35:27 INFO mapreduce.Job:  map 64% reduce 0%
14/06/11 06:35:28 INFO mapreduce.Job:  map 67% reduce 0%
14/06/11 06:35:38 INFO mapreduce.Job:  map 71% reduce 0%
14/06/11 06:35:39 INFO mapreduce.Job:  map 73% reduce 0%
14/06/11 06:35:40 INFO mapreduce.Job:  map 76% reduce 0%
14/06/11 06:35:48 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 06:35:51 INFO mapreduce.Job:  map 89% reduce 0%
14/06/11 06:35:52 INFO mapreduce.Job:  map 91% reduce 20%
14/06/11 06:35:53 INFO mapreduce.Job:  map 93% reduce 20%
14/06/11 06:35:55 INFO mapreduce.Job:  map 93% reduce 27%
14/06/11 06:35:56 INFO mapreduce.Job:  map 96% reduce 27%
14/06/11 06:35:57 INFO mapreduce.Job:  map 100% reduce 27%
14/06/11 06:35:58 INFO mapreduce.Job:  map 100% reduce 31%
14/06/11 06:36:00 INFO mapreduce.Job:  map 100% reduce 100%
14/06/11 06:36:00 INFO mapreduce.Job: Job job_1402467816780_0042 completed successfully
14/06/11 06:36:00 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=25067436
		FILE: Number of bytes written=51430116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34521
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=15
		Launched reduce tasks=1
		Data-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=1258013
		Total time spent by all reduces in occupied slots (ms)=29022
	Map-Reduce Framework
		Map input records=15
		Map output records=983025
		Map output bytes=23101380
		Map output materialized bytes=25067520
		Input split bytes=1521
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=25067520
		Reduce input records=983025
		Reduce output records=1
		Spilled Records=1966050
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=11219
		CPU time spent (ms)=111130
		Physical memory (bytes) snapshot=3385024512
		Virtual memory (bytes) snapshot=13360414720
		Total committed heap usage (bytes)=2533359616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 2316771
[MR2PhaseApriori] Phase 1 execution time: 2203215
[MR2PhaseApriori] Phase 2 execution time: 113556
splits=14
columns=16
Wed, Jun 11, 2014  6:36:01 AM
16
Warning, this script only works for 1000 lines now
62
62
62
62
62
62
62
62
62
62
62
62
62
62
62
62
8
columns=16
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1686) (out= 976)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 06:36:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 06:36:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/11 06:36:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 06:36:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 06:37:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 06:37:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 06:37:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/11 06:37:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/11 06:37:59 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 06:38:00 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/11 06:38:00 INFO input.FileInputFormat: Total input paths to process : 17
14/06/11 06:38:00 INFO mapreduce.JobSubmitter: number of splits:17
14/06/11 06:38:00 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/11 06:38:00 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/11 06:38:00 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/11 06:38:00 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/11 06:38:00 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/11 06:38:00 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/11 06:38:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402467816780_0043
14/06/11 06:38:01 INFO impl.YarnClientImpl: Submitted application application_1402467816780_0043 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/11 06:38:01 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402467816780_0043/
14/06/11 06:38:01 INFO mapreduce.Job: Running job: job_1402467816780_0043
14/06/11 06:38:08 INFO mapreduce.Job: Job job_1402467816780_0043 running in uber mode : false
14/06/11 06:38:08 INFO mapreduce.Job:  map 0% reduce 0%
14/06/11 06:38:42 INFO mapreduce.Job:  map 6% reduce 0%
14/06/11 06:38:43 INFO mapreduce.Job:  map 18% reduce 0%
14/06/11 06:38:46 INFO mapreduce.Job:  map 29% reduce 0%
14/06/11 06:38:52 INFO mapreduce.Job:  map 35% reduce 0%
14/06/11 06:38:53 INFO mapreduce.Job:  map 53% reduce 0%
14/06/11 06:38:55 INFO mapreduce.Job:  map 61% reduce 0%
14/06/11 06:38:58 INFO mapreduce.Job:  map 65% reduce 0%
14/06/11 06:38:59 INFO mapreduce.Job:  map 69% reduce 0%
14/06/11 06:39:10 INFO mapreduce.Job:  map 75% reduce 0%
14/06/11 06:39:12 INFO mapreduce.Job:  map 78% reduce 0%
14/06/11 06:39:13 INFO mapreduce.Job:  map 82% reduce 0%
14/06/11 06:39:16 INFO mapreduce.Job:  map 82% reduce 16%
14/06/11 06:58:41 INFO mapreduce.Job:  map 86% reduce 18%
14/06/11 06:58:44 INFO mapreduce.Job:  map 88% reduce 20%
14/06/11 06:58:46 INFO mapreduce.Job:  map 90% reduce 20%
14/06/11 06:58:47 INFO mapreduce.Job:  map 90% reduce 24%
14/06/11 06:59:07 INFO mapreduce.Job: Task Id : attempt_1402467816780_0043_m_000005_0, Status : FAILED
AttemptID:attempt_1402467816780_0043_m_000005_0 Timed out after 1200 secs
14/06/11 06:59:07 INFO mapreduce.Job: Task Id : attempt_1402467816780_0043_m_000003_0, Status : FAILED
AttemptID:attempt_1402467816780_0043_m_000003_0 Timed out after 1200 secs
14/06/11 06:59:07 INFO mapreduce.Job: Task Id : attempt_1402467816780_0043_m_000004_0, Status : FAILED
AttemptID:attempt_1402467816780_0043_m_000004_0 Timed out after 1200 secs
14/06/11 06:59:08 INFO mapreduce.Job:  map 78% reduce 24%
14/06/11 06:59:23 INFO mapreduce.Job:  map 82% reduce 24%
14/06/11 06:59:26 INFO mapreduce.Job:  map 86% reduce 24%
14/06/11 06:59:27 INFO mapreduce.Job:  map 90% reduce 24%
14/06/11 06:59:37 INFO mapreduce.Job: Task Id : attempt_1402467816780_0043_m_000016_0, Status : FAILED
AttemptID:attempt_1402467816780_0043_m_000016_0 Timed out after 1200 secs
14/06/11 06:59:37 INFO mapreduce.Job: Task Id : attempt_1402467816780_0043_m_000014_0, Status : FAILED
AttemptID:attempt_1402467816780_0043_m_000014_0 Timed out after 1200 secs
14/06/11 06:59:38 INFO mapreduce.Job:  map 82% reduce 24%
14/06/11 06:59:53 INFO mapreduce.Job:  map 86% reduce 24%
14/06/11 06:59:56 INFO mapreduce.Job:  map 90% reduce 24%
