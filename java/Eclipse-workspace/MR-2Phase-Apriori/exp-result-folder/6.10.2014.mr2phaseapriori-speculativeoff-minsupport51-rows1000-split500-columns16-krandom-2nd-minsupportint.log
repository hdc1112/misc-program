1
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 241
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:55:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:55:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:55:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:56:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:56:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:56:45 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:56:46 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:56:46 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:56:47 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:56:47 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 15:56:47 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 15:56:47 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 15:56:47 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 15:56:47 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 15:56:47 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 15:56:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0001
14/06/10 15:56:48 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0001 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:56:48 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0001/
14/06/10 15:56:48 INFO mapreduce.Job: Running job: job_1402440802128_0001
14/06/10 15:56:58 INFO mapreduce.Job: Job job_1402440802128_0001 running in uber mode : false
14/06/10 15:56:58 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:57:10 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 15:57:15 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:57:26 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 16:02:14 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 16:02:15 INFO mapreduce.Job:  map 100% reduce 40%
14/06/10 16:02:16 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:02:16 INFO mapreduce.Job: Job job_1402440802128_0001 completed successfully
14/06/10 16:02:16 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=323021
		Total time spent by all reduces in occupied slots (ms)=302603
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6638
		CPU time spent (ms)=283910
		Physical memory (bytes) snapshot=582836224
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:02:16 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:02:16 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:02:16 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:02:16 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:02:16 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:02:16 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:02:16 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:02:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0002
14/06/10 16:02:17 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0002 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:02:17 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0002/
14/06/10 16:02:17 INFO mapreduce.Job: Running job: job_1402440802128_0002
14/06/10 16:02:28 INFO mapreduce.Job: Job job_1402440802128_0002 running in uber mode : false
14/06/10 16:02:28 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:02:45 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 16:03:59 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:04:00 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:04:09 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:04:09 INFO mapreduce.Job: Job job_1402440802128_0002 completed successfully
14/06/10 16:04:09 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=180081
		Total time spent by all reduces in occupied slots (ms)=6191
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2630
		CPU time spent (ms)=79810
		Physical memory (bytes) snapshot=546324480
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 445191
[MR2PhaseApriori] Phase 1 execution time: 332444
[MR2PhaseApriori] Phase 2 execution time: 112747
Tue, Jun 10, 2014  4:04:10 PM
2
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 250
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:04:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:04:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:04:35 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:05:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:05:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:05:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:05:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:06:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:06:08 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:06:08 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:06:09 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:06:09 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:06:09 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:06:09 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:06:09 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:06:09 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:06:09 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:06:09 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:06:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0003
14/06/10 16:06:09 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0003 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:06:09 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0003/
14/06/10 16:06:09 INFO mapreduce.Job: Running job: job_1402440802128_0003
14/06/10 16:06:18 INFO mapreduce.Job: Job job_1402440802128_0003 running in uber mode : false
14/06/10 16:06:18 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:06:29 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:06:37 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:06:38 INFO mapreduce.Job: Job job_1402440802128_0003 completed successfully
14/06/10 16:06:38 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19756
		Total time spent by all reduces in occupied slots (ms)=4812
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=329
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=551763968
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:06:39 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:06:39 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:06:39 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:06:39 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:06:39 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:06:39 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:06:39 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:06:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0004
14/06/10 16:06:39 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0004 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:06:39 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0004/
14/06/10 16:06:39 INFO mapreduce.Job: Running job: job_1402440802128_0004
14/06/10 16:06:47 INFO mapreduce.Job: Job job_1402440802128_0004 running in uber mode : false
14/06/10 16:06:47 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:07:00 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:07:08 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:07:08 INFO mapreduce.Job: Job job_1402440802128_0004 completed successfully
14/06/10 16:07:08 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19965
		Total time spent by all reduces in occupied slots (ms)=4886
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=418
		CPU time spent (ms)=1420
		Physical memory (bytes) snapshot=543248384
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 62154
[MR2PhaseApriori] Phase 1 execution time: 32802
[MR2PhaseApriori] Phase 2 execution time: 29352
Tue, Jun 10, 2014  4:07:09 PM
3
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 242
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:07:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:07:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:07:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:08:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:08:07 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:08:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:08:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:09:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:09:06 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:09:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:09:07 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:09:07 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:09:07 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:09:07 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:09:07 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:09:07 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:09:07 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:09:07 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:09:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0005
14/06/10 16:09:08 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0005 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:09:08 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0005/
14/06/10 16:09:08 INFO mapreduce.Job: Running job: job_1402440802128_0005
14/06/10 16:09:17 INFO mapreduce.Job: Job job_1402440802128_0005 running in uber mode : false
14/06/10 16:09:17 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:09:28 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 16:09:33 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:09:44 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 16:14:21 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 16:14:23 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:14:24 INFO mapreduce.Job: Job job_1402440802128_0005 completed successfully
14/06/10 16:14:24 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=311947
		Total time spent by all reduces in occupied slots (ms)=291381
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6961
		CPU time spent (ms)=285310
		Physical memory (bytes) snapshot=586682368
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:14:24 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:14:24 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:14:24 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:14:24 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:14:24 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:14:24 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:14:24 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:14:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0006
14/06/10 16:14:24 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0006 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:14:24 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0006/
14/06/10 16:14:24 INFO mapreduce.Job: Running job: job_1402440802128_0006
14/06/10 16:14:33 INFO mapreduce.Job: Job job_1402440802128_0006 running in uber mode : false
14/06/10 16:14:33 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:14:50 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 16:16:04 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:16:05 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:16:12 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:16:12 INFO mapreduce.Job: Job job_1402440802128_0006 completed successfully
14/06/10 16:16:12 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178910
		Total time spent by all reduces in occupied slots (ms)=5713
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2687
		CPU time spent (ms)=78370
		Physical memory (bytes) snapshot=541769728
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 427936
[MR2PhaseApriori] Phase 1 execution time: 319440
[MR2PhaseApriori] Phase 2 execution time: 108496
Tue, Jun 10, 2014  4:16:14 PM
4
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 248
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:16:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:16:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:16:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:17:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:17:12 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:17:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:17:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:18:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:18:11 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:18:12 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:18:12 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:18:12 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:18:12 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:18:12 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:18:12 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:18:12 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:18:12 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:18:12 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:18:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0007
14/06/10 16:18:13 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0007 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:18:13 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0007/
14/06/10 16:18:13 INFO mapreduce.Job: Running job: job_1402440802128_0007
14/06/10 16:18:21 INFO mapreduce.Job: Job job_1402440802128_0007 running in uber mode : false
14/06/10 16:18:21 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:18:33 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:18:41 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:18:42 INFO mapreduce.Job: Job job_1402440802128_0007 completed successfully
14/06/10 16:18:42 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19819
		Total time spent by all reduces in occupied slots (ms)=4839
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=324
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=548368384
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:18:42 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:18:42 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:18:42 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:18:42 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:18:42 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:18:42 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:18:42 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:18:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0008
14/06/10 16:18:43 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0008 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:18:43 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0008/
14/06/10 16:18:43 INFO mapreduce.Job: Running job: job_1402440802128_0008
14/06/10 16:18:51 INFO mapreduce.Job: Job job_1402440802128_0008 running in uber mode : false
14/06/10 16:18:51 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:19:03 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:19:09 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:19:09 INFO mapreduce.Job: Job job_1402440802128_0008 completed successfully
14/06/10 16:19:09 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19299
		Total time spent by all reduces in occupied slots (ms)=4863
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=352
		CPU time spent (ms)=1380
		Physical memory (bytes) snapshot=553107456
		Virtual memory (bytes) snapshot=2519457792
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 60118
[MR2PhaseApriori] Phase 1 execution time: 32860
[MR2PhaseApriori] Phase 2 execution time: 27258
Tue, Jun 10, 2014  4:19:11 PM
5
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 242
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:19:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:19:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:19:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:20:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:20:09 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:20:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:20:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:21:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:21:09 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:21:09 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:21:10 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:21:10 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:21:10 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:21:10 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:21:10 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:21:10 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:21:10 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:21:10 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:21:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0009
14/06/10 16:21:10 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0009 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:21:10 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0009/
14/06/10 16:21:10 INFO mapreduce.Job: Running job: job_1402440802128_0009
14/06/10 16:21:19 INFO mapreduce.Job: Job job_1402440802128_0009 running in uber mode : false
14/06/10 16:21:19 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:21:31 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 16:21:36 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:21:46 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 16:26:22 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 16:26:24 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:26:25 INFO mapreduce.Job: Job job_1402440802128_0009 completed successfully
14/06/10 16:26:25 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=311105
		Total time spent by all reduces in occupied slots (ms)=290244
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6680
		CPU time spent (ms)=284430
		Physical memory (bytes) snapshot=592330752
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:26:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:26:25 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:26:25 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:26:25 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:26:25 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:26:25 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:26:25 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:26:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0010
14/06/10 16:26:26 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0010 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:26:26 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0010/
14/06/10 16:26:26 INFO mapreduce.Job: Running job: job_1402440802128_0010
14/06/10 16:26:34 INFO mapreduce.Job: Job job_1402440802128_0010 running in uber mode : false
14/06/10 16:26:34 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:26:51 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 16:28:04 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:28:05 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:28:12 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:28:12 INFO mapreduce.Job: Job job_1402440802128_0010 completed successfully
14/06/10 16:28:13 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=177952
		Total time spent by all reduces in occupied slots (ms)=5679
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2729
		CPU time spent (ms)=80470
		Physical memory (bytes) snapshot=543916032
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 425851
[MR2PhaseApriori] Phase 1 execution time: 318125
[MR2PhaseApriori] Phase 2 execution time: 107726
Tue, Jun 10, 2014  4:28:14 PM
6
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 255
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:28:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:28:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:28:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:29:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:29:12 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:29:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:29:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:30:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:30:12 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:30:13 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:30:13 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:30:13 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:30:13 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:30:13 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:30:13 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:30:13 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:30:13 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:30:13 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:30:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0011
14/06/10 16:30:14 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0011 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:30:14 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0011/
14/06/10 16:30:14 INFO mapreduce.Job: Running job: job_1402440802128_0011
14/06/10 16:30:22 INFO mapreduce.Job: Job job_1402440802128_0011 running in uber mode : false
14/06/10 16:30:22 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:30:34 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 16:30:39 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:30:47 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 16:35:24 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 16:35:25 INFO mapreduce.Job:  map 100% reduce 71%
14/06/10 16:35:26 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:35:26 INFO mapreduce.Job: Job job_1402440802128_0011 completed successfully
14/06/10 16:35:26 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=308690
		Total time spent by all reduces in occupied slots (ms)=289230
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6701
		CPU time spent (ms)=280250
		Physical memory (bytes) snapshot=586276864
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:35:26 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:35:26 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:35:26 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:35:26 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:35:26 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:35:26 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:35:26 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:35:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0012
14/06/10 16:35:27 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0012 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:35:27 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0012/
14/06/10 16:35:27 INFO mapreduce.Job: Running job: job_1402440802128_0012
14/06/10 16:35:35 INFO mapreduce.Job: Job job_1402440802128_0012 running in uber mode : false
14/06/10 16:35:35 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:35:52 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 16:37:05 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:37:06 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:37:13 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:37:15 INFO mapreduce.Job: Job job_1402440802128_0012 completed successfully
14/06/10 16:37:15 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178069
		Total time spent by all reduces in occupied slots (ms)=5737
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2668
		CPU time spent (ms)=77730
		Physical memory (bytes) snapshot=542224384
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 425246
[MR2PhaseApriori] Phase 1 execution time: 316628
[MR2PhaseApriori] Phase 2 execution time: 108617
Tue, Jun 10, 2014  4:37:16 PM
7
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 261
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:37:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:37:41 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:37:41 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:38:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:38:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:38:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:38:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:39:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:39:14 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:39:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:39:15 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:39:15 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:39:15 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:39:15 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:39:15 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:39:15 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:39:15 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:39:15 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:39:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0013
14/06/10 16:39:16 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0013 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:39:16 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0013/
14/06/10 16:39:16 INFO mapreduce.Job: Running job: job_1402440802128_0013
14/06/10 16:39:24 INFO mapreduce.Job: Job job_1402440802128_0013 running in uber mode : false
14/06/10 16:39:24 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:39:35 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 16:39:40 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:39:49 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 16:44:21 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 16:44:23 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:44:24 INFO mapreduce.Job: Job job_1402440802128_0013 completed successfully
14/06/10 16:44:24 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=304363
		Total time spent by all reduces in occupied slots (ms)=283948
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6513
		CPU time spent (ms)=275440
		Physical memory (bytes) snapshot=587718656
		Virtual memory (bytes) snapshot=2510557184
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:44:24 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:44:24 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:44:24 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:44:24 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:44:24 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:44:24 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:44:24 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:44:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0014
14/06/10 16:44:25 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0014 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:44:25 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0014/
14/06/10 16:44:25 INFO mapreduce.Job: Running job: job_1402440802128_0014
14/06/10 16:44:33 INFO mapreduce.Job: Job job_1402440802128_0014 running in uber mode : false
14/06/10 16:44:33 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:44:50 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 16:46:03 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:46:04 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:46:11 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:46:12 INFO mapreduce.Job: Job job_1402440802128_0014 completed successfully
14/06/10 16:46:12 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=176511
		Total time spent by all reduces in occupied slots (ms)=5808
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2711
		CPU time spent (ms)=80030
		Physical memory (bytes) snapshot=545841152
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 419783
[MR2PhaseApriori] Phase 1 execution time: 312009
[MR2PhaseApriori] Phase 2 execution time: 107774
Tue, Jun 10, 2014  4:46:13 PM
8
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 232
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:46:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:46:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:46:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:47:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:47:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:47:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:47:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:48:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:48:11 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:48:11 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:48:12 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:48:12 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:48:12 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:48:12 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:48:12 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:48:12 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:48:12 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:48:12 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:48:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0015
14/06/10 16:48:13 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0015 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:48:13 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0015/
14/06/10 16:48:13 INFO mapreduce.Job: Running job: job_1402440802128_0015
14/06/10 16:48:21 INFO mapreduce.Job: Job job_1402440802128_0015 running in uber mode : false
14/06/10 16:48:21 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:48:33 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 16:48:38 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:48:49 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 16:53:28 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 16:53:31 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:53:31 INFO mapreduce.Job: Job job_1402440802128_0015 completed successfully
14/06/10 16:53:31 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=315270
		Total time spent by all reduces in occupied slots (ms)=294601
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6570
		CPU time spent (ms)=277920
		Physical memory (bytes) snapshot=585539584
		Virtual memory (bytes) snapshot=2510266368
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:53:31 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:53:31 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:53:31 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:53:31 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:53:31 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:53:31 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:53:31 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:53:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0016
14/06/10 16:53:32 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0016 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:53:32 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0016/
14/06/10 16:53:32 INFO mapreduce.Job: Running job: job_1402440802128_0016
14/06/10 16:53:40 INFO mapreduce.Job: Job job_1402440802128_0016 running in uber mode : false
14/06/10 16:53:40 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:53:57 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 16:55:11 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 16:55:12 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:55:20 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:55:20 INFO mapreduce.Job: Job job_1402440802128_0016 completed successfully
14/06/10 16:55:20 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=179492
		Total time spent by all reduces in occupied slots (ms)=5817
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2562
		CPU time spent (ms)=79000
		Physical memory (bytes) snapshot=577257472
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=443285504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 430899
[MR2PhaseApriori] Phase 1 execution time: 322201
[MR2PhaseApriori] Phase 2 execution time: 108698
Tue, Jun 10, 2014  4:55:21 PM
9
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 249
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:55:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:55:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:55:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:56:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:56:19 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:56:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:56:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:57:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:57:18 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:57:19 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:57:19 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:57:19 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:57:19 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 16:57:19 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 16:57:19 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 16:57:19 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 16:57:19 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 16:57:19 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 16:57:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0017
14/06/10 16:57:20 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0017 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:57:20 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0017/
14/06/10 16:57:20 INFO mapreduce.Job: Running job: job_1402440802128_0017
14/06/10 16:57:29 INFO mapreduce.Job: Job job_1402440802128_0017 running in uber mode : false
14/06/10 16:57:29 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:57:40 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:57:47 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:57:48 INFO mapreduce.Job: Job job_1402440802128_0017 completed successfully
14/06/10 16:57:48 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19568
		Total time spent by all reduces in occupied slots (ms)=4837
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=328
		CPU time spent (ms)=1500
		Physical memory (bytes) snapshot=549269504
		Virtual memory (bytes) snapshot=2520047616
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 16:57:48 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:57:48 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 16:57:48 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 16:57:48 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 16:57:48 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 16:57:48 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 16:57:48 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 16:57:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0018
14/06/10 16:57:49 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0018 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 16:57:49 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0018/
14/06/10 16:57:49 INFO mapreduce.Job: Running job: job_1402440802128_0018
14/06/10 16:57:57 INFO mapreduce.Job: Job job_1402440802128_0018 running in uber mode : false
14/06/10 16:57:57 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 16:58:08 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 16:58:15 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 16:58:15 INFO mapreduce.Job: Job job_1402440802128_0018 completed successfully
14/06/10 16:58:15 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19338
		Total time spent by all reduces in occupied slots (ms)=4797
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=351
		CPU time spent (ms)=1450
		Physical memory (bytes) snapshot=548433920
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 58967
[MR2PhaseApriori] Phase 1 execution time: 31693
[MR2PhaseApriori] Phase 2 execution time: 27274
Tue, Jun 10, 2014  4:58:17 PM
10
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 251
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:58:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:58:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 16:58:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:59:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 16:59:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:59:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 16:59:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:00:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:00:14 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:00:15 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:00:15 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:00:15 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:00:15 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:00:15 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:00:15 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:00:15 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:00:15 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:00:15 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:00:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0019
14/06/10 17:00:16 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0019 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:00:16 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0019/
14/06/10 17:00:16 INFO mapreduce.Job: Running job: job_1402440802128_0019
14/06/10 17:00:24 INFO mapreduce.Job: Job job_1402440802128_0019 running in uber mode : false
14/06/10 17:00:24 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:00:36 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:00:43 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:00:43 INFO mapreduce.Job: Job job_1402440802128_0019 completed successfully
14/06/10 17:00:44 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19704
		Total time spent by all reduces in occupied slots (ms)=4870
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=334
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=551989248
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:00:44 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:00:44 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:00:44 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:00:44 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:00:44 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:00:44 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:00:44 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:00:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0020
14/06/10 17:00:44 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0020 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:00:44 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0020/
14/06/10 17:00:44 INFO mapreduce.Job: Running job: job_1402440802128_0020
14/06/10 17:00:53 INFO mapreduce.Job: Job job_1402440802128_0020 running in uber mode : false
14/06/10 17:00:53 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:01:04 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:01:12 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:01:12 INFO mapreduce.Job: Job job_1402440802128_0020 completed successfully
14/06/10 17:01:12 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19507
		Total time spent by all reduces in occupied slots (ms)=4985
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=315
		CPU time spent (ms)=1430
		Physical memory (bytes) snapshot=554438656
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 59825
[MR2PhaseApriori] Phase 1 execution time: 31593
[MR2PhaseApriori] Phase 2 execution time: 28232
Tue, Jun 10, 2014  5:01:13 PM
11
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 251
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:01:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:01:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:01:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:02:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:02:12 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:02:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:02:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:03:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:03:11 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:03:11 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:03:12 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:03:12 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:03:12 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:03:12 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:03:12 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:03:12 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:03:12 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:03:12 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:03:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0021
14/06/10 17:03:12 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0021 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:03:12 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0021/
14/06/10 17:03:12 INFO mapreduce.Job: Running job: job_1402440802128_0021
14/06/10 17:03:20 INFO mapreduce.Job: Job job_1402440802128_0021 running in uber mode : false
14/06/10 17:03:20 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:03:32 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:03:39 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:03:39 INFO mapreduce.Job: Job job_1402440802128_0021 completed successfully
14/06/10 17:03:39 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19669
		Total time spent by all reduces in occupied slots (ms)=4839
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=328
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=550363136
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:03:39 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:03:39 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:03:39 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:03:39 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:03:39 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:03:39 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:03:39 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:03:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0022
14/06/10 17:03:40 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0022 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:03:40 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0022/
14/06/10 17:03:40 INFO mapreduce.Job: Running job: job_1402440802128_0022
14/06/10 17:03:48 INFO mapreduce.Job: Job job_1402440802128_0022 running in uber mode : false
14/06/10 17:03:48 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:04:00 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:04:07 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:04:07 INFO mapreduce.Job: Job job_1402440802128_0022 completed successfully
14/06/10 17:04:07 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19632
		Total time spent by all reduces in occupied slots (ms)=4775
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=351
		CPU time spent (ms)=1400
		Physical memory (bytes) snapshot=551587840
		Virtual memory (bytes) snapshot=2510401536
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 58551
[MR2PhaseApriori] Phase 1 execution time: 30326
[MR2PhaseApriori] Phase 2 execution time: 28225
Tue, Jun 10, 2014  5:04:09 PM
12
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 249
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:04:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:04:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:04:34 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:05:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:05:07 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:05:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:05:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:06:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:06:06 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:06:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:06:07 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:06:07 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:06:07 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:06:07 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:06:07 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:06:07 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:06:07 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:06:07 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:06:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0023
14/06/10 17:06:08 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0023 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:06:08 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0023/
14/06/10 17:06:08 INFO mapreduce.Job: Running job: job_1402440802128_0023
14/06/10 17:06:17 INFO mapreduce.Job: Job job_1402440802128_0023 running in uber mode : false
14/06/10 17:06:17 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:06:28 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:06:35 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:06:35 INFO mapreduce.Job: Job job_1402440802128_0023 completed successfully
14/06/10 17:06:35 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19393
		Total time spent by all reduces in occupied slots (ms)=4803
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=344
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=547282944
		Virtual memory (bytes) snapshot=2510401536
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:06:35 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:06:35 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:06:35 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:06:35 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:06:35 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:06:35 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:06:35 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:06:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0024
14/06/10 17:06:36 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0024 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:06:36 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0024/
14/06/10 17:06:36 INFO mapreduce.Job: Running job: job_1402440802128_0024
14/06/10 17:06:44 INFO mapreduce.Job: Job job_1402440802128_0024 running in uber mode : false
14/06/10 17:06:44 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:06:56 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:07:03 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:07:03 INFO mapreduce.Job: Job job_1402440802128_0024 completed successfully
14/06/10 17:07:03 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19349
		Total time spent by all reduces in occupied slots (ms)=4968
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=377
		CPU time spent (ms)=1390
		Physical memory (bytes) snapshot=549683200
		Virtual memory (bytes) snapshot=2510401536
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 58905
[MR2PhaseApriori] Phase 1 execution time: 30702
[MR2PhaseApriori] Phase 2 execution time: 28203
Tue, Jun 10, 2014  5:07:05 PM
13
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 260
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:07:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:07:29 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:07:29 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:08:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:08:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:08:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:08:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:09:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:09:02 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:09:02 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:09:02 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:09:03 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:09:03 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:09:03 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:09:03 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:09:03 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:09:03 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:09:03 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:09:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0025
14/06/10 17:09:03 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0025 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:09:03 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0025/
14/06/10 17:09:03 INFO mapreduce.Job: Running job: job_1402440802128_0025
14/06/10 17:09:12 INFO mapreduce.Job: Job job_1402440802128_0025 running in uber mode : false
14/06/10 17:09:12 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:09:24 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 17:09:29 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 17:09:37 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 17:14:10 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 17:14:12 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:14:13 INFO mapreduce.Job: Job job_1402440802128_0025 completed successfully
14/06/10 17:14:14 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=306479
		Total time spent by all reduces in occupied slots (ms)=285896
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6801
		CPU time spent (ms)=287720
		Physical memory (bytes) snapshot=588898304
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:14:14 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:14:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:14:14 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:14:14 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:14:14 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:14:14 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:14:14 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:14:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0026
14/06/10 17:14:14 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0026 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:14:14 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0026/
14/06/10 17:14:14 INFO mapreduce.Job: Running job: job_1402440802128_0026
14/06/10 17:14:23 INFO mapreduce.Job: Job job_1402440802128_0026 running in uber mode : false
14/06/10 17:14:23 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:14:39 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 17:15:51 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 17:15:53 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:16:00 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:16:00 INFO mapreduce.Job: Job job_1402440802128_0026 completed successfully
14/06/10 17:16:00 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=175770
		Total time spent by all reduces in occupied slots (ms)=5599
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2719
		CPU time spent (ms)=79720
		Physical memory (bytes) snapshot=541507584
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 420593
[MR2PhaseApriori] Phase 1 execution time: 313811
[MR2PhaseApriori] Phase 2 execution time: 106782
Tue, Jun 10, 2014  5:16:02 PM
14
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 240
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:16:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:16:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:16:27 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:17:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:17:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:17:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:17:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:17:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:18:00 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:18:00 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:18:01 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:18:01 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:18:01 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:18:01 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:18:01 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:18:01 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:18:01 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:18:01 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:18:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0027
14/06/10 17:18:01 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0027 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:18:01 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0027/
14/06/10 17:18:01 INFO mapreduce.Job: Running job: job_1402440802128_0027
14/06/10 17:18:10 INFO mapreduce.Job: Job job_1402440802128_0027 running in uber mode : false
14/06/10 17:18:10 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:18:22 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 17:18:27 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 17:18:35 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 17:23:05 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 17:23:08 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:23:08 INFO mapreduce.Job: Job job_1402440802128_0027 completed successfully
14/06/10 17:23:09 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=303291
		Total time spent by all reduces in occupied slots (ms)=284176
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6641
		CPU time spent (ms)=275390
		Physical memory (bytes) snapshot=585687040
		Virtual memory (bytes) snapshot=2510553088
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:23:09 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:23:09 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:23:09 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:23:09 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:23:09 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:23:09 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:23:09 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:23:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0028
14/06/10 17:23:09 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0028 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:23:09 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0028/
14/06/10 17:23:09 INFO mapreduce.Job: Running job: job_1402440802128_0028
14/06/10 17:23:17 INFO mapreduce.Job: Job job_1402440802128_0028 running in uber mode : false
14/06/10 17:23:17 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:23:34 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 17:24:47 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 17:24:48 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:24:56 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:24:56 INFO mapreduce.Job: Job job_1402440802128_0028 completed successfully
14/06/10 17:24:56 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=177166
		Total time spent by all reduces in occupied slots (ms)=5989
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2748
		CPU time spent (ms)=80190
		Physical memory (bytes) snapshot=547729408
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 418625
[MR2PhaseApriori] Phase 1 execution time: 310973
[MR2PhaseApriori] Phase 2 execution time: 107652
Tue, Jun 10, 2014  5:24:58 PM
15
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 247
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:25:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:25:23 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:25:23 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:25:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:25:56 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:26:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:26:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:26:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:26:55 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:26:56 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:26:56 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:26:56 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:26:56 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:26:56 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:26:56 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:26:56 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:26:56 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:26:56 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:26:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0029
14/06/10 17:26:57 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0029 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:26:57 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0029/
14/06/10 17:26:57 INFO mapreduce.Job: Running job: job_1402440802128_0029
14/06/10 17:27:05 INFO mapreduce.Job: Job job_1402440802128_0029 running in uber mode : false
14/06/10 17:27:05 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:27:16 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:27:23 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:27:25 INFO mapreduce.Job: Job job_1402440802128_0029 completed successfully
14/06/10 17:27:25 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19515
		Total time spent by all reduces in occupied slots (ms)=4886
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=312
		CPU time spent (ms)=1490
		Physical memory (bytes) snapshot=549462016
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:27:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:27:25 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:27:25 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:27:25 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:27:25 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:27:25 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:27:25 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:27:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0030
14/06/10 17:27:25 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0030 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:27:25 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0030/
14/06/10 17:27:25 INFO mapreduce.Job: Running job: job_1402440802128_0030
14/06/10 17:27:34 INFO mapreduce.Job: Job job_1402440802128_0030 running in uber mode : false
14/06/10 17:27:34 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:27:45 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:27:52 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:27:52 INFO mapreduce.Job: Job job_1402440802128_0030 completed successfully
14/06/10 17:27:52 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19504
		Total time spent by all reduces in occupied slots (ms)=4898
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=362
		CPU time spent (ms)=1430
		Physical memory (bytes) snapshot=547803136
		Virtual memory (bytes) snapshot=2510602240
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 58756
[MR2PhaseApriori] Phase 1 execution time: 31482
[MR2PhaseApriori] Phase 2 execution time: 27274
Tue, Jun 10, 2014  5:27:53 PM
16
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 243
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:28:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:28:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:28:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:28:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:28:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:29:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:29:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:29:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:29:51 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:29:51 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:29:51 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:29:52 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:29:52 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:29:52 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:29:52 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:29:52 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:29:52 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:29:52 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:29:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0031
14/06/10 17:29:52 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0031 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:29:52 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0031/
14/06/10 17:29:52 INFO mapreduce.Job: Running job: job_1402440802128_0031
14/06/10 17:30:01 INFO mapreduce.Job: Job job_1402440802128_0031 running in uber mode : false
14/06/10 17:30:01 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:30:13 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 17:30:18 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 17:30:27 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 17:34:56 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 17:34:58 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:34:58 INFO mapreduce.Job: Job job_1402440802128_0031 completed successfully
14/06/10 17:34:59 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=302797
		Total time spent by all reduces in occupied slots (ms)=282118
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6499
		CPU time spent (ms)=274800
		Physical memory (bytes) snapshot=591769600
		Virtual memory (bytes) snapshot=2510548992
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:34:59 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:34:59 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:34:59 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:34:59 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:34:59 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:34:59 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:34:59 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:34:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0032
14/06/10 17:34:59 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0032 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:34:59 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0032/
14/06/10 17:34:59 INFO mapreduce.Job: Running job: job_1402440802128_0032
14/06/10 17:35:07 INFO mapreduce.Job: Job job_1402440802128_0032 running in uber mode : false
14/06/10 17:35:07 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:35:25 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 17:36:38 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 17:36:39 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:36:46 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:36:47 INFO mapreduce.Job: Job job_1402440802128_0032 completed successfully
14/06/10 17:36:47 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178031
		Total time spent by all reduces in occupied slots (ms)=5619
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=1986
		CPU time spent (ms)=78010
		Physical memory (bytes) snapshot=579551232
		Virtual memory (bytes) snapshot=2510417920
		Total committed heap usage (bytes)=443285504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 418316
[MR2PhaseApriori] Phase 1 execution time: 309822
[MR2PhaseApriori] Phase 2 execution time: 108494
Tue, Jun 10, 2014  5:36:49 PM
17
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 254
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:37:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:37:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:37:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:37:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:37:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:37:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:38:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:38:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:38:46 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:38:46 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:38:47 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:38:47 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:38:47 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:38:47 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:38:47 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:38:47 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:38:47 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:38:47 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:38:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0033
14/06/10 17:38:47 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0033 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:38:47 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0033/
14/06/10 17:38:47 INFO mapreduce.Job: Running job: job_1402440802128_0033
14/06/10 17:38:56 INFO mapreduce.Job: Job job_1402440802128_0033 running in uber mode : false
14/06/10 17:38:56 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:39:08 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:39:15 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:39:16 INFO mapreduce.Job: Job job_1402440802128_0033 completed successfully
14/06/10 17:39:16 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19444
		Total time spent by all reduces in occupied slots (ms)=4874
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=340
		CPU time spent (ms)=1520
		Physical memory (bytes) snapshot=550985728
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 17:39:16 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:39:16 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:39:17 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:39:17 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:39:17 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 17:39:17 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 17:39:17 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 17:39:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0034
14/06/10 17:39:17 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0034 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:39:17 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0034/
14/06/10 17:39:17 INFO mapreduce.Job: Running job: job_1402440802128_0034
14/06/10 17:39:25 INFO mapreduce.Job: Job job_1402440802128_0034 running in uber mode : false
14/06/10 17:39:25 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 17:39:37 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 17:39:44 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 17:39:44 INFO mapreduce.Job: Job job_1402440802128_0034 completed successfully
14/06/10 17:39:44 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19551
		Total time spent by all reduces in occupied slots (ms)=4876
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=318
		CPU time spent (ms)=1440
		Physical memory (bytes) snapshot=548061184
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 60609
[MR2PhaseApriori] Phase 1 execution time: 32357
[MR2PhaseApriori] Phase 2 execution time: 28252
Tue, Jun 10, 2014  5:39:46 PM
18
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 234
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4572) (out= 2035)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3386) (out= 1412)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5887) (out= 2819)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:40:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:40:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 17:40:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:40:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:40:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:40:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:41:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 17:41:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 17:41:43 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:41:44 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 17:41:44 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 17:41:44 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 17:41:44 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 17:41:44 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 17:41:44 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 17:41:44 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 17:41:44 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 17:41:44 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 17:41:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402440802128_0035
14/06/10 17:41:45 INFO impl.YarnClientImpl: Submitted application application_1402440802128_0035 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 17:41:45 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402440802128_0035/
14/06/10 17:41:45 INFO mapreduce.Job: Running job: job_1402440802128_0035
14/06/10 17:41:54 INFO mapreduce.Job: Job job_1402440802128_0035 running in uber mode : false
14/06/10 17:41:54 INFO mapreduce.Job:  map 0% reduce 0%
