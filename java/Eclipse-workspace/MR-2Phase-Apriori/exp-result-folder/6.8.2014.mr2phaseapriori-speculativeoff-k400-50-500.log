400
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:45:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:46:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:46:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:46:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:47:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 16:47:03 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 16:47:03 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 16:47:04 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 16:47:04 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 16:47:04 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 16:47:04 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 16:47:04 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 16:47:04 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 16:47:04 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 16:47:04 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 16:47:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0001
14/06/08 16:47:05 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0001 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 16:47:05 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0001/
14/06/08 16:47:05 INFO mapreduce.Job: Running job: job_1402271020717_0001
14/06/08 16:47:15 INFO mapreduce.Job: Job job_1402271020717_0001 running in uber mode : false
14/06/08 16:47:15 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 16:47:29 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 16:47:33 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 16:47:42 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 16:52:16 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 16:52:18 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 16:52:18 INFO mapreduce.Job: Job job_1402271020717_0001 completed successfully
14/06/08 16:52:18 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=310615
		Total time spent by all reduces in occupied slots (ms)=286849
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6333
		CPU time spent (ms)=280140
		Physical memory (bytes) snapshot=587993088
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 16:52:18 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 16:52:18 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 16:52:18 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 16:52:18 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 16:52:18 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 16:52:18 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 16:52:18 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 16:52:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0002
14/06/08 16:52:19 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0002 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 16:52:19 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0002/
14/06/08 16:52:19 INFO mapreduce.Job: Running job: job_1402271020717_0002
14/06/08 16:52:27 INFO mapreduce.Job: Job job_1402271020717_0002 running in uber mode : false
14/06/08 16:52:27 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 16:52:44 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 16:53:49 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 16:53:57 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 16:53:59 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 16:53:59 INFO mapreduce.Job: Job job_1402271020717_0002 completed successfully
14/06/08 16:53:59 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=169243
		Total time spent by all reduces in occupied slots (ms)=7093
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2455
		CPU time spent (ms)=79520
		Physical memory (bytes) snapshot=571023360
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=443285504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 418429
[MR2PhaseApriori] Phase 1 execution time: 317001
[MR2PhaseApriori] Phase 2 execution time: 101428
k=400
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:54:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 16:54:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 16:54:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Skip data reupload, use previously uploaded input
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 16:54:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 16:54:59 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 16:54:59 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 16:55:00 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 16:55:00 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 16:55:00 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 16:55:00 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 16:55:00 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 16:55:00 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 16:55:00 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 16:55:00 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 16:55:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0003
14/06/08 16:55:00 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0003 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 16:55:00 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0003/
14/06/08 16:55:00 INFO mapreduce.Job: Running job: job_1402271020717_0003
14/06/08 16:55:09 INFO mapreduce.Job: Job job_1402271020717_0003 running in uber mode : false
14/06/08 16:55:09 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 16:55:20 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 16:55:25 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 16:55:33 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:00:02 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:00:04 INFO mapreduce.Job:  map 100% reduce 70%
14/06/08 17:00:05 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:00:06 INFO mapreduce.Job: Job job_1402271020717_0003 completed successfully
14/06/08 17:00:07 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=302063
		Total time spent by all reduces in occupied slots (ms)=283072
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6495
		CPU time spent (ms)=273950
		Physical memory (bytes) snapshot=592429056
		Virtual memory (bytes) snapshot=2510553088
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:00:07 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:00:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:00:07 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:00:07 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:00:07 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:00:07 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:00:07 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:00:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0004
14/06/08 17:00:07 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0004 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:00:07 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0004/
14/06/08 17:00:07 INFO mapreduce.Job: Running job: job_1402271020717_0004
14/06/08 17:00:15 INFO mapreduce.Job: Job job_1402271020717_0004 running in uber mode : false
14/06/08 17:00:15 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:00:32 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:01:39 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:01:45 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 17:01:48 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:01:48 INFO mapreduce.Job: Job job_1402271020717_0004 completed successfully
14/06/08 17:01:48 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=169878
		Total time spent by all reduces in occupied slots (ms)=6305
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2612
		CPU time spent (ms)=79820
		Physical memory (bytes) snapshot=546156544
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 410988
[MR2PhaseApriori] Phase 1 execution time: 309470
[MR2PhaseApriori] Phase 2 execution time: 101518
k=400
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:02:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:02:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:02:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Skip data reupload, use previously uploaded input
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:02:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:02:48 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:02:48 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:02:48 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:02:48 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:02:48 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:02:48 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:02:48 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:02:48 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:02:48 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:02:48 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:02:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0005
14/06/08 17:02:49 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0005 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:02:49 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0005/
14/06/08 17:02:49 INFO mapreduce.Job: Running job: job_1402271020717_0005
14/06/08 17:02:58 INFO mapreduce.Job: Job job_1402271020717_0005 running in uber mode : false
14/06/08 17:02:58 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:03:09 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:03:14 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:03:22 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:07:56 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:07:58 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:07:58 INFO mapreduce.Job: Job job_1402271020717_0005 completed successfully
14/06/08 17:07:58 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=306634
		Total time spent by all reduces in occupied slots (ms)=286959
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6445
		CPU time spent (ms)=284470
		Physical memory (bytes) snapshot=592076800
		Virtual memory (bytes) snapshot=2510147584
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:07:59 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:07:59 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:07:59 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:07:59 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:07:59 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:07:59 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:07:59 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:07:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0006
14/06/08 17:07:59 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0006 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:07:59 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0006/
14/06/08 17:07:59 INFO mapreduce.Job: Running job: job_1402271020717_0006
14/06/08 17:08:07 INFO mapreduce.Job: Job job_1402271020717_0006 running in uber mode : false
14/06/08 17:08:07 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:08:25 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:09:33 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:09:45 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 17:09:47 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:09:48 INFO mapreduce.Job: Job job_1402271020717_0006 completed successfully
14/06/08 17:09:48 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178467
		Total time spent by all reduces in occupied slots (ms)=11407
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2607
		CPU time spent (ms)=78980
		Physical memory (bytes) snapshot=529002496
		Virtual memory (bytes) snapshot=2510643200
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 422346
[MR2PhaseApriori] Phase 1 execution time: 312826
[MR2PhaseApriori] Phase 2 execution time: 109520
k=400
450
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:10:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:10:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:10:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:10:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:10:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:11:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:11:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:11:46 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:11:46 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:11:47 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:11:47 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:11:47 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:11:47 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:11:47 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:11:47 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:11:47 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:11:47 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:11:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0007
14/06/08 17:11:48 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0007 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:11:48 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0007/
14/06/08 17:11:48 INFO mapreduce.Job: Running job: job_1402271020717_0007
14/06/08 17:11:56 INFO mapreduce.Job: Job job_1402271020717_0007 running in uber mode : false
14/06/08 17:11:56 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:12:07 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:12:12 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:12:22 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:16:54 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:16:55 INFO mapreduce.Job:  map 100% reduce 70%
14/06/08 17:16:56 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:16:56 INFO mapreduce.Job: Job job_1402271020717_0007 completed successfully
14/06/08 17:16:56 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=305026
		Total time spent by all reduces in occupied slots (ms)=285944
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6434
		CPU time spent (ms)=279720
		Physical memory (bytes) snapshot=584560640
		Virtual memory (bytes) snapshot=2510557184
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:16:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:16:56 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:16:56 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:16:56 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:16:56 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:16:56 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:16:56 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:16:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0008
14/06/08 17:16:56 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0008 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:16:56 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0008/
14/06/08 17:16:56 INFO mapreduce.Job: Running job: job_1402271020717_0008
14/06/08 17:17:05 INFO mapreduce.Job: Job job_1402271020717_0008 running in uber mode : false
14/06/08 17:17:05 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:17:22 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:18:26 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:18:38 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 17:18:40 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:18:41 INFO mapreduce.Job: Job job_1402271020717_0008 completed successfully
14/06/08 17:18:42 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=172251
		Total time spent by all reduces in occupied slots (ms)=11109
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2645
		CPU time spent (ms)=78840
		Physical memory (bytes) snapshot=542818304
		Virtual memory (bytes) snapshot=2510565376
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 417559
[MR2PhaseApriori] Phase 1 execution time: 311812
[MR2PhaseApriori] Phase 2 execution time: 105747
k=450
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:19:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:19:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:19:08 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Skip data reupload, use previously uploaded input
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:19:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:19:41 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:19:41 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:19:42 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:19:42 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:19:42 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:19:42 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:19:42 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:19:42 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:19:42 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:19:42 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:19:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0009
14/06/08 17:19:43 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0009 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:19:43 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0009/
14/06/08 17:19:43 INFO mapreduce.Job: Running job: job_1402271020717_0009
14/06/08 17:19:51 INFO mapreduce.Job: Job job_1402271020717_0009 running in uber mode : false
14/06/08 17:19:51 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:20:02 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:20:07 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:20:15 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:24:49 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:24:50 INFO mapreduce.Job:  map 100% reduce 71%
14/06/08 17:24:51 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:24:52 INFO mapreduce.Job: Job job_1402271020717_0009 completed successfully
14/06/08 17:24:52 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=305738
		Total time spent by all reduces in occupied slots (ms)=285998
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6569
		CPU time spent (ms)=277690
		Physical memory (bytes) snapshot=582074368
		Virtual memory (bytes) snapshot=2510352384
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:24:52 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:24:52 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:24:52 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:24:52 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:24:52 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:24:52 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:24:52 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:24:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0010
14/06/08 17:24:52 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0010 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:24:52 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0010/
14/06/08 17:24:52 INFO mapreduce.Job: Running job: job_1402271020717_0010
14/06/08 17:25:01 INFO mapreduce.Job: Job job_1402271020717_0010 running in uber mode : false
14/06/08 17:25:01 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:25:17 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:26:21 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:26:29 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 17:26:32 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:26:33 INFO mapreduce.Job: Job job_1402271020717_0010 completed successfully
14/06/08 17:26:33 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=166446
		Total time spent by all reduces in occupied slots (ms)=8108
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2622
		CPU time spent (ms)=79310
		Physical memory (bytes) snapshot=539893760
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 414370
[MR2PhaseApriori] Phase 1 execution time: 312794
[MR2PhaseApriori] Phase 2 execution time: 101576
k=450
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:26:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:27:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:27:00 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Skip data reupload, use previously uploaded input
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:27:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:27:33 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:27:33 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:27:34 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:27:34 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:27:34 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:27:34 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:27:34 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:27:34 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:27:34 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:27:34 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:27:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0011
14/06/08 17:27:35 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0011 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:27:35 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0011/
14/06/08 17:27:35 INFO mapreduce.Job: Running job: job_1402271020717_0011
14/06/08 17:27:42 INFO mapreduce.Job: Job job_1402271020717_0011 running in uber mode : false
14/06/08 17:27:42 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:27:54 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:27:59 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:28:07 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:32:50 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:32:53 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:32:53 INFO mapreduce.Job: Job job_1402271020717_0011 completed successfully
14/06/08 17:32:53 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=314946
		Total time spent by all reduces in occupied slots (ms)=295997
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6345
		CPU time spent (ms)=293070
		Physical memory (bytes) snapshot=590061568
		Virtual memory (bytes) snapshot=2519855104
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:32:53 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:32:53 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:32:53 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:32:53 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:32:53 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:32:53 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:32:53 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:32:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0012
14/06/08 17:32:53 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0012 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:32:53 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0012/
14/06/08 17:32:53 INFO mapreduce.Job: Running job: job_1402271020717_0012
14/06/08 17:33:02 INFO mapreduce.Job: Job job_1402271020717_0012 running in uber mode : false
14/06/08 17:33:02 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:33:18 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:34:22 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:34:35 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 17:34:38 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:34:38 INFO mapreduce.Job: Job job_1402271020717_0012 completed successfully
14/06/08 17:34:38 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=170826
		Total time spent by all reduces in occupied slots (ms)=12153
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2640
		CPU time spent (ms)=79150
		Physical memory (bytes) snapshot=549646336
		Virtual memory (bytes) snapshot=2510290944
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 427418
[MR2PhaseApriori] Phase 1 execution time: 321917
[MR2PhaseApriori] Phase 2 execution time: 105501
k=450
500
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:35:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:35:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:35:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:35:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:35:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:35:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:36:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:36:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:36:36 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:36:37 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:36:37 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:36:37 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:36:37 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:36:37 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:36:37 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:36:37 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:36:37 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:36:37 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:36:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0013
14/06/08 17:36:38 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0013 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:36:38 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0013/
14/06/08 17:36:38 INFO mapreduce.Job: Running job: job_1402271020717_0013
14/06/08 17:36:46 INFO mapreduce.Job: Job job_1402271020717_0013 running in uber mode : false
14/06/08 17:36:46 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:36:58 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:37:03 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:37:11 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:41:45 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:41:47 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:41:48 INFO mapreduce.Job: Job job_1402271020717_0013 completed successfully
14/06/08 17:41:48 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=306675
		Total time spent by all reduces in occupied slots (ms)=286859
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6524
		CPU time spent (ms)=278660
		Physical memory (bytes) snapshot=591892480
		Virtual memory (bytes) snapshot=2510352384
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:41:48 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:41:48 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:41:48 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:41:48 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:41:48 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:41:48 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:41:48 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:41:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0014
14/06/08 17:41:49 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0014 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:41:49 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0014/
14/06/08 17:41:49 INFO mapreduce.Job: Running job: job_1402271020717_0014
14/06/08 17:41:57 INFO mapreduce.Job: Job job_1402271020717_0014 running in uber mode : false
14/06/08 17:41:57 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:42:13 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:43:14 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:43:26 INFO mapreduce.Job:  map 100% reduce 0%
14/06/08 17:43:28 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:43:29 INFO mapreduce.Job: Job job_1402271020717_0014 completed successfully
14/06/08 17:43:29 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=162586
		Total time spent by all reduces in occupied slots (ms)=11356
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2631
		CPU time spent (ms)=78820
		Physical memory (bytes) snapshot=550674432
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 414043
[MR2PhaseApriori] Phase 1 execution time: 313383
[MR2PhaseApriori] Phase 2 execution time: 100660
k=500
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:43:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:43:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:43:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Skip data reupload, use previously uploaded input
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:44:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:44:28 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:44:28 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:44:29 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:44:29 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:44:29 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:44:29 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:44:29 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:44:29 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:44:29 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:44:29 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:44:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0015
14/06/08 17:44:30 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0015 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:44:30 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0015/
14/06/08 17:44:30 INFO mapreduce.Job: Running job: job_1402271020717_0015
14/06/08 17:44:38 INFO mapreduce.Job: Job job_1402271020717_0015 running in uber mode : false
14/06/08 17:44:38 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:44:50 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:44:55 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:45:03 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:49:44 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:49:46 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:49:46 INFO mapreduce.Job: Job job_1402271020717_0015 completed successfully
14/06/08 17:49:46 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=313381
		Total time spent by all reduces in occupied slots (ms)=294022
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6335
		CPU time spent (ms)=291290
		Physical memory (bytes) snapshot=589398016
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:49:47 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:49:47 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:49:47 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:49:47 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:49:47 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:49:47 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:49:47 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:49:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0016
14/06/08 17:49:47 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0016 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:49:47 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0016/
14/06/08 17:49:47 INFO mapreduce.Job: Running job: job_1402271020717_0016
14/06/08 17:49:55 INFO mapreduce.Job: Job job_1402271020717_0016 running in uber mode : false
14/06/08 17:49:55 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:50:11 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:51:14 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:51:29 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:51:30 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:51:32 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:51:32 INFO mapreduce.Job: Job job_1402271020717_0016 completed successfully
14/06/08 17:51:32 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=168845
		Total time spent by all reduces in occupied slots (ms)=15323
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2645
		CPU time spent (ms)=78100
		Physical memory (bytes) snapshot=542466048
		Virtual memory (bytes) snapshot=2510426112
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 425875
[MR2PhaseApriori] Phase 1 execution time: 320282
[MR2PhaseApriori] Phase 2 execution time: 105593
k=500
Warning, this script only works for 1000 lines now
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4209) (out= 2091)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4571) (out= 2031)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5478) (out= 2424)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3383) (out= 1409)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5951) (out= 2845)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:51:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:51:58 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/08 17:51:58 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Skip data reupload, use previously uploaded input
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/08 17:52:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/08 17:52:32 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:52:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:52:32 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:52:32 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:52:32 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/08 17:52:32 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/08 17:52:32 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/08 17:52:32 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/08 17:52:32 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/08 17:52:32 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/08 17:52:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0017
14/06/08 17:52:33 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0017 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:52:33 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0017/
14/06/08 17:52:33 INFO mapreduce.Job: Running job: job_1402271020717_0017
14/06/08 17:52:42 INFO mapreduce.Job: Job job_1402271020717_0017 running in uber mode : false
14/06/08 17:52:42 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:52:53 INFO mapreduce.Job:  map 50% reduce 0%
14/06/08 17:52:58 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:53:08 INFO mapreduce.Job:  map 83% reduce 17%
14/06/08 17:57:47 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:57:49 INFO mapreduce.Job:  map 100% reduce 71%
14/06/08 17:57:50 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:57:50 INFO mapreduce.Job: Job job_1402271020717_0017 completed successfully
14/06/08 17:57:50 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581267
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=313921
		Total time spent by all reduces in occupied slots (ms)=294860
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6399
		CPU time spent (ms)=288370
		Physical memory (bytes) snapshot=586346496
		Virtual memory (bytes) snapshot=2510348288
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/08 17:57:50 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:57:50 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/08 17:57:51 INFO input.FileInputFormat: Total input paths to process : 2
14/06/08 17:57:51 INFO mapreduce.JobSubmitter: number of splits:2
14/06/08 17:57:51 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/08 17:57:51 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/08 17:57:51 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/08 17:57:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402271020717_0018
14/06/08 17:57:51 INFO impl.YarnClientImpl: Submitted application application_1402271020717_0018 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/08 17:57:51 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402271020717_0018/
14/06/08 17:57:51 INFO mapreduce.Job: Running job: job_1402271020717_0018
14/06/08 17:57:59 INFO mapreduce.Job: Job job_1402271020717_0018 running in uber mode : false
14/06/08 17:57:59 INFO mapreduce.Job:  map 0% reduce 0%
14/06/08 17:58:15 INFO mapreduce.Job:  map 33% reduce 0%
14/06/08 17:58:16 INFO mapreduce.Job:  map 67% reduce 0%
14/06/08 17:59:19 INFO mapreduce.Job:  map 83% reduce 0%
14/06/08 17:59:34 INFO mapreduce.Job:  map 100% reduce 17%
14/06/08 17:59:36 INFO mapreduce.Job:  map 100% reduce 100%
14/06/08 17:59:37 INFO mapreduce.Job: Job job_1402271020717_0018 completed successfully
14/06/08 17:59:37 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1540093
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=170398
		Total time spent by all reduces in occupied slots (ms)=15212
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=65535
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2684
		CPU time spent (ms)=78130
		Physical memory (bytes) snapshot=575598592
		Virtual memory (bytes) snapshot=2510139392
		Total committed heap usage (bytes)=443285504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1540093
[MR2PhaseApriori] Total execution time: 427433
[MR2PhaseApriori] Phase 1 execution time: 320681
[MR2PhaseApriori] Phase 2 execution time: 106752
k=500
