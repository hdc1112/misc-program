1
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 242
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:36:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:36:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:37:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:37:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:37:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:37:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:37:56 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 13:37:57 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 13:37:57 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 13:37:57 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 13:37:57 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 13:37:57 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 13:37:57 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 13:37:57 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 13:37:57 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 13:37:57 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0001
14/06/10 13:37:58 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0001 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:37:58 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0001/
14/06/10 13:37:58 INFO mapreduce.Job: Running job: job_1402432471050_0001
14/06/10 13:38:08 INFO mapreduce.Job: Job job_1402432471050_0001 running in uber mode : false
14/06/10 13:38:08 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 13:38:21 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 13:38:26 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 13:38:37 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 13:43:24 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 13:43:26 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 13:43:26 INFO mapreduce.Job: Job job_1402432471050_0001 completed successfully
14/06/10 13:43:26 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=324792
		Total time spent by all reduces in occupied slots (ms)=301922
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6855
		CPU time spent (ms)=282250
		Physical memory (bytes) snapshot=586309632
		Virtual memory (bytes) snapshot=2510147584
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 13:43:26 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:43:26 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 13:43:26 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 13:43:27 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 13:43:27 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 13:43:27 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 13:43:27 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 13:43:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0002
14/06/10 13:43:27 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0002 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:43:27 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0002/
14/06/10 13:43:27 INFO mapreduce.Job: Running job: job_1402432471050_0002
14/06/10 13:43:35 INFO mapreduce.Job: Job job_1402432471050_0002 running in uber mode : false
14/06/10 13:43:35 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 13:43:52 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 13:45:06 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 13:45:07 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 13:45:17 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 13:45:17 INFO mapreduce.Job: Job job_1402432471050_0002 completed successfully
14/06/10 13:45:17 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178696
		Total time spent by all reduces in occupied slots (ms)=7990
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2673
		CPU time spent (ms)=78370
		Physical memory (bytes) snapshot=544919552
		Virtual memory (bytes) snapshot=2510401536
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 443104
[MR2PhaseApriori] Phase 1 execution time: 332460
[MR2PhaseApriori] Phase 2 execution time: 110644
Tue, Jun 10, 2014  1:45:19 PM
2
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 244
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:45:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:45:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 13:45:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:46:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:46:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:46:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:46:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:47:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:47:16 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:47:16 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 13:47:17 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 13:47:17 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 13:47:17 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 13:47:17 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 13:47:17 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 13:47:17 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 13:47:17 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 13:47:17 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 13:47:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0003
14/06/10 13:47:17 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0003 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:47:17 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0003/
14/06/10 13:47:17 INFO mapreduce.Job: Running job: job_1402432471050_0003
14/06/10 13:47:26 INFO mapreduce.Job: Job job_1402432471050_0003 running in uber mode : false
14/06/10 13:47:26 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 13:47:38 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 13:47:42 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 13:47:50 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 13:52:24 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 13:52:25 INFO mapreduce.Job:  map 100% reduce 33%
14/06/10 13:52:27 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 13:52:28 INFO mapreduce.Job: Job job_1402432471050_0003 completed successfully
14/06/10 13:52:28 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=306172
		Total time spent by all reduces in occupied slots (ms)=287336
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6663
		CPU time spent (ms)=280630
		Physical memory (bytes) snapshot=591474688
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 13:52:28 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:52:28 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 13:52:28 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 13:52:28 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 13:52:28 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 13:52:28 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 13:52:28 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 13:52:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0004
14/06/10 13:52:29 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0004 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:52:29 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0004/
14/06/10 13:52:29 INFO mapreduce.Job: Running job: job_1402432471050_0004
14/06/10 13:52:37 INFO mapreduce.Job: Job job_1402432471050_0004 running in uber mode : false
14/06/10 13:52:37 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 13:52:54 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 13:54:14 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 13:54:22 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 13:54:23 INFO mapreduce.Job: Job job_1402432471050_0004 completed successfully
14/06/10 13:54:23 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=190416
		Total time spent by all reduces in occupied slots (ms)=5987
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2830
		CPU time spent (ms)=84260
		Physical memory (bytes) snapshot=547205120
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 429087
[MR2PhaseApriori] Phase 1 execution time: 314208
[MR2PhaseApriori] Phase 2 execution time: 114879
Tue, Jun 10, 2014  1:54:24 PM
3
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 258
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:54:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:54:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 13:54:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:55:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:55:23 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:55:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:55:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 13:56:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 13:56:22 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:56:23 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 13:56:23 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 13:56:23 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 13:56:23 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 13:56:23 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 13:56:23 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 13:56:23 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 13:56:23 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 13:56:23 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 13:56:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0005
14/06/10 13:56:24 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0005 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 13:56:24 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0005/
14/06/10 13:56:24 INFO mapreduce.Job: Running job: job_1402432471050_0005
14/06/10 13:56:32 INFO mapreduce.Job: Job job_1402432471050_0005 running in uber mode : false
14/06/10 13:56:32 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 13:56:44 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 13:56:49 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 13:57:00 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 14:01:32 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 14:01:33 INFO mapreduce.Job:  map 100% reduce 73%
14/06/10 14:01:34 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:01:34 INFO mapreduce.Job: Job job_1402432471050_0005 completed successfully
14/06/10 14:01:34 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=307459
		Total time spent by all reduces in occupied slots (ms)=286250
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6588
		CPU time spent (ms)=273850
		Physical memory (bytes) snapshot=584355840
		Virtual memory (bytes) snapshot=2510548992
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:01:34 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:01:34 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:01:34 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:01:34 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:01:35 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:01:35 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:01:35 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:01:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0006
14/06/10 14:01:35 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0006 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:01:35 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0006/
14/06/10 14:01:35 INFO mapreduce.Job: Running job: job_1402432471050_0006
14/06/10 14:01:43 INFO mapreduce.Job: Job job_1402432471050_0006 running in uber mode : false
14/06/10 14:01:43 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:02:00 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 14:03:13 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:03:14 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:03:21 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:03:21 INFO mapreduce.Job: Job job_1402432471050_0006 completed successfully
14/06/10 14:03:21 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=176258
		Total time spent by all reduces in occupied slots (ms)=5721
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2714
		CPU time spent (ms)=79700
		Physical memory (bytes) snapshot=547209216
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 420864
[MR2PhaseApriori] Phase 1 execution time: 314228
[MR2PhaseApriori] Phase 2 execution time: 106636
Tue, Jun 10, 2014  2:03:22 PM
4
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 250
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:03:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:03:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:03:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:04:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:04:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:04:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:04:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:05:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:05:19 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:05:20 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:05:20 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:05:20 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:05:20 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:05:20 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:05:20 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:05:20 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:05:20 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:05:20 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:05:21 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0007
14/06/10 14:05:21 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0007 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:05:21 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0007/
14/06/10 14:05:21 INFO mapreduce.Job: Running job: job_1402432471050_0007
14/06/10 14:05:30 INFO mapreduce.Job: Job job_1402432471050_0007 running in uber mode : false
14/06/10 14:05:30 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:05:42 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:05:49 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:05:50 INFO mapreduce.Job: Job job_1402432471050_0007 completed successfully
14/06/10 14:05:50 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=20619
		Total time spent by all reduces in occupied slots (ms)=4731
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=328
		CPU time spent (ms)=1460
		Physical memory (bytes) snapshot=548044800
		Virtual memory (bytes) snapshot=2510401536
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:05:50 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:05:50 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:05:50 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:05:50 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:05:50 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:05:50 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:05:50 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:05:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0008
14/06/10 14:05:51 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0008 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:05:51 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0008/
14/06/10 14:05:51 INFO mapreduce.Job: Running job: job_1402432471050_0008
14/06/10 14:05:59 INFO mapreduce.Job: Job job_1402432471050_0008 running in uber mode : false
14/06/10 14:05:59 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:06:10 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:06:18 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:06:18 INFO mapreduce.Job: Job job_1402432471050_0008 completed successfully
14/06/10 14:06:18 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242909
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19492
		Total time spent by all reduces in occupied slots (ms)=5426
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=331
		CPU time spent (ms)=1470
		Physical memory (bytes) snapshot=549625856
		Virtual memory (bytes) snapshot=2510553088
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 61019
[MR2PhaseApriori] Phase 1 execution time: 32679
[MR2PhaseApriori] Phase 2 execution time: 28340
Tue, Jun 10, 2014  2:06:20 PM
5
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 232
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:06:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:06:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:06:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:07:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:07:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:07:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:07:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:08:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:08:18 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:08:19 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:08:19 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:08:19 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:08:19 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:08:19 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:08:19 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:08:19 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:08:19 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:08:19 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:08:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0009
14/06/10 14:08:20 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0009 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:08:20 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0009/
14/06/10 14:08:20 INFO mapreduce.Job: Running job: job_1402432471050_0009
14/06/10 14:08:29 INFO mapreduce.Job: Job job_1402432471050_0009 running in uber mode : false
14/06/10 14:08:29 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:08:41 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 14:08:46 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:08:57 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 14:13:34 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 14:13:36 INFO mapreduce.Job:  map 100% reduce 67%
14/06/10 14:13:37 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:13:38 INFO mapreduce.Job: Job job_1402432471050_0009 completed successfully
14/06/10 14:13:38 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=313638
		Total time spent by all reduces in occupied slots (ms)=293421
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6701
		CPU time spent (ms)=279740
		Physical memory (bytes) snapshot=587579392
		Virtual memory (bytes) snapshot=2510213120
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:13:38 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:13:38 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:13:38 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:13:38 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:13:38 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:13:38 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:13:38 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:13:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0010
14/06/10 14:13:39 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0010 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:13:39 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0010/
14/06/10 14:13:39 INFO mapreduce.Job: Running job: job_1402432471050_0010
14/06/10 14:13:47 INFO mapreduce.Job: Job job_1402432471050_0010 running in uber mode : false
14/06/10 14:13:47 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:14:04 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 14:15:17 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:15:18 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:15:27 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:15:27 INFO mapreduce.Job: Job job_1402432471050_0010 completed successfully
14/06/10 14:15:27 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=177790
		Total time spent by all reduces in occupied slots (ms)=5886
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2720
		CPU time spent (ms)=79480
		Physical memory (bytes) snapshot=540745728
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 431155
[MR2PhaseApriori] Phase 1 execution time: 322387
[MR2PhaseApriori] Phase 2 execution time: 108768
Tue, Jun 10, 2014  2:15:28 PM
6
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 265
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:15:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:15:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:15:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:16:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:16:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:16:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:16:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:17:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:17:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:17:26 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:17:26 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:17:26 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:17:26 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:17:26 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:17:26 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:17:26 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:17:26 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:17:26 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:17:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0011
14/06/10 14:17:27 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0011 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:17:27 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0011/
14/06/10 14:17:27 INFO mapreduce.Job: Running job: job_1402432471050_0011
14/06/10 14:17:35 INFO mapreduce.Job: Job job_1402432471050_0011 running in uber mode : false
14/06/10 14:17:35 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:17:47 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 14:17:52 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:18:00 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 14:22:27 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 14:22:28 INFO mapreduce.Job:  map 100% reduce 93%
14/06/10 14:22:29 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:22:29 INFO mapreduce.Job: Job job_1402432471050_0011 completed successfully
14/06/10 14:22:29 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=299538
		Total time spent by all reduces in occupied slots (ms)=279837
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6704
		CPU time spent (ms)=280810
		Physical memory (bytes) snapshot=584237056
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:22:30 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:22:30 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:22:30 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:22:30 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:22:30 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:22:30 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:22:30 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:22:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0012
14/06/10 14:22:30 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0012 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:22:30 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0012/
14/06/10 14:22:30 INFO mapreduce.Job: Running job: job_1402432471050_0012
14/06/10 14:22:38 INFO mapreduce.Job: Job job_1402432471050_0012 running in uber mode : false
14/06/10 14:22:38 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:22:56 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 14:24:08 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:24:09 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:24:16 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:24:17 INFO mapreduce.Job: Job job_1402432471050_0012 completed successfully
14/06/10 14:24:17 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=176620
		Total time spent by all reduces in occupied slots (ms)=5807
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2665
		CPU time spent (ms)=79390
		Physical memory (bytes) snapshot=545796096
		Virtual memory (bytes) snapshot=2510467072
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 413805
[MR2PhaseApriori] Phase 1 execution time: 306106
[MR2PhaseApriori] Phase 2 execution time: 107699
Tue, Jun 10, 2014  2:24:19 PM
7
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 250
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:24:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:24:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:24:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:25:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:25:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:25:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:25:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:26:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:26:16 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:26:16 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:26:16 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:26:17 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:26:17 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:26:17 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:26:17 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:26:17 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:26:17 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:26:17 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:26:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0013
14/06/10 14:26:17 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0013 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:26:17 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0013/
14/06/10 14:26:17 INFO mapreduce.Job: Running job: job_1402432471050_0013
14/06/10 14:26:26 INFO mapreduce.Job: Job job_1402432471050_0013 running in uber mode : false
14/06/10 14:26:26 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:26:37 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:26:45 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:26:45 INFO mapreduce.Job: Job job_1402432471050_0013 completed successfully
14/06/10 14:26:45 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19566
		Total time spent by all reduces in occupied slots (ms)=5208
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=336
		CPU time spent (ms)=1590
		Physical memory (bytes) snapshot=551464960
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:26:45 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:26:45 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:26:45 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:26:46 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:26:46 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:26:46 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:26:46 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:26:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0014
14/06/10 14:26:46 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0014 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:26:46 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0014/
14/06/10 14:26:46 INFO mapreduce.Job: Running job: job_1402432471050_0014
14/06/10 14:26:54 INFO mapreduce.Job: Job job_1402432471050_0014 running in uber mode : false
14/06/10 14:26:54 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:27:06 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:27:13 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:27:14 INFO mapreduce.Job: Job job_1402432471050_0014 completed successfully
14/06/10 14:27:14 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242909
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19406
		Total time spent by all reduces in occupied slots (ms)=4852
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=319
		CPU time spent (ms)=1420
		Physical memory (bytes) snapshot=549527552
		Virtual memory (bytes) snapshot=2510430208
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 60065
[MR2PhaseApriori] Phase 1 execution time: 31575
[MR2PhaseApriori] Phase 2 execution time: 28490
Tue, Jun 10, 2014  2:27:15 PM
8
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 255
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:27:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:27:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:27:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:28:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:28:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:28:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:28:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:29:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:29:12 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:29:13 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:29:13 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:29:13 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:29:13 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:29:13 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:29:13 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:29:13 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:29:13 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:29:13 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:29:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0015
14/06/10 14:29:14 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0015 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:29:14 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0015/
14/06/10 14:29:14 INFO mapreduce.Job: Running job: job_1402432471050_0015
14/06/10 14:29:24 INFO mapreduce.Job: Job job_1402432471050_0015 running in uber mode : false
14/06/10 14:29:24 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:29:35 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 14:29:40 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:29:48 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 14:34:31 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 14:34:32 INFO mapreduce.Job:  map 100% reduce 33%
14/06/10 14:34:34 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:34:34 INFO mapreduce.Job: Job job_1402432471050_0015 completed successfully
14/06/10 14:34:34 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=315553
		Total time spent by all reduces in occupied slots (ms)=296214
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6702
		CPU time spent (ms)=286650
		Physical memory (bytes) snapshot=586629120
		Virtual memory (bytes) snapshot=2510548992
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:34:34 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:34:34 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:34:34 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:34:34 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:34:34 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:34:34 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:34:34 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:34:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0016
14/06/10 14:34:35 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0016 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:34:35 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0016/
14/06/10 14:34:35 INFO mapreduce.Job: Running job: job_1402432471050_0016
14/06/10 14:34:43 INFO mapreduce.Job: Job job_1402432471050_0016 running in uber mode : false
14/06/10 14:34:43 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:35:00 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 14:36:13 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:36:15 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:36:23 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:36:23 INFO mapreduce.Job: Job job_1402432471050_0016 completed successfully
14/06/10 14:36:23 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178493
		Total time spent by all reduces in occupied slots (ms)=5729
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2769
		CPU time spent (ms)=80510
		Physical memory (bytes) snapshot=547934208
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 432279
[MR2PhaseApriori] Phase 1 execution time: 323623
[MR2PhaseApriori] Phase 2 execution time: 108656
Tue, Jun 10, 2014  2:36:24 PM
9
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 253
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:36:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:36:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:36:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:37:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:37:22 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:37:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:37:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:38:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:38:21 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:38:22 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:38:22 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:38:22 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:38:22 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:38:22 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:38:22 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:38:22 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:38:22 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:38:22 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:38:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0017
14/06/10 14:38:23 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0017 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:38:23 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0017/
14/06/10 14:38:23 INFO mapreduce.Job: Running job: job_1402432471050_0017
14/06/10 14:38:32 INFO mapreduce.Job: Job job_1402432471050_0017 running in uber mode : false
14/06/10 14:38:32 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:38:44 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:38:52 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:38:52 INFO mapreduce.Job: Job job_1402432471050_0017 completed successfully
14/06/10 14:38:52 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=20584
		Total time spent by all reduces in occupied slots (ms)=4866
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=350
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=548642816
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:38:52 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:38:52 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:38:52 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:38:52 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:38:52 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:38:52 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:38:52 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:38:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0018
14/06/10 14:38:52 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0018 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:38:52 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0018/
14/06/10 14:38:52 INFO mapreduce.Job: Running job: job_1402432471050_0018
14/06/10 14:39:01 INFO mapreduce.Job: Job job_1402432471050_0018 running in uber mode : false
14/06/10 14:39:01 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:39:13 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:39:20 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:39:21 INFO mapreduce.Job: Job job_1402432471050_0018 completed successfully
14/06/10 14:39:21 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242909
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19837
		Total time spent by all reduces in occupied slots (ms)=4759
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=343
		CPU time spent (ms)=1410
		Physical memory (bytes) snapshot=551211008
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 61718
[MR2PhaseApriori] Phase 1 execution time: 32524
[MR2PhaseApriori] Phase 2 execution time: 29194
Tue, Jun 10, 2014  2:39:23 PM
10
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 241
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:39:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:39:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:39:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:40:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:40:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:40:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:40:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:41:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:41:20 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:41:20 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:41:21 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:41:21 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:41:21 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:41:21 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:41:21 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:41:21 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:41:21 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:41:21 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:41:21 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0019
14/06/10 14:41:22 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0019 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:41:22 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0019/
14/06/10 14:41:22 INFO mapreduce.Job: Running job: job_1402432471050_0019
14/06/10 14:41:30 INFO mapreduce.Job: Job job_1402432471050_0019 running in uber mode : false
14/06/10 14:41:30 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:41:42 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 14:41:47 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:41:56 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 14:46:28 INFO mapreduce.Job:  map 100% reduce 33%
14/06/10 14:46:30 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:46:30 INFO mapreduce.Job: Job job_1402432471050_0019 completed successfully
14/06/10 14:46:30 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=304832
		Total time spent by all reduces in occupied slots (ms)=284064
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6515
		CPU time spent (ms)=276270
		Physical memory (bytes) snapshot=590643200
		Virtual memory (bytes) snapshot=2510352384
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:46:30 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:46:30 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:46:30 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:46:30 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:46:30 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:46:30 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:46:30 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:46:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0020
14/06/10 14:46:30 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0020 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:46:30 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0020/
14/06/10 14:46:30 INFO mapreduce.Job: Running job: job_1402432471050_0020
14/06/10 14:46:39 INFO mapreduce.Job: Job job_1402432471050_0020 running in uber mode : false
14/06/10 14:46:39 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:46:56 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 14:48:09 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:48:10 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:48:18 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:48:18 INFO mapreduce.Job: Job job_1402432471050_0020 completed successfully
14/06/10 14:48:18 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178551
		Total time spent by all reduces in occupied slots (ms)=5854
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2698
		CPU time spent (ms)=78300
		Physical memory (bytes) snapshot=548544512
		Virtual memory (bytes) snapshot=2510000128
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 420377
[MR2PhaseApriori] Phase 1 execution time: 311817
[MR2PhaseApriori] Phase 2 execution time: 108560
Tue, Jun 10, 2014  2:48:20 PM
11
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 252
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:48:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:48:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:48:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:49:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:49:18 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:49:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:49:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:50:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:50:17 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:50:18 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:50:18 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:50:18 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:50:18 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:50:18 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:50:18 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:50:18 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:50:18 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:50:18 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:50:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0021
14/06/10 14:50:19 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0021 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:50:19 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0021/
14/06/10 14:50:19 INFO mapreduce.Job: Running job: job_1402432471050_0021
14/06/10 14:50:27 INFO mapreduce.Job: Job job_1402432471050_0021 running in uber mode : false
14/06/10 14:50:27 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:50:39 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:50:47 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:50:48 INFO mapreduce.Job: Job job_1402432471050_0021 completed successfully
14/06/10 14:50:48 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=238965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19968
		Total time spent by all reduces in occupied slots (ms)=4786
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=1
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=304
		CPU time spent (ms)=1510
		Physical memory (bytes) snapshot=550006784
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=4
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:50:48 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:50:48 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:50:48 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:50:48 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:50:48 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:50:48 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:50:48 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:50:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0022
14/06/10 14:50:48 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0022 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:50:48 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0022/
14/06/10 14:50:48 INFO mapreduce.Job: Running job: job_1402432471050_0022
14/06/10 14:50:57 INFO mapreduce.Job: Job job_1402432471050_0022 running in uber mode : false
14/06/10 14:50:57 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:51:09 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 14:51:16 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:51:17 INFO mapreduce.Job: Job job_1402432471050_0022 completed successfully
14/06/10 14:51:17 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=22
		FILE: Number of bytes written=242909
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19779
		Total time spent by all reduces in occupied slots (ms)=4773
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=12
		Map output materialized bytes=28
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=28
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=336
		CPU time spent (ms)=1430
		Physical memory (bytes) snapshot=546488320
		Virtual memory (bytes) snapshot=2510200832
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 61924
[MR2PhaseApriori] Phase 1 execution time: 32585
[MR2PhaseApriori] Phase 2 execution time: 29339
Tue, Jun 10, 2014  2:51:19 PM
12
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 245
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:51:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:51:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 14:51:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:52:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:52:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:52:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:52:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 14:53:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 14:53:16 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:53:16 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:53:17 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:53:17 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:53:17 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 14:53:17 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 14:53:17 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 14:53:17 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 14:53:17 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 14:53:17 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 14:53:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0023
14/06/10 14:53:17 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0023 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:53:18 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0023/
14/06/10 14:53:18 INFO mapreduce.Job: Running job: job_1402432471050_0023
14/06/10 14:53:26 INFO mapreduce.Job: Job job_1402432471050_0023 running in uber mode : false
14/06/10 14:53:26 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:53:38 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 14:53:43 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 14:53:54 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 14:58:37 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 14:58:39 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 14:58:40 INFO mapreduce.Job: Job job_1402432471050_0023 completed successfully
14/06/10 14:58:40 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=318801
		Total time spent by all reduces in occupied slots (ms)=297897
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6846
		CPU time spent (ms)=292060
		Physical memory (bytes) snapshot=595480576
		Virtual memory (bytes) snapshot=2510901248
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 14:58:40 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:58:40 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 14:58:40 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 14:58:40 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 14:58:40 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 14:58:40 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 14:58:40 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 14:58:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0024
14/06/10 14:58:40 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0024 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 14:58:40 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0024/
14/06/10 14:58:40 INFO mapreduce.Job: Running job: job_1402432471050_0024
14/06/10 14:58:49 INFO mapreduce.Job: Job job_1402432471050_0024 running in uber mode : false
14/06/10 14:58:49 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 14:59:05 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 15:00:19 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:00:21 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 15:00:28 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:00:29 INFO mapreduce.Job: Job job_1402432471050_0024 completed successfully
14/06/10 15:00:29 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178462
		Total time spent by all reduces in occupied slots (ms)=5952
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2741
		CPU time spent (ms)=79060
		Physical memory (bytes) snapshot=544018432
		Virtual memory (bytes) snapshot=2509864960
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 434759
[MR2PhaseApriori] Phase 1 execution time: 325934
[MR2PhaseApriori] Phase 2 execution time: 108825
Tue, Jun 10, 2014  3:00:30 PM
13
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 242
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:00:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:00:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 15:00:55 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:01:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:01:28 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:01:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:01:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:02:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:02:28 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:02:29 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:02:29 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:02:29 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:02:29 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 15:02:29 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 15:02:29 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 15:02:29 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 15:02:29 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 15:02:29 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 15:02:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0025
14/06/10 15:02:30 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0025 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:02:30 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0025/
14/06/10 15:02:30 INFO mapreduce.Job: Running job: job_1402432471050_0025
14/06/10 15:02:38 INFO mapreduce.Job: Job job_1402432471050_0025 running in uber mode : false
14/06/10 15:02:38 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:02:50 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 15:02:55 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:03:06 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 15:07:37 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 15:07:38 INFO mapreduce.Job:  map 100% reduce 70%
14/06/10 15:07:39 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:07:40 INFO mapreduce.Job: Job job_1402432471050_0025 completed successfully
14/06/10 15:07:40 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=306719
		Total time spent by all reduces in occupied slots (ms)=286257
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6634
		CPU time spent (ms)=280390
		Physical memory (bytes) snapshot=589479936
		Virtual memory (bytes) snapshot=2510151680
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 15:07:40 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:07:41 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:07:41 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:07:41 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:07:41 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 15:07:41 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 15:07:41 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 15:07:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0026
14/06/10 15:07:41 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0026 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:07:41 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0026/
14/06/10 15:07:41 INFO mapreduce.Job: Running job: job_1402432471050_0026
14/06/10 15:07:49 INFO mapreduce.Job: Job job_1402432471050_0026 running in uber mode : false
14/06/10 15:07:49 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:08:06 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 15:09:20 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:09:21 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 15:09:29 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:09:30 INFO mapreduce.Job: Job job_1402432471050_0026 completed successfully
14/06/10 15:09:30 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=177824
		Total time spent by all reduces in occupied slots (ms)=6137
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2772
		CPU time spent (ms)=79880
		Physical memory (bytes) snapshot=547774464
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 423901
[MR2PhaseApriori] Phase 1 execution time: 314326
[MR2PhaseApriori] Phase 2 execution time: 109575
Tue, Jun 10, 2014  3:09:32 PM
14
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 258
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:09:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:09:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 15:09:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:10:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:10:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:10:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:10:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:11:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:11:29 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:11:30 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:11:30 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:11:30 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:11:30 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 15:11:30 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 15:11:30 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 15:11:30 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 15:11:30 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 15:11:30 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 15:11:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0027
14/06/10 15:11:31 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0027 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:11:31 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0027/
14/06/10 15:11:31 INFO mapreduce.Job: Running job: job_1402432471050_0027
14/06/10 15:11:39 INFO mapreduce.Job: Job job_1402432471050_0027 running in uber mode : false
14/06/10 15:11:39 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:11:51 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 15:11:55 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:12:06 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 15:16:43 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 15:16:45 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:16:45 INFO mapreduce.Job: Job job_1402432471050_0027 completed successfully
14/06/10 15:16:45 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=312332
		Total time spent by all reduces in occupied slots (ms)=291268
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6651
		CPU time spent (ms)=279650
		Physical memory (bytes) snapshot=588234752
		Virtual memory (bytes) snapshot=2510147584
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 15:16:45 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:16:45 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:16:46 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:16:46 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:16:46 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 15:16:46 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 15:16:46 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 15:16:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0028
14/06/10 15:16:46 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0028 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:16:46 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0028/
14/06/10 15:16:46 INFO mapreduce.Job: Running job: job_1402432471050_0028
14/06/10 15:16:54 INFO mapreduce.Job: Job job_1402432471050_0028 running in uber mode : false
14/06/10 15:16:54 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:17:10 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 15:18:24 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:18:25 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 15:18:33 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:18:33 INFO mapreduce.Job: Job job_1402432471050_0028 completed successfully
14/06/10 15:18:33 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=178043
		Total time spent by all reduces in occupied slots (ms)=5665
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2694
		CPU time spent (ms)=78920
		Physical memory (bytes) snapshot=549642240
		Virtual memory (bytes) snapshot=2510221312
		Total committed heap usage (bytes)=404291584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 425902
[MR2PhaseApriori] Phase 1 execution time: 318137
[MR2PhaseApriori] Phase 2 execution time: 107765
Tue, Jun 10, 2014  3:18:35 PM
15
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 255
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:18:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:18:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 15:18:59 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:19:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:19:33 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /input-test
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:19:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:19:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:20:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:20:32 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:20:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:20:33 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:20:33 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:20:33 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/10 15:20:33 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/10 15:20:33 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/06/10 15:20:33 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/10 15:20:33 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/10 15:20:33 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/10 15:20:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0029
14/06/10 15:20:34 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0029 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:20:34 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0029/
14/06/10 15:20:34 INFO mapreduce.Job: Running job: job_1402432471050_0029
14/06/10 15:20:42 INFO mapreduce.Job: Job job_1402432471050_0029 running in uber mode : false
14/06/10 15:20:42 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:20:53 INFO mapreduce.Job:  map 50% reduce 0%
14/06/10 15:20:58 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:21:09 INFO mapreduce.Job:  map 83% reduce 17%
14/06/10 15:25:50 INFO mapreduce.Job:  map 100% reduce 17%
14/06/10 15:25:52 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:25:53 INFO mapreduce.Job: Job job_1402432471050_0029 completed successfully
14/06/10 15:25:53 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: Number of bytes read=1671226
		FILE: Number of bytes written=3581273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=1409022
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=316140
		Total time spent by all reduces in occupied slots (ms)=295268
	Map-Reduce Framework
		Map input records=2
		Map output records=65538
		Map output bytes=1540144
		Map output materialized bytes=1671232
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65536
		Reduce shuffle bytes=1671232
		Reduce input records=65538
		Reduce output records=65535
		Spilled Records=131076
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=6598
		CPU time spent (ms)=279410
		Physical memory (bytes) snapshot=588840960
		Virtual memory (bytes) snapshot=2510467072
		Total committed heap usage (bytes)=443285504
	MR2PhaseApriori$TOTALROWCOUNTER
		TOTALROW=1000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=1409022
[MR2PhaseApriori] Total rows: 1000
Just added 2 files into distributed cache.
14/06/10 15:25:53 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:25:53 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/10 15:25:53 INFO input.FileInputFormat: Total input paths to process : 2
14/06/10 15:25:53 INFO mapreduce.JobSubmitter: number of splits:2
14/06/10 15:25:53 INFO Configuration.deprecation: mapred.cache.files.filesizes is deprecated. Instead, use mapreduce.job.cache.files.filesizes
14/06/10 15:25:53 INFO Configuration.deprecation: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
14/06/10 15:25:53 INFO Configuration.deprecation: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
14/06/10 15:25:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402432471050_0030
14/06/10 15:25:53 INFO impl.YarnClientImpl: Submitted application application_1402432471050_0030 to ResourceManager at hadoop1/192.168.46.100:8032
14/06/10 15:25:53 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1402432471050_0030/
14/06/10 15:25:53 INFO mapreduce.Job: Running job: job_1402432471050_0030
14/06/10 15:26:02 INFO mapreduce.Job: Job job_1402432471050_0030 running in uber mode : false
14/06/10 15:26:02 INFO mapreduce.Job:  map 0% reduce 0%
14/06/10 15:26:19 INFO mapreduce.Job:  map 67% reduce 0%
14/06/10 15:27:34 INFO mapreduce.Job:  map 83% reduce 0%
14/06/10 15:27:35 INFO mapreduce.Job:  map 100% reduce 0%
14/06/10 15:27:42 INFO mapreduce.Job:  map 100% reduce 100%
14/06/10 15:27:43 INFO mapreduce.Job: Job job_1402432471050_0030 completed successfully
14/06/10 15:27:43 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=3342330
		FILE: Number of bytes written=6927543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=33210
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=179914
		Total time spent by all reduces in occupied slots (ms)=5738
	Map-Reduce Framework
		Map input records=2
		Map output records=131070
		Map output bytes=3080184
		Map output materialized bytes=3342336
		Input split bytes=210
		Combine input records=0
		Combine output records=0
		Reduce input groups=65535
		Reduce shuffle bytes=3342336
		Reduce input records=131070
		Reduce output records=1
		Spilled Records=262140
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2186
		CPU time spent (ms)=79010
		Physical memory (bytes) snapshot=575651840
		Virtual memory (bytes) snapshot=2510065664
		Total committed heap usage (bytes)=443285504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=33000
	File Output Format Counters 
		Bytes Written=7
[MR2PhaseApriori] Total execution time: 433435
[MR2PhaseApriori] Phase 1 execution time: 323043
[MR2PhaseApriori] Phase 2 execution time: 110392
Tue, Jun 10, 2014  3:27:45 PM
16
Warning, this script only works for 1000 lines now
Complete 1 rows in the first split: 248
Note: MR2PhaseApriori.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: ControlkRows.class(in = 1678) (out= 973)(deflated 42%)
adding: DatasetGenerator1.class(in = 1618) (out= 980)(deflated 39%)
adding: DatasetGenerator2.class(in = 1618) (out= 981)(deflated 39%)
adding: DatasetGenerator3.class(in = 1605) (out= 974)(deflated 39%)
adding: FisherYatesShuffle.class(in = 1028) (out= 663)(deflated 35%)
adding: LocalApriori.class(in = 4212) (out= 2094)(deflated 50%)
adding: MR2PhaseApriori$FirstPhaseMapper.class(in = 4622) (out= 2062)(deflated 55%)
adding: MR2PhaseApriori$FirstPhaseReducer.class(in = 3482) (out= 1448)(deflated 58%)
adding: MR2PhaseApriori$SecondPhaseMapper.class(in = 5406) (out= 2383)(deflated 55%)
adding: MR2PhaseApriori$SecondPhaseReducer.class(in = 3388) (out= 1414)(deflated 58%)
adding: MR2PhaseApriori$TOTALROWCOUNTER.class(in = 944) (out= 487)(deflated 48%)
adding: MR2PhaseApriori.class(in = 5995) (out= 2862)(deflated 52%)
adding: PermuteRows.class(in = 1795) (out= 1075)(deflated 40%)
adding: RandomPermuteRows.class(in = 1848) (out= 1109)(deflated 39%)
adding: WholeFileInputFormat.class(in = 1065) (out= 447)(deflated 58%)
adding: WholeFileRecordReader.class(in = 2588) (out= 1172)(deflated 54%)
META-INF/
META-INF/MANIFEST.MF
ControlkRows.class
DatasetGenerator1.class
DatasetGenerator2.class
DatasetGenerator3.class
FisherYatesShuffle.class
LocalApriori.class
MR2PhaseApriori$FirstPhaseMapper.class
MR2PhaseApriori$FirstPhaseReducer.class
MR2PhaseApriori$SecondPhaseMapper.class
MR2PhaseApriori$SecondPhaseReducer.class
MR2PhaseApriori$TOTALROWCOUNTER.class
MR2PhaseApriori.class
PermuteRows.class
RandomPermuteRows.class
WholeFileInputFormat.class
WholeFileRecordReader.class
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/dachuan/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/10 15:28:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/06/10 15:28:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test-1stphase
14/06/10 15:28:10 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /output-test
