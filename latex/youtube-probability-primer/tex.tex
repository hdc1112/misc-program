% https://latexbase.com/

\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[latin1]{inputenc}

\title{Notes on Youtube's probability primer}
\date{\today}

\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\T}{\mathcal{T}}

\begin{document}
\maketitle

\section{Definition of $\sigma$-algebra}

Given a set $\Omega$, a $\sigma$-algebra $\A$ is a non-empty subset of $2^\Omega$ such that:

\begin{enumerate}
    \item closed under complement, $E\in \A \implies E^c \in \A$ 

    \item closed under countable unions, $E_1\in \A, E_2\in \A \implies E_1\cup E_2\in \A$
\end{enumerate}

\bigbreak

\textbf{Theorem 1} $\Omega\in \A$

Proof: since $\A$ is non-empty, there must exist one element $E\in \A$. Because $\A$ is closed
under complement, so $E^c\in \A$. Because of $\A$ is closed under countable unions, so
$E \cup E^c \in \A$. Hence $\Omega\in A$.
\bigbreak

\textbf{Theorem 2} $\phi \in \A$

Proof: because $\Omega \in \A$ and $\A$ is closed under complement, so $\Omega^c=\phi\in \A$.
\bigbreak

\textbf{Theorem 3} $\A$ is closed under countable intersections.

Proof: $\bigcap\limits_{i=1}^{\infty} E_i = (\bigcup\limits_{i=1}^{\infty} E_i^c)^c$
From this equation we can see that $\A$ is closed under intersections.

\section{Definition of generated $\sigma$-algebra}

Given a $\C\subseteq 2^\Omega$, the generated $\sigma$-algebra $\C$, or $\sigma(\C)$, is the smallest
$\sigma$-algebra containing $\C$.
Or, $\sigma(\C)=\bigcap\limits_{\A\ is\ \sigma-algebra\ on\ \Omega,\ \C\subseteq \A} \A$.
\bigbreak

\textbf{Theorem 4} $\sigma(\C)$ always exists

Proof: $2^\Omega$ is a $\sigma$-algebra, and any intersections of $\sigma$-algebra is also
$\sigma$-algebra (needed by the mathematical ``smallest" definition). (These two can be easily proved.)
\bigbreak

Example of $\sigma$-algebra:
\begin{enumerate}
    \item $\A=\{\phi, \Omega\}$
    \item $\A=\{\phi,E, E^c, \Omega\}$
    \item if $\Omega = \mathbb{R}$, the Borel $\sigma$-algebra $\B(\mathbb{R})=\sigma(\T)$ where
        $\T=\{open\ sets\ of\ \mathbb{R}\}$.
\end{enumerate}

\section{Definition of measure}

A measure $\mu$ on $\Omega$ with $\sigma$-algebra $\A$ is a function
$\mu: \A \rightarrow [0,\infty]$ such that:

\begin{enumerate}
    \item $\mu(\phi) = 0$
    \item ``countable additivity" $\mu(\bigcup\limits_{i=1}^{\infty} E_i)=\sum\limits_{i=1}^{\infty} \mu(E_i)$ for any pairwise disjoint sets $E_1, E_2, ... \in \A$ 
\end{enumerate}

\section{Definition of probability measure}

A probability measure is a measure $P$ such that $P(\Omega) = 1$. (Notice that $\Omega\in \A$). Also known as Kolmogorov's axioms.

\section{Example of measures}

\begin{enumerate}
\item $\Omega=\{1,2,...,n\}$, $\A=2^\Omega$, 
$P(\{k\})=P(k)=1/n,\forall k\in\Omega$. Uniform distribution. We do
not need to define other element $E\in\A$ because of countable
additivity.

\item Countable infinite. $\Omega=\{1,2,3,...\}$, $\A=2^\Omega$,
$P(\{k\})=P(k)=\\ probability\ it\ takes\ k\ coinflips\ to\ get\ heads
=\alpha * (1-\alpha)^{k-1}=1/2 * (1 - 1/2)^{k-1}$. Geometric distribution.

\item Uncountable infinite. $\Omega=[0,\infty)$, $\A=\B(\Omega)$,
$P([0,x))=1-e^{-x}, \forall x>0$. Exponential distribution. Note
that $P({x})=0,\forall x\ge 0$ because this is a continuous distribution.

\item Lebesgue measure. $\Omega=\mathbb{R}$, $\A=\B(\mathbb{R})$,
$\mu((a,b)) = b - a,\forall a,b\in\mathbb{R},a<b$. 
\end{enumerate}

\section{Basic properties of measures}

Let $(\Omega,\A,\mu)$ be a measure space.

\begin{enumerate}
    \item Monoticity: If $E,F\in\A$ and $E\subset F$, then $\mu(E)\le\mu(F)$
    \item Subadditivity: If $E_1,E_2,...\in\A$, then
        $\mu(\bigcup\limits_{i=1}^{\infty} E_i)\le \sum\limits_{i=1}^{\infty} \mu(E_i)$

    \item Continuity from below: If $E_1,E_2,...\in\A$ and $E_1\subset E_2\subset ...$,
        then $\mu(\bigcup\limits_{i=1}^{\infty} E_i)=\lim\limits_{i\rightarrow\infty} \mu(E_i)$

    \item Continuity from above: If $E_1,E_2,...\in\A$ and $E_1\supset E_2\supset ...$
        and $\mu(E_1)<\infty$, then
        $\mu(\bigcap\limits_{i=1}^{\infty} E_i)=\lim\limits_{i\rightarrow\infty} \mu(E_i)$
\end{enumerate}

\section{Facts}

Let $(\Omega,\A,P)$ be probability measure space with $E,F,E_i\in\A$.

\begin{enumerate}
    \item $P(E\cup F)=P(E)+P(F)$ if $E\cap F=\phi$
    \item $P(E\cup F)=P(E)+P(F)-P(E\cap F)$
    \item $P(E)=1-P(E^c)$
    \item $P(E\cap F^c)=P(E) - P(E\cap F)$
    \item (Inclusion-Exclusion formula)
        $P(\bigcup\limits_{i=1}^{n} E_i)=\sum\limits_{i} P(E_i) - \sum\limits_{i<j} P(E_i\cap E_j) 
        + \sum\limits_{i<j<k} P(E_i\cap E_j\cap E_k) - ... + (-1)^{n+1}P(E_1\cap E_2\cap ... \cap E_n)$

    \item $P(\bigcup\limits_{i=1}^{n} E_i)\le \sum\limits_{i=1}^{n} P(E_i)$ and
          $P(\bigcup\limits_{i=1}^{\infty} E_i)\le \sum\limits_{i=1}^{\infty} P(E_i)$
\end{enumerate}

\section {$\mathbb{R}$ and $\B(\mathbb{R})$}

Definition: A Borel measure on $\mathbb{R}$ is a measure on $(\mathbb{R},\B(\mathbb{R}))$.

Definition: A CDF (cumulative distribution function) is a function $F:\mathbb{R}\rightarrow\mathbb{R}$
such that 
\begin{enumerate}
    \item $F$ is nondecreasing $(x\le y \Rightarrow F(x)\le F(y))$
    \item $F$ is right continuous $(\lim\limits_{x\searrow a} F(x)=F(a))$
    \item $\lim\limits_{x\rightarrow\infty} F(x)=1$
    \item $\lim\limits_{x\rightarrow -\infty} F(x)=0$
\end{enumerate}

\bigbreak
\textbf{Theorem}: There is an equivalence between CDFs and Borel probability measures.

\begin{enumerate}
    \item If $F$ is a CDF then there is a unique Borel probability measure on $\mathbb{R}$
such that $P((-\infty,x]))=F(x), \forall x\in\mathbb{R}$

\item If $P$ is a Borel probability measure on $\mathbb{R}$ then there is a unique CDF $F$ such
that $F(x)=P((-\infty,x]), \forall x\in\mathbb{R}$

\end{enumerate}

\section{References on measure theory}

Real analysis (Undergrad)
\begin{enumerate}
\item Rudin's ``Principles of Mathematical Analysis"
\end{enumerate}

Probability (grad)

\begin{enumerate}
    \item Jacod \& Protter "Probability Essentials"
    \item Durrett ``Probability Theory and Examples"
    \item Grimmett \& Stirzaker ``Probability \& Random Processes"
\end{enumerate}

Real analysis (Grad)

\begin{enumerate}
    \item Fdlord's ``Real Analysis"
    \item Rudin ``Real \& Complex Analysis"
\end{enumerate}

\section{Summary}

Definition: A $\sigma-algebra$ on $\Omega$ is a collection $\A\subset 2^\Omega$ such that
\begin{enumerate}
    \item $E\in\A \Rightarrow E^c\in\A$
    \item $E_1,E_2,...\in\A\Rightarrow \bigcup\limits_{i=1}^{\infty} E_i\in\A$ Also closed under finite unions
\end{enumerate}

Definition: A probability measure $P$ on $(\Omega,\A)$ is a function $P:\A\rightarrow [0,1]$
such that
\begin{enumerate}
    \item $P(\phi)=0$, and $P(\Omega)=1$.
    \item $P(\bigcup\limits_{i=1}^{\infty} E_i)=\sum\limits_{i=1}^{\infty} P(E_i)$
        for any $E_1,E_2,...\in\A$ pairwise disjoint set
\end{enumerate}

Remarks:
\begin{enumerate}
    \item $P(E\cup F)=P(E)+P(F)-P(E\cap F), E,F\in\A$
    \item $P(E)=1-P(E^c), \forall E\in \A$
    \item $E\subset F$ then $P(E)\le P(F)$
    \item If $E_1,E_2,...\in\A$ then $P(\bigcup\limits_{i=1}^{\infty} E_i)\le
        \sum\limits_{i=1}^{\infty} P(E_i)$

    \item If $E_1\subset E_2\subset... $ then $P(\bigcup\limits_{i=1}^{\infty} E_i)
        =\lim\limits_{i\rightarrow \infty} P(E_i)$

    \item If $E_1\supset E_2\supset...$ then $P(\bigcap\limits_{i=1}^{\infty} E_i)
        =\lim\limits_{i\rightarrow \infty} P(E_i)$

\end{enumerate}

Definition: A CDF is a function $F:\mathbb{R}\rightarrow\mathbb{R}$ such that
\begin{enumerate}
    \item $x\le y \Rightarrow F(x)\le F(y) (x,y\in \mathbb{R})$
    \item $\lim\limits_{x\searrow a} F(x) = F(a)$
    \item $\lim\limits_{x\rightarrow \infty} F(x) = 1$
    \item $\lim\limits_{x\rightarrow -\infty} F(x)=0$
\end{enumerate}

Theorem: $F(x)=P((-\infty,x])$ defines a one-to-one mapping from CDF function $F$
to Borel probability measure function $P$. That is to say, if
we have a CDF function $F$, then we have a probability measure $P$, and vice versa.
This simplies lots of things, and deserves a theorem.


\section{Conditional Probability and Independence}

Notation: hidden $(\Omega,\A)$ and $P(E)$.

Terminology: event = measurable set = set in $\A$. sample space = $\Omega$. 
\bigbreak

Definition: If $P(B)>0$, then $P(A|B)=\frac{P(A\cap B)}{P(B)}$.
\bigbreak

Definition: Events $A, B$ are independent if $P(A\cap B) = P(A) P(B)$.
\bigbreak

Theorem: Suppose $P(B)>0$, then $A,B$ are indep. iff $P(A|B)=P(A)$

Proof: (trivial, by def. of $|$ and def. of indep.)
\bigbreak

Definition: $A_1,A_2,...,A_n$ are mutually independent if $\forall S\subseteq \{1,2,...,n\}$,
$P(\bigcap\limits_{i\in S} A_i) = \prod\limits_{i\in S} P(A_i)$

Remark: mutually independence $\Rightarrow$ pairwise indepenjdence

Remark: pairwise independence $\nRightarrow$ mutually independence

Remark: One interesting picture to show $n$ mutually independent sets (PP 2.2).
\bigbreak

Definition: $A_1, A_2,...$ are MI if $\forall\ finite\ S\in \{1,2,...\}$ (like above).
\bigbreak

Definition: Events $A,B$ are conditionally independent given $C$ if
$P(A\cap B | C) = P(A|C) P (B|C)$.

Remark: $A,B$ are conditionally independent given $C$ does not always mean that $A$ and $B$
are independent.
\bigbreak

Definition: $A_1, A_2,...,A_n$ are CI given $C$ if $\forall\ finite\ S\in \{1,2,...,n\}$,
$P(\bigcap\limits_{i\in S} A_i|C)=\prod\limits_{i\in S} P(A_i|C)$. ($P(C) > 0$ for all conditional
independence definition).

\section{Bayes' rule}

Remind: $P(A\cap B) = P(A|B)P(B)$ if $P(B) > 0$ (from def. of $|$)

Rewrite: $P(B\cap A) = P(B|A) P(A)$ if $P(A) > 0$ (from def. of $|$)
\bigbreak

\textbf{The Bayes' rule}: $P(B|A)=\frac{P(A|B)P(B)}{P(A)}$ if $P(A)>0$ and $P(B)>0$

\section{Chain rule}

\textbf{Chain rule}: If $A_1,A_2,...,A_n$ and $P(A_1\cap A_2...\cap A_{n-1}) > 0$,
then $P(A_1\cap A_2...\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)...P(A_n|A_1\cap ... \cap A_{n-1})$.

Proof: (trivial, induction over $n$)

Remark: $P(A_1\cap A_2\cap ... \cap A_{n-1})>0$ already implies that $\forall s\in \{2,...n\}$,
$P(A_1\cap A_2\cap ...\cap A_{s-1}) > 0$.

\section{Partition rule}

Definition: A partition of $\Omega$ is a finite or countable infinite collection
of $\{B_i\}\subset 2^{\Omega}$, such that
\begin{enumerate}
    \item $\bigcup\limits_i B_i = \Omega$
    \item $B_i\cap B_j = \phi, i\neq j$
\end{enumerate}

\textbf{Partition rule}: $P(A) = \sum\limits_i P(A\cap B_i)$ for any paritition $\{B_i\}$ of $\Omega$.

Proof: $A=A\cap \Omega=A\cap (\bigcup\limits_i B_i)=\bigcup\limits_i (A\cap B_i)$, and
$(A\cap B_i)\cap (A\cap B_j)=\phi, i\neq j$, so because of additivity of measure,
we have $P(A) = \sum\limits_i P(A\cap B_i)$.

\section{Conditional measure}

Theorem: If $P(B)>0$, then $Q(A)=P(A|B)$ defines a probability measure $Q$ (conditional
probability measure given $B$.

Proof: (trivial, use Partition rule)

\section{Random Variables}

Definition: Given $(\Omega, \A, P)$, a random variable is a function $X:\Omega \rightarrow \mathbb{R}$
such that $\{w\in \Omega: X(w)\le x\} \in \A$ $\forall x\in \mathbb{R}$
\bigbreak

Remarks
\begin{enumerate}
    \item $X$ is called a measurable function if $X$ satisfies that $\{w\in \Omega: X(w)\le x\} \in \A$ $\forall x\in \mathbb{R}$
    \item Notation: capital letters $X, Y$ for random variables, little letters $x,y$ for values
    \item Notation: $\{X\le x\}=\{w\in\Omega:X(w)\le x\}$; $\{...X...\}=\{w\in\Omega:...X(w)...\}$
    \item Notation: $P(X\le x)=P(\{X\le x\})$; $P(...)=P(\{...\})$
\end{enumerate}
\bigbreak

Definition (ext.): The CDF of a random variable $X$ is the function $F:\mathbb{R}\rightarrow [0,1]$
such that $F(x)=P(X\le x)$ (this definition fits the old CDF definition above, proof trivial)

Warning: before this, we have the definition of probability measure, and the definition
of CDF. now, this new function $F(x)=P(X\le x)$, which is defined on top of probability measure
and random variable,
is actually a CDF because it fits the old CDF definition. 
\bigbreak

Definition (ext.): The distribution of $X$ is the function $P^X: \B(\mathbb{R})\rightarrow \mathbb{R}$
such that $P^{X}(A)=P(X\in A)$ where $A\in \B(\mathbb{R})$. Proof that $P^X$ is a
probability measure function is trivial.
\bigbreak

Warning: $P(X\in A)=P(\{w\in\Omega | X(w)\in A\})$ where $A\in \mathcal{B}(\mathbb{R})$ (informally,
treat it as $A\subseteq \mathbb{R}$)
\bigbreak

%Useful link: \url{http://math.arizona.edu/~tgk/mc/prob_background.pdf}
%\bigbreak

Claim: $P^X$ is the probability measure induced by $F$ (because previously we mentioned that
there is a one-to-one mapping between CDF and probability measure, we need to prove
that the $P^X$ is exactly the same with that probability measure)

Proof: $Q((-\infty,x])=F(x)=P(X\le x)=P(X\in(-\infty,x])=P^{X}((-\infty,x])$
this implies that $Q=P^X$.
\bigbreak

\textbf{Summary} After defining random variable $X$, we defined two new functions on top of it:
\begin{enumerate}
    \item $P^X(A) = P(X\in A), A\in\B(\mathbb{R})$. It turns out this is a probability measure function.
        We call it ``the distribution of random variable $X$".
    \item $F(x) = P(X\le x), x\in \mathbb{R}$. It turns out this is a CDF function.
        We call it ``CDF of the random variable $X$".
\end{enumerate}
And finally it turns out they form a pair, and each of them can be induced from the other.

\section{Types of Random Variables}

Definition: A random variable $X$ is discrete if $X(\Omega)=\{X(w):w\in\Omega\}$ is countable.
e.g., $X(\Omega)=\{x_1, x_2,...\}$.
\bigbreak

Definition: A random variable $X$ has a density $f$ if $F(x)=\int\limits_{-\infty}^x f(u)du, \forall x\in \mathbb{R}$ 
(for some integrable $f:\mathbb{R}\rightarrow [0,\infty)$). (so density function is defined after CDF)
\bigbreak

Advanced part below.

Let $Q=P^X$. Let $J=\{x\in\mathbb{R}:Q(\{x\})>0\}$. Let $Q_d(A)=Q(A\cap J)$.
Let $Q_c(A) = Q(A) - Q(A\cap J)$. So $Q= Q_d + Q_c$.

$Q_d$ is the discrete part of this measure $Q$,
and $Q_c$ is the continuous part of this measure $Q$.

$Q_c=Q_{ac} + Q_{sc}$ (by R-N theorem) where $Q_{ac}((-\infty,x])=\int\limits_{-\infty}^{x} f(u)du$
for some $f:\mathbb{R}\rightarrow [0,\infty)$.

Claim: $X$ is discrete $\Rightarrow$ $Q=Q_d$; $X$ has density $\Leftrightarrow$ $Q=Q_{ac}$. (Proof omitted).

Warning: beware of the singular part! $Q=Q_c \nRightarrow X$ has a density.
One counter-example is: cantor function as CDF, which $Q_d=0,Q_{ac}=0$
\bigbreak

Remark: need to learn mathematics..

\section{Discrete Random Variable}

Recall that $X$ is a random variable if $X(\Omega)$ is countable.

Definition: The probability mass function (pmf) of a discrete random variable
is the function $p:\mathbb{R}\rightarrow [0,1]$ such that $p(x)=P(X=x)$.

Remarks:
%\begin{enumerate}
%\end{enumerate}


\end{document}

