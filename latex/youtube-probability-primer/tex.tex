% https://latexbase.com/

\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[latin1]{inputenc}

\title{Notes on Youtube's probability primer}
\date{\today}

\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\T}{\mathcal{T}}

\begin{document}
\maketitle

\section{Definition of $\sigma$-algebra}

Given a set $\Omega$, a $\sigma$-algebra $\A$ is a non-empty subset of $2^\Omega$ such that:

\begin{enumerate}
    \item closed under complement, $E\in \A \implies E^c \in \A$ 

    \item closed under countable unions, $E_1\in \A, E_2\in \A \implies E_1\cup E_2\in \A$
\end{enumerate}

\par \noindent

\textbf{Theorem 1} $\Omega\in \A$

Proof: since $\A$ is non-empty, there must exist one element $E\in \A$. Because $\A$ is closed
under complement, so $E^c\in \A$. Because of $\A$ is closed under countable unions, so
$E \cup E^c \in \A$. Hence $\Omega\in A$.

\textbf{Theorem 2} $\phi \in \A$

Proof: because $\Omega \in \A$ and $\A$ is closed under complement, so $\Omega^c=\phi\in \A$.

\textbf{Theorem 3} $\A$ is closed under countable intersections.

Proof: $\bigcap\limits_{i=1}^{\infty} E_i = (\bigcup\limits_{i=1}^{\infty} E_i^c)^c$
From this equation we can see that $\A$ is closed under intersections.

\section{Definition of generated $\sigma$-algebra}

Given a $\C\in 2^\Omega$, the generated $\sigma$-algebra $\C$, or $\sigma(\C)$, is the smallest
$\sigma$-algebra containing $\C$.
Or, $\sigma(\C)=\bigcap\limits_{\A\ is\ \sigma-algebra\ on\ \Omega,\ \C\subseteq \A} \A$.

\textbf{Theorem 4} $\sigma(\C)$ always exists

Proof: $2^\Omega$ is a $\sigma$-algebra, and any intersections of $\sigma$-algebra is also
$\sigma$-algebra (needed by the mathematical ``smallest" definition). (These two can be easily proved.)

Example of $\sigma$-algebra:
\begin{enumerate}
    \item $\A=\{\phi, \Omega\}$
    \item $\A=\{\phi,E, E^c, \Omega\}$
    \item if $\Omega = \mathbb{R}$, the Borel $\sigma$-algebra $\B=\sigma(\T)$ where
        $\T=\{open\ sets\ of\ \mathbb{R}\}$.
\end{enumerate}

\section{Definition of measure}

A measure $\mu$ on $\Omega$ with $\sigma$-algebra $\A$ is a function
$\mu: \A \rightarrow [0,\infty]$ such that:

\begin{enumerate}
    \item $\mu(\phi) = 0$
    \item ``countable additivity" $\mu(\bigcup\limits_{i=1}^{\infty} E_i)=\sum\limits_{i=1}^{\infty} \mu(E_i)$ for any pairwise disjoint sets $E_1, E_2, ... \in \A$ 
\end{enumerate}

\section{Definition of probability measure}

A probability measure is a measure $P$ such that $P(\Omega) = 1$. (Notice that $\Omega\in \A$). Also known as Kolmogorov's axioms.

\section{Example of measures}

\begin{enumerate}
\item $\Omega=\{1,2,...,n\}$, $\A=2^\Omega$, 
$P(\{k\})=P(k)=1/n,\forall k\in\Omega$. Uniform distribution. We do
not need to define other element $E\in\A$ because of countable
additivity.

\item Countable infinite. $\Omega=\{1,2,3,...\}$, $\A=2^\Omega$,
$P(\{k\})=P(k)=\\ probability\ it\ takes\ k\ coinflips\ to\ get\ heads
=\alpha * (1-\alpha)^{k-1}=1/2 * (1 - 1/2)^{k-1}$. Geometric distribution.

\item Uncountable infinite. $\Omega=[0,\infty)$, $\A=\B(\Omega)$,
$P([0,x))=1-e^{-x}, \forall x>0$. Exponential distribution. Note
that $P({x})=0,\forall x\ge 0$ because this is a continuous distribution.

\item Lebesgue measure. $\Omega=\mathbb{R}$, $\A=\B(\mathbb{R})$,
$\mu((a,b)) = b - a,\forall a,b\in\mathbb{R},a<b$. 
\end{enumerate}

\section{Basic properties of measures}

Let $(\Omega,\A,\mu)$ be a measure space.

\begin{enumerate}
    \item Monoticity: If $E,F\in\A$ and $E\subset F$, then $\mu(E)\le\mu(F)$
    \item Subadditivity: If $E_1,E_2,...\in\A$, then
        $\mu(\bigcup\limits_{i=1}^{\infty} E_i)\le \sum\limits_{i=1}^{\infty} \mu(E_i)$

    \item Continuity from below: If $E_1,E_2,...\in\A$ and $E_1\subset E_2\subset ...$,
        then $\mu(\bigcup\limits_{i=1}^{\infty} E_i)=\lim\limits_{i\rightarrow\infty} \mu(E_i)$

    \item Continuity from above: If $E_1,E_2,...\in\A$ and $E_1\supset E_2\supset ...$
        and $\mu(E_1)<\infty$, then
        $\mu(\bigcap\limits_{i=1}^{\infty} E_i)=\lim\limits_{i\rightarrow\infty} \mu(E_i)$
\end{enumerate}

\section{Facts}

Let $(\Omega,\A,P)$ be probability measure space with $E,F,E_i\in\A$.

\begin{enumerate}
    \item $P(E\cup F)=P(E)+P(F)$ if $E\cap F=\phi$
    \item $P(E\cup F)=P(E)+P(F)-P(E\cap F)$
    \item $P(E)=1-P(E^c)$
    \item $P(E\cap F^c)=P(E) - P(E\cap F)$
    \item (Inclusion-Exclusion formula)
        $P(\bigcup\limits_{i=1}^{n} E_i)=\sum\limits_{i} P(E_i) - \sum\limits_{i<j} P(E_i\cap E_j) 
        + \sum\limits_{i<j<k} P(E_i\cap E_j\cap E_k) - ... + (-1)^{n+1}P(E_1\cap E_2\cap ... \cap E_n)$

    \item $P(\bigcup\limits_{i=1}^{n} E_i)\le \sum\limits_{i=1}^{n} P(E_i)$ and
          $P(\bigcup\limits_{i=1}^{\infty} E_i)\le \sum\limits_{i=1}^{\infty} P(E_i)$
\end{enumerate}

\section {$\mathbb{R}$ and $\B(\mathbb{R})$}

Definition: A Borel measure on $\mathbb{R}$ is a measure on $(\mathbb{R},\B(\mathbb{R}))$.

Definition: A CDF (cumulative distribution function) is a function $F:\mathbb{R}\rightarrow\mathbb{R}$
such that 
\begin{enumerate}
    \item $F$ is nondecreasing $(x\le y \Rightarrow F(x)\le F(y))$
    \item $F$ is right continuous $(\lim\limits_{x\searrow a} F(x)=F(a))$
    \item $\lim\limits_{x\rightarrow\infty} F(x)=1$
    \item $\lim\limits_{x\rightarrow -\infty} F(x)=0$
\end{enumerate}

\textbf{Theorem} There is an equivalence between CDFs and Borel probability measures.

\begin{enumerate}
    \item If $F$ is a CDF then there is a unique Borel probability measure on $\mathbb{R}$
such that $P((-\infty,x]))=F(x), \forall x\in\mathbb{R}$

\item If $P$ is a Borel probability measure on $\mathbb{R}$ then there is a unique CDF $F$ such
that $F(x)=P((-\infty,x]), \forall x\in\mathbb{R}$

\end{enumerate}

\section{References on measure theory}

Real analysis (Undergrad)
\begin{enumerate}
\item Rudin's ``Principles of Mathematical Analysis"
\end{enumerate}

Probability (grad)

\begin{enumerate}
    \item Jacod \& Protter "Probability Essentials"
    \item Durrett ``Probability Theory and Examples"
    \item Grimmett \& Stirzaker ``Probability \& Random Processes"
\end{enumerate}

Real analysis (Grad)

\begin{enumerate}
    \item Fdlord's ``Real Analysis"
    \item Rudin ``Real \& Complex Analysis"
\end{enumerate}

\section{Summary}

Definition: A $\sigma-algebra$ on $\Omega$ is a collection $\A\subset 2^\Omega$ such that
\begin{enumerate}
    \item $E\in\A \Rightarrow E^c\in\A$
    \item $E_1,E_2,...\in\A\Rightarrow \bigcup\limits_{i=1}^{\infty} E_i\in\A$ Also closed under finite unions
\end{enumerate}

Definition: A probability measure $P$ on $(\Omega,\A)$ is a function $P:\A\rightarrow [0,1]$
such that
\begin{enumerate}
    \item $P(\phi)=0$, and $P(\Omega)=1$.
    \item $P(\bigcup\limits_{i=1}^{\infty} E_i)=\sum\limits_{i=1}^{\infty} P(E_i)$
        for any $E_1,E_2,...\in\A$ pairwise disjoint set
\end{enumerate}

Remarks:
\begin{enumerate}
    \item $P(E\cup F)=P(E)+P(F)-P(E\cap F), E,F\in\A$
    \item $P(E)=1-P(E^c), \forall E\in \A$
    \item $E\subset F$ then $P(E)\le P(F)$
    \item If $E_1,E_2,...\in\A$ then $P(\bigcup\limits_{i=1}^{\infty} E_i)\le
        \sum\limits_{i=1}^{\infty} P(E_i)$

    \item If $E_1\subset E_2\subset... $ then $P(\bigcup\limits_{i=1}^{\infty} E_i)
        =\lim\limits_{i\rightarrow \infty} P(E_i)$

    \item If $E_1\supset E_2\supset...$ then $P(\bigcap\limits_{i=1}^{\infty} E_i)
        =\lim\limits_{i\rightarrow \infty} P(E_i)$

\end{enumerate}

Definition: A CDF is a function $F:\mathbb{R}\rightarrow\mathbb{R}$ such that
\begin{enumerate}
    \item $x\le y \Rightarrow F(x)\le F(y) (x,y\in \mathbb{R})$
    \item $\lim\limits_{x\searrow a} = F(a)$
    \item $\lim\limits_{x\rightarrow \infty} F(x) = 1$
    \item $\lim\limits_{x\rightarrow -\infty} F(x)=0$
\end{enumerate}

Theorem: $F(x)=P((-\infty,x])$ defines an equivalence between CDF $F$ and Borel probability measure $P$ on
$\mathbb{R}$.






\end{document}

